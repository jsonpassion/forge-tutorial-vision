# IP-Adapter

> ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ í™œìš©

## ê°œìš”

[ControlNet](./03-controlnet.md)ì—ì„œ ì´ë¯¸ì§€ì˜ **êµ¬ì¡°**(í¬ì¦ˆ, ì—ì§€, ê¹Šì´)ë¥¼ ë”°ë¼ ìƒì„±í•˜ëŠ” ë°©ë²•ì„ ë°°ì› ìŠµë‹ˆë‹¤. ì´ë²ˆì—ëŠ” **IP-Adapter** â€” ì´ë¯¸ì§€ ìì²´ë¥¼ í”„ë¡¬í”„íŠ¸ë¡œ ì‚¬ìš©í•˜ì—¬ **ìŠ¤íƒ€ì¼, ë¶„ìœ„ê¸°, ì‹¬ì§€ì–´ ì–¼êµ´**ê¹Œì§€ ì „ì´í•˜ëŠ” ê¸°ìˆ ì„ ë‹¤ë£¹ë‹ˆë‹¤. "ì´ ê·¸ë¦¼ ìŠ¤íƒ€ì¼ë¡œ ìƒˆ ì´ë¯¸ì§€ ë§Œë“¤ì–´ì¤˜", "ì´ ì‚¬ëŒ ì–¼êµ´ë¡œ ë‹¤ë¥¸ ìƒí™© ìƒì„±í•´ì¤˜"ê°€ ê°€ëŠ¥í•´ì§‘ë‹ˆë‹¤.

**ì„ ìˆ˜ ì§€ì‹**: [SD ì•„í‚¤í…ì²˜](../13-stable-diffusion/01-sd-architecture.md), [CLIP](../10-vision-language/02-clip.md)
**í•™ìŠµ ëª©í‘œ**:
- IP-Adapterì˜ Decoupled Cross-Attention ì•„í‚¤í…ì²˜ë¥¼ ì´í•´í•œë‹¤
- IP-Adapter ë³€í˜•ë“¤(Plus, FaceID)ì˜ ì°¨ì´ë¥¼ íŒŒì•…í•œë‹¤
- ìŠ¤íƒ€ì¼ ì „ì´ì™€ ì–¼êµ´ ì¼ê´€ì„± ìƒì„±ì„ ì‹¤ìŠµí•œë‹¤
- ControlNetê³¼ IP-Adapterë¥¼ ì¡°í•©í•  ìˆ˜ ìˆë‹¤

## ì™œ ì•Œì•„ì•¼ í• ê¹Œ?

Midjourneyë‚˜ DALL-E 3ì—ì„œ "ì´ë¯¸ì§€ ì°¸ì¡°" ê¸°ëŠ¥ì„ ì‚¬ìš©í•´ë³´ì…¨ë‚˜ìš”? IP-AdapterëŠ” Stable Diffusionì—ì„œ ê°™ì€ ê¸°ëŠ¥ì„ êµ¬í˜„í•©ë‹ˆë‹¤. ë‹¨ **22M(2200ë§Œ) íŒŒë¼ë¯¸í„°**ì˜ ê²½ëŸ‰ ì–´ëŒ‘í„°ë¡œ, ì°¸ì¡° ì´ë¯¸ì§€ì˜ ìŠ¤íƒ€ì¼ì´ë‚˜ ì£¼ì œë¥¼ ìƒˆ ì´ë¯¸ì§€ì— ë°˜ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. [LoRA](./01-lora.md)ê°€ í•™ìŠµì´ í•„ìš”í•˜ë‹¤ë©´, IP-AdapterëŠ” **í•™ìŠµ ì—†ì´ ì¦‰ì‹œ** ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ í™œìš©í•  ìˆ˜ ìˆë‹¤ëŠ” ê²Œ í° ì¥ì ì…ë‹ˆë‹¤.

## í•µì‹¬ ê°œë…

### ê°œë… 1: IP-Adapterì˜ í•µì‹¬ ì•„ì´ë””ì–´

> ğŸ’¡ **ë¹„ìœ **: IP-AdapterëŠ” **í†µì—­ì‚¬**ì™€ ê°™ìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¼ëŠ” "ì˜ì–´"ì™€ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ë¼ëŠ” "ì¤‘êµ­ì–´"ë¥¼ ëª¨ë‘ ì´í•´í•´ì„œ, ë‘ ì–¸ì–´ì˜ ì˜ë¯¸ë¥¼ í•©ì³ ê²°ê³¼ë¬¼ì„ ë§Œë“¤ì–´ëƒ…ë‹ˆë‹¤. ê¸°ì¡´ SDëŠ” í…ìŠ¤íŠ¸ë§Œ ì´í•´í–ˆì§€ë§Œ, IP-Adapterë¥¼ ë¶™ì´ë©´ ì´ë¯¸ì§€ë„ "ì½ì„ ìˆ˜" ìˆê²Œ ë˜ì£ .

IP-Adapter(Image Prompt Adapter)ëŠ” 2023ë…„ 8ì›” Tencent AI Labì—ì„œ ë°œí‘œí•œ ë…¼ë¬¸ "IP-Adapter: Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Models"ì—ì„œ ì†Œê°œë˜ì—ˆìŠµë‹ˆë‹¤.

**í•µì‹¬ ì•„ì´ë””ì–´:**

1. **ì´ë¯¸ì§€ ì¸ì½”ë”**: ì°¸ì¡° ì´ë¯¸ì§€ì—ì„œ íŠ¹ì§•(feature) ì¶”ì¶œ
2. **ë¶„ë¦¬ëœ Cross-Attention**: í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ë³„ë„ë¡œ ì²˜ë¦¬
3. **ê²°í•©**: ë‘ ì¡°ê±´ì„ í•©ì³ ìµœì¢… ì´ë¯¸ì§€ ìƒì„±

**ê¸°ì¡´ ë°©ì‹ê³¼ì˜ ì°¨ì´:**

| ë°©ì‹ | í…ìŠ¤íŠ¸ ì¡°ê±´ | ì´ë¯¸ì§€ ì¡°ê±´ | í•™ìŠµ í•„ìš” |
|------|------------|------------|-----------|
| **í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸** | âœ… | âŒ | ì—†ìŒ |
| **LoRA/DreamBooth** | âœ… | ê°„ì ‘ | **í•„ìš”** |
| **ControlNet** | âœ… | êµ¬ì¡°ë§Œ | ì—†ìŒ |
| **IP-Adapter** | âœ… | **ìŠ¤íƒ€ì¼/ë‚´ìš©** | ì—†ìŒ |

### ê°œë… 2: Decoupled Cross-Attention â€” ë¶„ë¦¬ëœ ì–´í…ì…˜

> ğŸ’¡ **ë¹„ìœ **: ê¸°ì¡´ SDì˜ Cross-Attentionì´ **í•œ ê·€ë¡œë§Œ ë“£ëŠ”** ê²ƒì´ë¼ë©´, IP-AdapterëŠ” **ì–‘ìª½ ê·€ë¡œ ë”°ë¡œ ë“£ëŠ”** ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤. ì˜¤ë¥¸ìª½ ê·€(í…ìŠ¤íŠ¸)ì™€ ì™¼ìª½ ê·€(ì´ë¯¸ì§€)ê°€ ê°ì ì •ë³´ë¥¼ ë°›ì•„ë“¤ì´ê³ , ë‡Œì—ì„œ í•©ì³ì„œ ì´í•´í•˜ì£ .

ê¸°ì¡´ SDì˜ Cross-Attention:
> í…ìŠ¤íŠ¸ ì„ë² ë”© â†’ Cross-Attention â†’ U-Net

IP-Adapterì˜ Decoupled Cross-Attention:
> í…ìŠ¤íŠ¸ ì„ë² ë”© â†’ Cross-Attention (Text) â”€â”
>                                          â”œâ†’ ê²°í•© â†’ U-Net
> ì´ë¯¸ì§€ ì„ë² ë”© â†’ Cross-Attention (Image) â”€â”˜

**êµ¬ì²´ì ì¸ ì•„í‚¤í…ì²˜:**

| êµ¬ì„± ìš”ì†Œ | ì—­í•  | íŒŒë¼ë¯¸í„° |
|-----------|------|---------|
| **CLIP Image Encoder** | ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ë²¡í„°ë¡œ ë³€í™˜ | ë™ê²° (í•™ìŠµ ì•ˆ í•¨) |
| **Image Projection** | CLIP íŠ¹ì§•ì„ U-Net í˜¸í™˜ í˜•íƒœë¡œ ë³€í™˜ | **í•™ìŠµ ëŒ€ìƒ** |
| **Image Cross-Attention** | ì´ë¯¸ì§€ ì¡°ê±´ì„ U-Netì— ì£¼ì… | **í•™ìŠµ ëŒ€ìƒ** |

ì „ì²´ íŒŒë¼ë¯¸í„°: ì•½ 22M (SD 1.5ì˜ ê²½ìš°), ë§¤ìš° ê°€ë²¼ì›€!

> âš ï¸ **í”í•œ ì˜¤í•´**: "IP-AdapterëŠ” ì´ë¯¸ì§€ë¥¼ ë³µì‚¬í•œë‹¤" â€” IP-AdapterëŠ” ì´ë¯¸ì§€ë¥¼ **ë³µì‚¬**í•˜ëŠ” ê²Œ ì•„ë‹ˆë¼ **ìŠ¤íƒ€ì¼ê³¼ ì˜ë¯¸**ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. CLIP ì„ë² ë”©ì„ ê±°ì¹˜ë©´ì„œ ì´ë¯¸ì§€ì˜ "ë³¸ì§ˆ"ë§Œ ë‚¨ê³  ì„¸ë¶€ ë””í…Œì¼ì€ ì‚¬ë¼ì§‘ë‹ˆë‹¤.

### ê°œë… 3: IP-Adapter ë³€í˜•ë“¤

**1. IP-Adapter (ê¸°ë³¸)**

| íŠ¹ì§• | ì„¤ëª… |
|------|------|
| **ì¸ì½”ë”** | OpenCLIP ViT-H/14 (SD 1.5), ViT-bigG/14 (SDXL) |
| **ì¶œë ¥** | ê¸€ë¡œë²Œ ì´ë¯¸ì§€ ì„ë² ë”© |
| **ìš©ë„** | ì „ì²´ì ì¸ ìŠ¤íƒ€ì¼/ë¶„ìœ„ê¸° ì „ì´ |
| **ê°•ì ** | ê°€ë³ê³  ë¹ ë¦„ |

**2. IP-Adapter Plus**

| íŠ¹ì§• | ì„¤ëª… |
|------|------|
| **ì¸ì½”ë”** | ë™ì¼ + **íŒ¨ì¹˜ ì„ë² ë”©** ì‚¬ìš© |
| **ì¶œë ¥** | ì„¸ë¶€ ì˜ì—­ë³„ íŠ¹ì§• í¬í•¨ |
| **ìš©ë„** | ë” ì •ë°€í•œ ìŠ¤íƒ€ì¼ ì „ì´ |
| **ê°•ì ** | ì„¸ë°€í•œ ë””í…Œì¼ ë³´ì¡´ |

**3. IP-Adapter FaceID**

| íŠ¹ì§• | ì„¤ëª… |
|------|------|
| **ì¸ì½”ë”** | **InsightFace** ì–¼êµ´ ì¸ì‹ ëª¨ë¸ |
| **ì¶œë ¥** | ì–¼êµ´ ì„ë² ë”© (ì‹ ì› ì •ë³´) |
| **ìš©ë„** | ë™ì¼ ì¸ë¬¼ì˜ ë‹¤ë¥¸ ì´ë¯¸ì§€ ìƒì„± |
| **ê°•ì ** | ì–¼êµ´ ì¼ê´€ì„± ìœ ì§€ |

**IP-Adapter FaceID ë³€í˜•:**

| ë³€í˜• | íŠ¹ì§• | ì‚¬ìš© ìƒí™© |
|------|------|----------|
| **FaceID** | ê¸°ë³¸, ì–¼êµ´ ì„ë² ë”©ë§Œ | ê°„ë‹¨í•œ ì–¼êµ´ ì „ì´ |
| **FaceID-Plus** | ì–¼êµ´ + CLIP ì„ë² ë”© | ìŠ¤íƒ€ì¼ë„ í•¨ê»˜ ì „ì´ |
| **FaceID-PlusV2** | ê°œì„ ëœ í’ˆì§ˆ | ê¶Œì¥ ë²„ì „ |
| **FaceID-Portrait** | ì´ˆìƒí™” íŠ¹í™” | ì´ˆìƒí™”/í”„ë¡œí•„ ìƒì„± |

> ğŸ’¡ **ì•Œê³  ê³„ì…¨ë‚˜ìš”?** IP-Adapter FaceIDëŠ” 2023ë…„ 12ì›”ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. InsightFaceë¼ëŠ” ì–¼êµ´ ì¸ì‹ AIë¥¼ í†µí•©í•´ì„œ, [DreamBooth](./02-dreambooth.md)ì²˜ëŸ¼ í•™ìŠµí•˜ì§€ ì•Šê³ ë„ íŠ¹ì • ì¸ë¬¼ì˜ ì–¼êµ´ì„ ìœ ì§€í•œ ì±„ ë‹¤ì–‘í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆì£ .

### ê°œë… 4: IP-Adapter ê°•ë„ì™€ ì¡°í•©

**Scale (ê°•ë„ ì¡°ì ˆ)**

| ê°’ | íš¨ê³¼ |
|----|------|
| 0.0 | IP-Adapter ë¹„í™œì„±í™” |
| 0.3~0.5 | ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ì•½í•˜ê²Œ ë°˜ì˜ |
| 0.7~1.0 | ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ê°•í•˜ê²Œ ë°˜ì˜ |
| 1.0+ | ê³¼ë„í•œ ì˜í–¥, í…ìŠ¤íŠ¸ ë¬´ì‹œë  ìˆ˜ ìˆìŒ |

**í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ì™€ì˜ ì¡°í•©**

IP-Adapterì˜ í° ì¥ì ì€ **í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ì™€ í•¨ê»˜** ì‘ë™í•œë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤:

```
ì°¸ì¡° ì´ë¯¸ì§€: ê³ íì˜ ë³„ì´ ë¹›ë‚˜ëŠ” ë°¤
í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸: "a cat sitting on a chair"
ê²°ê³¼: ê³ í ìŠ¤íƒ€ì¼ë¡œ ê·¸ë ¤ì§„ ì˜ì ìœ„ì˜ ê³ ì–‘ì´
```

**ControlNetê³¼ì˜ ì¡°í•©**

IP-Adapter + ControlNetì€ ë§¤ìš° ê°•ë ¥í•œ ì¡°í•©ì…ë‹ˆë‹¤:

| ë„êµ¬ | ì—­í•  |
|------|------|
| **IP-Adapter** | ìŠ¤íƒ€ì¼/ë¶„ìœ„ê¸° ê²°ì • |
| **ControlNet** | êµ¬ì¡°/í¬ì¦ˆ ê²°ì • |
| **í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸** | ì„¸ë¶€ ë‚´ìš© ê²°ì • |

> ğŸ”¥ **ì‹¤ë¬´ íŒ**: IP-Adapter(ìŠ¤íƒ€ì¼) + OpenPose(í¬ì¦ˆ) + í…ìŠ¤íŠ¸(ë‚´ìš©)ë¥¼ ì¡°í•©í•˜ë©´, "ì´ ìŠ¤íƒ€ì¼ë¡œ, ì´ í¬ì¦ˆë¡œ, ì´ëŸ° ë‚´ìš©ì˜ ì´ë¯¸ì§€"ë¥¼ ì •ë°€í•˜ê²Œ ì œì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ê°œë… 5: ì–¸ì œ IP-Adapter vs LoRA vs DreamBooth?

| ìƒí™© | ì¶”ì²œ ë„êµ¬ | ì´ìœ  |
|------|-----------|------|
| **ì¦‰ì‹œ ìŠ¤íƒ€ì¼ ì „ì´** | **IP-Adapter** | í•™ìŠµ ë¶ˆí•„ìš”, ì¦‰ì‹œ ì‚¬ìš© |
| **ë°˜ë³µì ìœ¼ë¡œ ê°™ì€ ìŠ¤íƒ€ì¼** | **LoRA** | í•œ ë²ˆ í•™ìŠµí•˜ë©´ ê³„ì† ì‚¬ìš© |
| **íŠ¹ì • ì¸ë¬¼ (í•™ìŠµ ê°€ëŠ¥)** | **DreamBooth LoRA** | ê°€ì¥ ë†’ì€ ì¶©ì‹¤ë„ |
| **íŠ¹ì • ì¸ë¬¼ (í•™ìŠµ ë¶ˆê°€)** | **IP-Adapter FaceID** | í•™ìŠµ ì—†ì´ ì–¼êµ´ ìœ ì§€ |
| **ì¼íšŒì„± ì°¸ì¡°** | **IP-Adapter** | ê°„ë‹¨í•˜ê³  ë¹ ë¦„ |
| **í”„ë¡œë•ì…˜ ìš©** | **LoRA** | ì•ˆì •ì , ì¬í˜„ ê°€ëŠ¥ |

## ì‹¤ìŠµ: IP-Adapter ì‚¬ìš©í•˜ê¸°

### ë°©ë²• 1: ê¸°ë³¸ IP-Adapterë¡œ ìŠ¤íƒ€ì¼ ì „ì´

```python
# IP-Adapterë¡œ ìŠ¤íƒ€ì¼ ì „ì´
from diffusers import StableDiffusionPipeline
from diffusers.utils import load_image
import torch

# 1. íŒŒì´í”„ë¼ì¸ ë¡œë“œ
pipe = StableDiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16
)
pipe.to("cuda")

# 2. IP-Adapter ë¡œë“œ
pipe.load_ip_adapter(
    "h94/IP-Adapter",
    subfolder="models",
    weight_name="ip-adapter_sd15.bin"
)

# 3. ì°¸ì¡° ì´ë¯¸ì§€ ë¡œë“œ (ìŠ¤íƒ€ì¼ ì›ë³¸)
style_image = load_image("https://example.com/van_gogh.jpg")

# 4. IP-Adapter ê°•ë„ ì„¤ì •
pipe.set_ip_adapter_scale(0.7)  # 0~1 ì‚¬ì´

# 5. ì´ë¯¸ì§€ ìƒì„±
prompt = "a beautiful landscape with mountains and river"
output = pipe(
    prompt=prompt,
    ip_adapter_image=style_image,
    num_inference_steps=30,
    guidance_scale=7.5,
).images[0]

output.save("ip_adapter_style_result.png")
print("ìŠ¤íƒ€ì¼ ì „ì´ ì™„ë£Œ!")
```

### ë°©ë²• 2: IP-Adapter Plusë¡œ ë” ì •ë°€í•œ ì „ì´

```python
# IP-Adapter Plus ì‚¬ìš©
from diffusers import StableDiffusionPipeline
from transformers import CLIPVisionModelWithProjection
import torch

# 1. CLIP ì´ë¯¸ì§€ ì¸ì½”ë” ë¡œë“œ
image_encoder = CLIPVisionModelWithProjection.from_pretrained(
    "h94/IP-Adapter",
    subfolder="models/image_encoder",
    torch_dtype=torch.float16
)

# 2. íŒŒì´í”„ë¼ì¸ì— ì´ë¯¸ì§€ ì¸ì½”ë” ì¶”ê°€
pipe = StableDiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    image_encoder=image_encoder,
    torch_dtype=torch.float16
)
pipe.to("cuda")

# 3. IP-Adapter Plus ë¡œë“œ
pipe.load_ip_adapter(
    "h94/IP-Adapter",
    subfolder="models",
    weight_name="ip-adapter-plus_sd15.bin"
)

# 4. ì°¸ì¡° ì´ë¯¸ì§€ì™€ í”„ë¡¬í”„íŠ¸ë¡œ ìƒì„±
reference_image = load_image("reference_artwork.jpg")
pipe.set_ip_adapter_scale(0.8)

output = pipe(
    prompt="a portrait of a woman in a garden",
    ip_adapter_image=reference_image,
    num_inference_steps=30,
).images[0]

output.save("ip_adapter_plus_result.png")
```

### ë°©ë²• 3: IP-Adapter FaceIDë¡œ ì–¼êµ´ ì¼ê´€ì„±

```python
# IP-Adapter FaceID ì‚¬ìš© (ì–¼êµ´ ì „ì´)
from diffusers import StableDiffusionPipeline
from insightface.app import FaceAnalysis
import torch
import cv2
import numpy as np

# 1. InsightFace ì´ˆê¸°í™” (ì–¼êµ´ ì¸ì‹)
app = FaceAnalysis(
    name="buffalo_l",
    providers=['CUDAExecutionProvider', 'CPUExecutionProvider']
)
app.prepare(ctx_id=0, det_size=(640, 640))

# 2. ì°¸ì¡° ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ ì„ë² ë”© ì¶”ì¶œ
ref_image = cv2.imread("person_photo.jpg")
faces = app.get(ref_image)
faceid_embeds = torch.from_numpy(faces[0].normed_embedding).unsqueeze(0)

# 3. íŒŒì´í”„ë¼ì¸ ë¡œë“œ ë° FaceID ì–´ëŒ‘í„° ì„¤ì •
pipe = StableDiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16
)
pipe.to("cuda")

pipe.load_ip_adapter(
    "h94/IP-Adapter-FaceID",
    subfolder="",
    weight_name="ip-adapter-faceid_sd15.bin"
)

pipe.set_ip_adapter_scale(0.8)

# 4. ê°™ì€ ì–¼êµ´ë¡œ ë‹¤ì–‘í•œ ìƒí™© ìƒì„±
prompts = [
    "a person as an astronaut on the moon",
    "a person as a medieval knight",
    "a person in a futuristic city"
]

for i, prompt in enumerate(prompts):
    output = pipe(
        prompt=prompt,
        ip_adapter_image_embeds=faceid_embeds,
        num_inference_steps=30,
    ).images[0]
    output.save(f"faceid_result_{i}.png")
    print(f"ìƒì„± ì™„ë£Œ: {prompt}")
```

### ë°©ë²• 4: IP-Adapter + ControlNet ì¡°í•©

```python
# IP-Adapter(ìŠ¤íƒ€ì¼) + ControlNet(í¬ì¦ˆ) ì¡°í•©
from diffusers import (
    StableDiffusionControlNetPipeline,
    ControlNetModel
)
from controlnet_aux import OpenposeDetector
import torch

# 1. ControlNet ë¡œë“œ
controlnet = ControlNetModel.from_pretrained(
    "lllyasviel/sd-controlnet-openpose",
    torch_dtype=torch.float16
)

# 2. íŒŒì´í”„ë¼ì¸ ë¡œë“œ
pipe = StableDiffusionControlNetPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    controlnet=controlnet,
    torch_dtype=torch.float16
)
pipe.to("cuda")

# 3. IP-Adapter ë¡œë“œ
pipe.load_ip_adapter(
    "h94/IP-Adapter",
    subfolder="models",
    weight_name="ip-adapter_sd15.bin"
)

# 4. ì¡°ê±´ ì´ë¯¸ì§€ ì¤€ë¹„
# ìŠ¤íƒ€ì¼ ì°¸ì¡°
style_image = load_image("anime_style_reference.jpg")

# í¬ì¦ˆ ì°¸ì¡°
openpose = OpenposeDetector.from_pretrained("lllyasviel/ControlNet")
pose_image = openpose(load_image("dancer_pose.jpg"))

# 5. ë‘ ì¡°ê±´ì„ ì¡°í•©í•˜ì—¬ ìƒì„±
pipe.set_ip_adapter_scale(0.6)  # ìŠ¤íƒ€ì¼ ê°•ë„

output = pipe(
    prompt="a girl dancing, detailed, high quality",
    image=pose_image,              # ControlNet: í¬ì¦ˆ
    ip_adapter_image=style_image,  # IP-Adapter: ìŠ¤íƒ€ì¼
    num_inference_steps=30,
    controlnet_conditioning_scale=1.0,
).images[0]

output.save("style_pose_combined.png")
print("ìŠ¤íƒ€ì¼ + í¬ì¦ˆ ì¡°í•© ìƒì„± ì™„ë£Œ!")
```

## ë” ê¹Šì´ ì•Œì•„ë³´ê¸°

### CLIP ì„ë² ë”©ì˜ ì—­í• 

IP-Adapterê°€ ì‘ë™í•˜ëŠ” í•µì‹¬ì—ëŠ” [CLIP](../10-vision-language/02-clip.md)ì´ ìˆìŠµë‹ˆë‹¤. CLIPì€ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ **ê°™ì€ ê³µê°„**ì— ì„ë² ë”©í•˜ë„ë¡ í•™ìŠµë˜ì—ˆê¸° ë•Œë¬¸ì—, ì´ë¯¸ì§€ ì„ë² ë”©ì„ í…ìŠ¤íŠ¸ ì„ë² ë”© ìë¦¬ì— ë„£ì–´ë„ SDê°€ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**IP-Adapterê°€ ì‚¬ìš©í•˜ëŠ” CLIP ëª¨ë¸:**

| ê¸°ë³¸ ëª¨ë¸ | CLIP ì¸ì½”ë” | íŒŒë¼ë¯¸í„° |
|-----------|------------|---------|
| SD 1.5 | OpenCLIP ViT-H/14 | 632M |
| SDXL | OpenCLIP ViT-bigG/14 | 1.85B |

IP-Adapter PlusëŠ” CLIPì˜ **ê¸€ë¡œë²Œ ì„ë² ë”©**ë¿ ì•„ë‹ˆë¼ **íŒ¨ì¹˜ ì„ë² ë”©**ë„ ì‚¬ìš©í•©ë‹ˆë‹¤. íŒ¨ì¹˜ ì„ë² ë”©ì€ ì´ë¯¸ì§€ë¥¼ ê²©ìë¡œ ë‚˜ëˆ  ê° ì˜ì—­ì˜ íŠ¹ì§•ì„ ë‹´ê³  ìˆì–´ì„œ, ë” ì„¸ë°€í•œ ì •ë³´ë¥¼ ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### IP-Adapter vs ê¸°ì¡´ ì ‘ê·¼ë²•

IP-Adapter ì´ì „ì—ë„ ì´ë¯¸ì§€ë¥¼ ì¡°ê±´ìœ¼ë¡œ ì‚¬ìš©í•˜ë ¤ëŠ” ì‹œë„ê°€ ìˆì—ˆìŠµë‹ˆë‹¤:

| ì ‘ê·¼ë²• | ë°©ì‹ | ë¬¸ì œì  |
|--------|------|--------|
| **CLIP Interrogator** | ì´ë¯¸ì§€â†’í…ìŠ¤íŠ¸ ë³€í™˜ | ì •ë³´ ì†ì‹¤ ì‹¬í•¨ |
| **Image2Image** | ë…¸ì´ì¦ˆ ì‹œì‘ì  ë³€ê²½ | êµ¬ì¡°ë§Œ ìœ ì§€, ìŠ¤íƒ€ì¼ ì•½í•¨ |
| **Textual Inversion** | ìƒˆ í† í° í•™ìŠµ | í•™ìŠµ í•„ìš”, ëŠë¦¼ |
| **IP-Adapter** | ë¶„ë¦¬ëœ Cross-Attention | í•™ìŠµ ë¶ˆí•„ìš”, íš¨ê³¼ì  |

IP-Adapterì˜ í•µì‹¬ í˜ì‹ ì€ **í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ë¶„ë¦¬ëœ ê²½ë¡œë¡œ ì²˜ë¦¬**í•œë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ë‘ ì¡°ê±´ì´ ì„œë¡œ ê°„ì„­í•˜ì§€ ì•Šê³  ê°ìì˜ ì—­í• ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## í”í•œ ì˜¤í•´ì™€ íŒ

> âš ï¸ **í”í•œ ì˜¤í•´**: "IP-Adapter ê°•ë„ë¥¼ ë†’ì´ë©´ ë¬´ì¡°ê±´ ì¢‹ë‹¤" â€” ê°•ë„ê°€ ë„ˆë¬´ ë†’ìœ¼ë©´(1.0+) í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ê°€ ë¬´ì‹œë˜ê³ , ì°¸ì¡° ì´ë¯¸ì§€ë§Œ ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. ë³´í†µ 0.5~0.8ì´ ì ì ˆí•©ë‹ˆë‹¤.

> ğŸ”¥ **ì‹¤ë¬´ íŒ**: **IP-Adapter + LoRA**ë¥¼ í•¨ê»˜ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. IP-Adapterë¡œ ì°¸ì¡° ì´ë¯¸ì§€ì˜ ë¶„ìœ„ê¸°ë¥¼ ì¡ê³ , LoRAë¡œ í•™ìŠµëœ ìŠ¤íƒ€ì¼ì„ ë”í•˜ë©´ ë”ìš± ì •êµí•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆì–´ìš”.

> ğŸ’¡ **ì•Œê³  ê³„ì…¨ë‚˜ìš”?** IP-AdapterëŠ” Tencent AI Labì—ì„œ ê°œë°œí–ˆëŠ”ë°, ë…¼ë¬¸ ê³µê°œ í›„ ì»¤ë®¤ë‹ˆí‹°ê°€ ë¹ ë¥´ê²Œ ì±„íƒí•˜ì—¬ ComfyUI, AUTOMATIC1111 ë“± ì£¼ìš” UIì— ëª¨ë‘ í†µí•©ë˜ì—ˆìŠµë‹ˆë‹¤. 22M íŒŒë¼ë¯¸í„°ë¼ëŠ” ê°€ë²¼ì›€ì´ ì±„íƒì„ ê°€ì†í™”í•œ ìš”ì¸ì´ì—ˆì£ .

## í•µì‹¬ ì •ë¦¬

| ê°œë… | ì„¤ëª… |
|------|------|
| **IP-Adapter ì›ë¦¬** | ì´ë¯¸ì§€ë¥¼ CLIPìœ¼ë¡œ ì¸ì½”ë”©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ì²˜ëŸ¼ ì‚¬ìš© |
| **Decoupled Cross-Attention** | í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ì¡°ê±´ì„ ë¶„ë¦¬ëœ ì–´í…ì…˜ìœ¼ë¡œ ì²˜ë¦¬ |
| **ê¸°ë³¸ vs Plus** | ê¸°ë³¸=ê¸€ë¡œë²Œ ì„ë² ë”©, Plus=íŒ¨ì¹˜ ì„ë² ë”© ì¶”ê°€ |
| **FaceID** | InsightFaceë¡œ ì–¼êµ´ ì„ë² ë”© ì¶”ì¶œ, ì–¼êµ´ ì¼ê´€ì„± ìœ ì§€ |
| **Scale** | 0~1 ì‚¬ì´, IP-Adapter ì˜í–¥ë ¥ ì¡°ì ˆ |
| **ì¡°í•©** | ControlNet, LoRAì™€ í•¨ê»˜ ì‚¬ìš© ê°€ëŠ¥ |

## ë‹¤ìŒ ì„¹ì…˜ ë¯¸ë¦¬ë³´ê¸°

ë‹¤ìŒ [ComfyUI ì›Œí¬í”Œë¡œìš°](./05-comfyui.md)ì—ì„œëŠ” ì§€ê¸ˆê¹Œì§€ ë°°ìš´ LoRA, ControlNet, IP-Adapterë¥¼ **ë…¸ë“œ ê¸°ë°˜ UI**ì—ì„œ ììœ ë¡­ê²Œ ì¡°í•©í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤. ì½”ë“œ ì—†ì´ë„ ë³µì¡í•œ íŒŒì´í”„ë¼ì¸ì„ ì‹œê°ì ìœ¼ë¡œ êµ¬ì„±í•  ìˆ˜ ìˆì–´ìš”.

## ì°¸ê³  ìë£Œ

- [IP-Adapter: Text Compatible Image Prompt Adapter (arXiv)](https://arxiv.org/abs/2308.06721) - IP-Adapter ì›ë…¼ë¬¸
- [IP-Adapter GitHub](https://github.com/tencent-ailab/IP-Adapter) - Tencent AI Lab ê³µì‹ ì €ì¥ì†Œ
- [IP-Adapter Project Page](https://ip-adapter.github.io/) - ê³µì‹ í”„ë¡œì íŠ¸ í˜ì´ì§€
- [h94/IP-Adapter on HuggingFace](https://huggingface.co/h94/IP-Adapter) - ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
- [IP-Adapters: All you need to know - Stable Diffusion Art](https://stable-diffusion-art.com/ip-adapter/) - ì¢…í•© ê°€ì´ë“œ
- [IP-Adapter in Diffusers](https://huggingface.co/docs/diffusers/en/using-diffusers/ip_adapter) - HuggingFace ê³µì‹ ë¬¸ì„œ
