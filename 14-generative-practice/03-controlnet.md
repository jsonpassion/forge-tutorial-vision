# ControlNet

> í¬ì¦ˆ, ì—ì§€, ê¹Šì´ ê¸°ë°˜ ì œì–´

## ê°œìš”

[DreamBooth](./02-dreambooth.md)ì—ì„œ "ë¬´ì—‡ì„" ìƒì„±í• ì§€ ì •í•˜ëŠ” ê¸°ìˆ ì„ ë°°ì› ìŠµë‹ˆë‹¤. ì´ë²ˆì—ëŠ” "**ì–´ë–»ê²Œ** ìƒì„±í• ì§€"ë¥¼ ì œì–´í•˜ëŠ” **ControlNet**ì„ ë‹¤ë£¹ë‹ˆë‹¤. í¬ì¦ˆ, ìœ¤ê³½ì„ , ê¹Šì´ ë§µ ë“±ì˜ ì¡°ê±´ ì´ë¯¸ì§€ë¥¼ ì…ë ¥í•˜ë©´, ê·¸ êµ¬ì¡°ë¥¼ ì •í™•íˆ ë”°ë¥´ë©´ì„œ ìƒˆë¡œìš´ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. "ì´ í¬ì¦ˆë¡œ ì¶¤ì¶”ëŠ” ì‚¬ëŒ", "ì´ ê±´ë¬¼ ìŠ¤ì¼€ì¹˜ë¥¼ ì‚¬ì‹¤ì ì¸ ì‚¬ì§„ìœ¼ë¡œ", "ì´ ê¹Šì´ê°ì„ ìœ ì§€í•˜ë©´ì„œ ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ë¡œ" â€” ì´ëŸ° ì •ë°€í•œ ì œì–´ê°€ ê°€ëŠ¥í•´ì§‘ë‹ˆë‹¤.

**ì„ ìˆ˜ ì§€ì‹**: [SD ì•„í‚¤í…ì²˜](../13-stable-diffusion/01-sd-architecture.md), [U-Net ì•„í‚¤í…ì²˜](../12-diffusion-models/04-unet-architecture.md)
**í•™ìŠµ ëª©í‘œ**:
- ControlNetì˜ ì•„í‚¤í…ì²˜(Trainable Copy + Zero Convolution)ë¥¼ ì´í•´í•œë‹¤
- ì£¼ìš” ControlNet ëª¨ë¸ ìœ í˜•ê³¼ ìš©ë„ë¥¼ íŒŒì•…í•œë‹¤
- ë‹¤ì–‘í•œ ì œì–´ ì¡°ê±´ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìˆë‹¤
- ì—¬ëŸ¬ ControlNetì„ ì¡°í•©í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤

## ì™œ ì•Œì•„ì•¼ í• ê¹Œ?

í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë§Œìœ¼ë¡œëŠ” ì›í•˜ëŠ” êµ¬ë„ë‚˜ í¬ì¦ˆë¥¼ ì •í™•íˆ í‘œí˜„í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤. "ì˜¤ë¥¸ì†ì„ ë“¤ê³  ìˆëŠ” ì‚¬ëŒ"ì´ë¼ê³  ì¨ë„ ë§¤ë²ˆ ë‹¤ë¥¸ ê²°ê³¼ê°€ ë‚˜ì˜¤ì£ . ControlNetì€ **ì°¸ì¡° ì´ë¯¸ì§€ì˜ êµ¬ì¡°ë¥¼ ì¶”ì¶œ**í•˜ì—¬ ê·¸ëŒ€ë¡œ ë”°ë¥´ê²Œ í•©ë‹ˆë‹¤. ì¼ëŸ¬ìŠ¤íŠ¸ë ˆì´í„°, ê²Œì„ ê°œë°œì, ì˜í™” ì œì‘ì ë“± **ì •ë°€í•œ ì œì–´ê°€ í•„ìš”í•œ í¬ë¦¬ì—ì´í„°**ë“¤ì—ê²Œ í•„ìˆ˜ ë„êµ¬ì…ë‹ˆë‹¤.

## í•µì‹¬ ê°œë…

### ê°œë… 1: ControlNetì˜ í•µì‹¬ ì•„ì´ë””ì–´

> ğŸ’¡ **ë¹„ìœ **: ControlNetì€ **íˆ¬ì‚¬ì§€(íŠ¸ë ˆì´ì‹± í˜ì´í¼)**ì™€ ê°™ìŠµë‹ˆë‹¤. ë°‘ê·¸ë¦¼ ìœ„ì— íˆ¬ì‚¬ì§€ë¥¼ ì˜¬ë ¤ë†“ê³  ìƒˆ ê·¸ë¦¼ì„ ê·¸ë¦¬ë©´, êµ¬ë„ì™€ í˜•íƒœëŠ” ìœ ì§€í•˜ë©´ì„œ ìŠ¤íƒ€ì¼ë§Œ ë°”ê¿€ ìˆ˜ ìˆì–ì•„ìš”? ControlNetë„ ì¡°ê±´ ì´ë¯¸ì§€ì˜ **êµ¬ì¡°ë§Œ ì¶”ì¶œ**í•˜ì—¬ ìƒˆ ì´ë¯¸ì§€ì˜ ë¼ˆëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.

ControlNetì€ 2023ë…„ 2ì›” ìŠ¤íƒ í¬ë“œ ëŒ€í•™êµì˜ Lvmin Zhangì´ ë°œí‘œí•œ ë…¼ë¬¸ "Adding Conditional Control to Text-to-Image Diffusion Models"ì—ì„œ ì†Œê°œë˜ì—ˆìŠµë‹ˆë‹¤.

**ì‘ë™ ë°©ì‹ì˜ í•µì‹¬:**

1. **ì¡°ê±´ ì´ë¯¸ì§€ ì…ë ¥**: í¬ì¦ˆ, ì—ì§€, ê¹Šì´ ë§µ ë“±
2. **êµ¬ì¡° ì¶”ì¶œ**: ì „ì²˜ë¦¬ê¸°(Preprocessor)ê°€ ì¡°ê±´ ì •ë³´ë¥¼ ì¶”ì¶œ
3. **U-Netê³¼ ê²°í•©**: ì¶”ì¶œëœ ì¡°ê±´ì´ ë””ë…¸ì´ì§• ê³¼ì •ì„ ê°€ì´ë“œ
4. **ê²°ê³¼ ìƒì„±**: ì¡°ê±´ êµ¬ì¡°ë¥¼ ë”°ë¥´ëŠ” ìƒˆ ì´ë¯¸ì§€ ìƒì„±

**ControlNet íŒŒì´í”„ë¼ì¸:**

> ì›ë³¸ ì´ë¯¸ì§€ â†’ **ì „ì²˜ë¦¬ê¸°**(Canny/OpenPose/Depth) â†’ ì¡°ê±´ ë§µ â†’ **ControlNet** + í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ â†’ ê²°ê³¼ ì´ë¯¸ì§€

### ê°œë… 2: ì•„í‚¤í…ì²˜ â€” Trainable Copyì™€ Zero Convolution

> ğŸ’¡ **ë¹„ìœ **: ControlNetì˜ ì•„í‚¤í…ì²˜ëŠ” **ìŒë‘¥ì´ ë„¤íŠ¸ì›Œí¬**ì™€ ê°™ìŠµë‹ˆë‹¤. ì›ë³¸ U-Net(í˜•)ì€ ê·¸ëŒ€ë¡œ ë‘ê³ , ë³µì œë³¸(ë™ìƒ)ë§Œ ìƒˆë¡œìš´ ì¡°ê±´ì„ í•™ìŠµí•©ë‹ˆë‹¤. ì²˜ìŒì—ëŠ” ë™ìƒì´ ì¡°ìš©íˆ ìˆë‹¤ê°€(zero convolution), í•™ìŠµì´ ì§„í–‰ë˜ë©´ì„œ ì ì  ëª©ì†Œë¦¬ë¥¼ ë‚´ê¸° ì‹œì‘í•©ë‹ˆë‹¤.

**í•µì‹¬ êµ¬ì„± ìš”ì†Œ:**

| êµ¬ì„± ìš”ì†Œ | ì—­í•  | íŠ¹ì§• |
|-----------|------|------|
| **Locked Copy** | ì›ë³¸ SDì˜ U-Net | ê°€ì¤‘ì¹˜ ë™ê²°, ì›ë³¸ ëŠ¥ë ¥ ë³´ì¡´ |
| **Trainable Copy** | ì¡°ê±´ì„ í•™ìŠµí•˜ëŠ” ë³µì œë³¸ | ì¸ì½”ë” ë¶€ë¶„ë§Œ ë³µì œ |
| **Zero Convolution** | ë‘ ë„¤íŠ¸ì›Œí¬ ì—°ê²° | ê°€ì¤‘ì¹˜ 0ìœ¼ë¡œ ì´ˆê¸°í™” |

**Zero Convolutionì˜ ë§ˆë²•:**

Zero Convolutionì€ ê°€ì¤‘ì¹˜ì™€ í¸í–¥ì´ ëª¨ë‘ 0ìœ¼ë¡œ ì´ˆê¸°í™”ëœ 1Ã—1 ì»¨ë³¼ë£¨ì…˜ì…ë‹ˆë‹¤:

- **í•™ìŠµ ì „**: ì¶œë ¥ì´ 0 â†’ ì›ë³¸ SDì™€ ë™ì¼í•˜ê²Œ ì‘ë™
- **í•™ìŠµ ì¤‘**: ì ì§„ì ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ì¦ê°€ â†’ ì¡°ê±´ ì •ë³´ ë°˜ì˜
- **í•™ìŠµ í›„**: ì¡°ê±´ì— ë§ëŠ” ì¶œë ¥ ìƒì„±

ì´ ì„¤ê³„ ë•ë¶„ì—:
- ì›ë³¸ ëª¨ë¸ì„ **íŒŒê´´í•˜ì§€ ì•ŠìŒ**
- ì ì€ ë°ì´í„°(~50k ìŒ)ë¡œë„ ì•ˆì •ì  í•™ìŠµ
- ê¸°ì¡´ SDì˜ ëª¨ë“  ëŠ¥ë ¥ ìœ ì§€

**ì ìš© ë²”ìœ„:**

ControlNetì€ U-Netì˜ **ì¸ì½”ë” ë¸”ë¡(12ê°œ)ê³¼ ë¯¸ë“¤ ë¸”ë¡(1ê°œ)**ì— ì ìš©ë©ë‹ˆë‹¤:

> U-Net ì¸ì½”ë”: 64Ã—64 â†’ 32Ã—32 â†’ 16Ã—16 â†’ 8Ã—8
>
> ê° í•´ìƒë„ì—ì„œ ControlNetì´ ì¡°ê±´ ì •ë³´ë¥¼ ì£¼ì…

### ê°œë… 3: ì£¼ìš” ControlNet ìœ í˜•

**1. Canny Edge (ì—ì§€ ê²€ì¶œ)**

| íŠ¹ì§• | ì„¤ëª… |
|------|------|
| **ì…ë ¥** | ì—ì§€ê°€ ê²€ì¶œëœ í‘ë°± ì´ë¯¸ì§€ |
| **ìš©ë„** | ìœ¤ê³½ì„  ìœ ì§€, ì„ í™”ë¥¼ ì‚¬ì§„ìœ¼ë¡œ ë³€í™˜ |
| **ì¥ì ** | ì„¸ë°€í•œ ë””í…Œì¼ ë³´ì¡´ |
| **ì í•©í•œ ìƒí™©** | ë¡œê³ , ë¼ì¸ì•„íŠ¸, ê±´ì¶• ìŠ¤ì¼€ì¹˜ |

**2. OpenPose (í¬ì¦ˆ ê²€ì¶œ)**

| íŠ¹ì§• | ì„¤ëª… |
|------|------|
| **ì…ë ¥** | ì¸ì²´ ê´€ì ˆì (ìŠ¤ì¼ˆë ˆí†¤) ì´ë¯¸ì§€ |
| **ìš©ë„** | íŠ¹ì • í¬ì¦ˆë¡œ ì¸ë¬¼ ìƒì„± |
| **ë³€í˜•** | ëª¸í†µë§Œ / ì†ê°€ë½ í¬í•¨ / ì–¼êµ´ ë°©í–¥ í¬í•¨ |
| **ì í•©í•œ ìƒí™©** | ëŒ„ìŠ¤, ì•¡ì…˜, íŒ¨ì…˜ í¬ì¦ˆ |

**3. Depth (ê¹Šì´ ë§µ)**

| íŠ¹ì§• | ì„¤ëª… |
|------|------|
| **ì…ë ¥** | ê°€ê¹Œìš´ ê³³=ë°ê²Œ, ë¨¼ ê³³=ì–´ë‘¡ê²Œ í‘œí˜„í•œ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ |
| **ìš©ë„** | 3D êµ¬ì¡°ì™€ ì›ê·¼ê° ìœ ì§€ |
| **ì „ì²˜ë¦¬ê¸°** | MiDaS, Zoe, LeReS ë“± |
| **ì í•©í•œ ìƒí™©** | í’ê²½, ì‹¤ë‚´, ì œí’ˆ ì‚¬ì§„ |

**4. Segmentation (ì„¸ê·¸ë©˜í…Œì´ì…˜)**

| íŠ¹ì§• | ì„¤ëª… |
|------|------|
| **ì…ë ¥** | ì˜ì—­ë³„ë¡œ ìƒ‰ êµ¬ë¶„ëœ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§µ |
| **ìš©ë„** | ê° ì˜ì—­ì˜ ìœ„ì¹˜ì™€ í¬ê¸° ì œì–´ |
| **í”„ë¡œí† ì½œ** | ADE20k (150 í´ë˜ìŠ¤) |
| **ì í•©í•œ ìƒí™©** | ì”¬ ë ˆì´ì•„ì›ƒ, ë°°ê²½ êµì²´ |

**5. ê¸°íƒ€ ìœ í˜•**

| ìœ í˜• | ì…ë ¥ | ìš©ë„ |
|------|------|------|
| **HED/Soft Edge** | ë¶€ë“œëŸ¬ìš´ ì—ì§€ | Cannyë³´ë‹¤ ìœ ì—°í•œ ê²°ê³¼ |
| **Scribble** | ì†ìœ¼ë¡œ ê·¸ë¦° ë‚™ì„œ | ëŸ¬í”„ ìŠ¤ì¼€ì¹˜ë¥¼ ì™„ì„±ì‘ìœ¼ë¡œ |
| **Normal Map** | í‘œë©´ ë²•ì„  ë§µ | 3D í…ìŠ¤ì²˜ë§, ì¡°ëª… ì œì–´ |
| **Lineart** | ì„ í™” | ë§Œí™”/ì¼ëŸ¬ìŠ¤íŠ¸ ì»¬ëŸ¬ë§ |
| **MLSD** | ì§ì„  ê²€ì¶œ | ê±´ì¶•, ì¸í…Œë¦¬ì–´ |
| **Shuffle** | ìƒ‰ìƒ/í…ìŠ¤ì²˜ ì°¸ì¡° | ìƒ‰ê° ì „ì´ |
| **IP2P** | í¸ì§‘ ì§€ì‹œë¬¸ | InstructPix2Pix ìŠ¤íƒ€ì¼ í¸ì§‘ |

> ğŸ”¥ **ì‹¤ë¬´ íŒ**: ê°€ì¥ ë§ì´ ì‚¬ìš©í•˜ëŠ” ì¡°í•©ì€ **Canny + OpenPose**ì…ë‹ˆë‹¤. Cannyë¡œ ì „ì²´ êµ¬ë„ë¥¼ ì¡ê³ , OpenPoseë¡œ ì¸ë¬¼ í¬ì¦ˆë¥¼ ì œì–´í•˜ë©´ ëŒ€ë¶€ë¶„ì˜ ìƒí™©ì„ ì»¤ë²„í•  ìˆ˜ ìˆì–´ìš”.

### ê°œë… 4: ControlNet ê°•ë„ì™€ ì¡°í•©

**Conditioning Scale (ì œì–´ ê°•ë„)**

ControlNetì˜ ì˜í–¥ë ¥ì„ ì¡°ì ˆí•˜ëŠ” íŒŒë¼ë¯¸í„°ì…ë‹ˆë‹¤:

| ê°’ | íš¨ê³¼ |
|----|------|
| 0.0 | ControlNet ë¬´ì‹œ (ì¼ë°˜ SD) |
| 0.5~0.7 | ì¡°ê±´ì„ ì°¸ê³ í•˜ë˜ ììœ ë„ ìœ ì§€ |
| 1.0 | ì¡°ê±´ì„ ì •í™•íˆ ë”°ë¦„ (ê¸°ë³¸ê°’) |
| 1.5+ | ê³¼ë„í•œ ì œì–´, ì•„í‹°íŒ©íŠ¸ ê°€ëŠ¥ |

**ë‹¤ì¤‘ ControlNet ì¡°í•©**

ì—¬ëŸ¬ ControlNetì„ ë™ì‹œì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```
Canny (0.7) + OpenPose (1.0) + Depth (0.5)
= ìœ¤ê³½ì„  ì°¸ê³  + í¬ì¦ˆ ì—„ê²© ì¤€ìˆ˜ + ê¹Šì´ê° ì•½í•˜ê²Œ ë°˜ì˜
```

> âš ï¸ **í”í•œ ì˜¤í•´**: "ì—¬ëŸ¬ ControlNetì„ ì“°ë©´ ë¬´ì¡°ê±´ ì¢‹ë‹¤" â€” ì˜¤íˆë ¤ ì¶©ëŒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, Cannyì™€ Scribbleì€ ë‘˜ ë‹¤ ìœ¤ê³½ì„ ì„ ì œì–´í•˜ë¯€ë¡œ ë™ì‹œ ì‚¬ìš© ì‹œ ê²°ê³¼ê°€ ë¶ˆì•ˆì •í•  ìˆ˜ ìˆì–´ìš”.

### ê°œë… 5: ControlNet for SDXL, SD3, FLUX

**ëª¨ë¸ë³„ ControlNet ì§€ì›:**

| ê¸°ë³¸ ëª¨ë¸ | ControlNet ì§€ì› | íŠ¹ì§• |
|-----------|----------------|------|
| **SD 1.5** | ê°€ì¥ í’ë¶€í•œ ìƒíƒœê³„ | ëª¨ë“  ìœ í˜• ì‚¬ìš© ê°€ëŠ¥ |
| **SDXL** | ì£¼ìš” ìœ í˜• ì§€ì› | ê³ í•´ìƒë„(1024) ì§€ì› |
| **SD 3.5** | 2024ë…„ 11ì›” ê³µê°œ | Blur, Canny, Depth |
| **FLUX** | ì»¤ë®¤ë‹ˆí‹° ê°œë°œ ì¤‘ | xlabs-ai ë“±ì—ì„œ ì œê³µ |

> ğŸ’¡ **ì•Œê³  ê³„ì…¨ë‚˜ìš”?** ControlNetì˜ ì €ì Lvmin Zhangì€ ìŠ¤íƒ í¬ë“œ ëŒ€í•™ì›ìƒ ì‹œì ˆ ì´ ì—°êµ¬ë¥¼ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. ë…¼ë¬¸ ê³µê°œ í›„ ë¶ˆê³¼ ëª‡ ë‹¬ ë§Œì— ì»¤ë®¤ë‹ˆí‹° í‘œì¤€ì´ ë˜ì—ˆê³ , ì´ë¯¸ì§€ ìƒì„± AIì˜ í™œìš© ë²”ìœ„ë¥¼ í¬ê²Œ ë„“í˜”ìŠµë‹ˆë‹¤.

## ì‹¤ìŠµ: ControlNet ì‚¬ìš©í•˜ê¸°

### ë°©ë²• 1: Canny Edge ControlNet

```python
# Canny ControlNetìœ¼ë¡œ ì´ë¯¸ì§€ ìƒì„±
from diffusers import (
    StableDiffusionControlNetPipeline,
    ControlNetModel,
    UniPCMultistepScheduler
)
from diffusers.utils import load_image
import torch
import cv2
import numpy as np
from PIL import Image

# 1. Canny ì—ì§€ ì¶”ì¶œ
def get_canny_edge(image, low_threshold=100, high_threshold=200):
    """PIL Imageì—ì„œ Canny ì—ì§€ ì¶”ì¶œ"""
    image_np = np.array(image)
    edges = cv2.Canny(image_np, low_threshold, high_threshold)
    edges = edges[:, :, None]
    edges = np.concatenate([edges, edges, edges], axis=2)
    return Image.fromarray(edges)

# 2. ì…ë ¥ ì´ë¯¸ì§€ ë¡œë“œ ë° ì—ì§€ ì¶”ì¶œ
input_image = load_image("https://example.com/room.jpg")
input_image = input_image.resize((512, 512))
canny_image = get_canny_edge(input_image)

# 3. ControlNet ë° íŒŒì´í”„ë¼ì¸ ë¡œë“œ
controlnet = ControlNetModel.from_pretrained(
    "lllyasviel/sd-controlnet-canny",
    torch_dtype=torch.float16
)

pipe = StableDiffusionControlNetPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    controlnet=controlnet,
    torch_dtype=torch.float16
)
pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)
pipe.to("cuda")

# 4. ì´ë¯¸ì§€ ìƒì„±
prompt = "a futuristic cyberpunk room, neon lights, highly detailed"
negative_prompt = "low quality, blurry"

output = pipe(
    prompt=prompt,
    negative_prompt=negative_prompt,
    image=canny_image,             # Canny ì—ì§€ ì¡°ê±´
    num_inference_steps=30,
    guidance_scale=7.5,
    controlnet_conditioning_scale=1.0,  # ControlNet ê°•ë„
).images[0]

output.save("canny_result.png")
print("Canny ControlNet ê²°ê³¼ ì €ì¥ ì™„ë£Œ!")
```

### ë°©ë²• 2: OpenPose ControlNet

```python
# OpenPose ControlNetìœ¼ë¡œ í¬ì¦ˆ ì œì–´
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel
from controlnet_aux import OpenposeDetector
import torch

# 1. OpenPose ì „ì²˜ë¦¬ê¸° ë¡œë“œ
openpose = OpenposeDetector.from_pretrained("lllyasviel/ControlNet")

# 2. ì…ë ¥ ì´ë¯¸ì§€ì—ì„œ í¬ì¦ˆ ì¶”ì¶œ
input_image = load_image("https://example.com/dancer.jpg")
input_image = input_image.resize((512, 768))
pose_image = openpose(input_image)

# 3. OpenPose ControlNet ë¡œë“œ
controlnet = ControlNetModel.from_pretrained(
    "lllyasviel/sd-controlnet-openpose",
    torch_dtype=torch.float16
)

pipe = StableDiffusionControlNetPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    controlnet=controlnet,
    torch_dtype=torch.float16
)
pipe.to("cuda")

# 4. ê°™ì€ í¬ì¦ˆë¡œ ë‹¤ë¥¸ ì¸ë¬¼ ìƒì„±
prompt = "a robot dancing, metallic body, studio lighting"
output = pipe(
    prompt=prompt,
    image=pose_image,
    num_inference_steps=30,
    controlnet_conditioning_scale=1.0,
).images[0]

output.save("openpose_result.png")
```

### ë°©ë²• 3: ë‹¤ì¤‘ ControlNet ì¡°í•©

```python
# Canny + Depth ë‹¤ì¤‘ ControlNet
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel
from controlnet_aux import MidasDetector
import torch

# 1. ë‘ ControlNet ë¡œë“œ
controlnet_canny = ControlNetModel.from_pretrained(
    "lllyasviel/sd-controlnet-canny",
    torch_dtype=torch.float16
)
controlnet_depth = ControlNetModel.from_pretrained(
    "lllyasviel/sd-controlnet-depth",
    torch_dtype=torch.float16
)

# 2. ë‹¤ì¤‘ ControlNet íŒŒì´í”„ë¼ì¸
pipe = StableDiffusionControlNetPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    controlnet=[controlnet_canny, controlnet_depth],  # ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬
    torch_dtype=torch.float16
)
pipe.to("cuda")

# 3. ì¡°ê±´ ì´ë¯¸ì§€ ì¤€ë¹„
midas = MidasDetector.from_pretrained("lllyasviel/ControlNet")
depth_image = midas(input_image)

# Canny ì´ë¯¸ì§€ëŠ” ì•ì„œ ì •ì˜í•œ í•¨ìˆ˜ ì‚¬ìš©
canny_image = get_canny_edge(input_image)

# 4. ë‹¤ì¤‘ ì¡°ê±´ìœ¼ë¡œ ìƒì„±
prompt = "a beautiful garden, flowers, sunlight"
output = pipe(
    prompt=prompt,
    image=[canny_image, depth_image],  # ìˆœì„œëŒ€ë¡œ ì „ë‹¬
    num_inference_steps=30,
    controlnet_conditioning_scale=[0.7, 0.5],  # ê°ê° ë‹¤ë¥¸ ê°•ë„
).images[0]

output.save("multi_controlnet_result.png")
print("ë‹¤ì¤‘ ControlNet ê²°ê³¼ ì €ì¥ ì™„ë£Œ!")
```

### ë°©ë²• 4: SDXL ControlNet

```python
# SDXLìš© ControlNet
from diffusers import (
    StableDiffusionXLControlNetPipeline,
    ControlNetModel,
    AutoencoderKL
)
import torch

# SDXL Canny ControlNet ë¡œë“œ
controlnet = ControlNetModel.from_pretrained(
    "diffusers/controlnet-canny-sdxl-1.0",
    torch_dtype=torch.float16
)

# SDXL VAE (ê¶Œì¥)
vae = AutoencoderKL.from_pretrained(
    "madebyollin/sdxl-vae-fp16-fix",
    torch_dtype=torch.float16
)

# SDXL íŒŒì´í”„ë¼ì¸
pipe = StableDiffusionXLControlNetPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0",
    controlnet=controlnet,
    vae=vae,
    torch_dtype=torch.float16
)
pipe.to("cuda")

# ê³ í•´ìƒë„ Canny ì´ë¯¸ì§€ ì¤€ë¹„
canny_image = get_canny_edge(input_image.resize((1024, 1024)))

# SDXL í’ˆì§ˆë¡œ ìƒì„±
prompt = "a masterpiece painting, oil on canvas, highly detailed"
output = pipe(
    prompt=prompt,
    image=canny_image,
    num_inference_steps=30,
    controlnet_conditioning_scale=0.8,
).images[0]

output.save("sdxl_controlnet_result.png")
```

## ë” ê¹Šì´ ì•Œì•„ë³´ê¸°

### ControlNetì˜ íƒ„ìƒ ìŠ¤í† ë¦¬

ControlNetì˜ ì €ì Lvmin Zhangì€ í¥ë¯¸ë¡œìš´ ë°°ê²½ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŠ” ì›ë˜ **ì• ë‹ˆë©”ì´ì…˜ ì œì‘ ë„êµ¬**ë¥¼ ì—°êµ¬í•˜ë˜ ì¤‘, "ì–´ë–»ê²Œ í•˜ë©´ AIê°€ ê·¸ë¦° ì´ë¯¸ì§€ë¥¼ ë” ì •ë°€í•˜ê²Œ ì œì–´í•  ìˆ˜ ìˆì„ê¹Œ?"ë¼ëŠ” ì§ˆë¬¸ì—ì„œ ControlNet ì•„ì´ë””ì–´ë¥¼ ì–»ì—ˆìŠµë‹ˆë‹¤.

ë…¼ë¬¸ì—ì„œ íŠ¹íˆ ê°•ì¡°í•œ ì ì€ **"íŒŒê´´ ì—†ëŠ” í•™ìŠµ"**ì…ë‹ˆë‹¤. Zero Convolution ë•ë¶„ì— í•™ìŠµ ì´ˆê¸°ì—ëŠ” ì›ë³¸ SDì™€ ì™„ì „íˆ ë™ì¼í•˜ê²Œ ì‘ë™í•˜ê³ , ì ì§„ì ìœ¼ë¡œ ìƒˆ ì¡°ê±´ì„ í•™ìŠµí•©ë‹ˆë‹¤. ì´ ì•„ì´ë””ì–´ê°€ ControlNetì˜ ì„±ê³µ ë¹„ê²°ì…ë‹ˆë‹¤.

### ì „ì²˜ë¦¬ê¸°(Preprocessor) ì„ íƒ ê°€ì´ë“œ

ê°™ì€ ìœ í˜•ì˜ ControlNetì´ë¼ë„ **ì „ì²˜ë¦¬ê¸°**ì— ë”°ë¼ ê²°ê³¼ê°€ ë‹¬ë¼ì§‘ë‹ˆë‹¤:

**Depth ì „ì²˜ë¦¬ê¸° ë¹„êµ:**

| ì „ì²˜ë¦¬ê¸° | íŠ¹ì§• | ê¶Œì¥ ìƒí™© |
|---------|------|-----------|
| **MiDaS** | í‘œì¤€, ì•ˆì •ì  | ì¼ë°˜ ìš©ë„ |
| **Zoe** | ë” ì •ë°€í•œ ê¹Šì´ | ì‹¤ë‚´, ì œí’ˆ |
| **LeReS** | ì ˆëŒ€ ê¹Šì´ ì¶”ì • | ì•¼ì™¸ í’ê²½ |
| **DepthAnything** | 2024ë…„ ìµœì‹ , ë²”ìš© | ëª¨ë“  ìƒí™© |

**Edge ì „ì²˜ë¦¬ê¸° ë¹„êµ:**

| ì „ì²˜ë¦¬ê¸° | íŠ¹ì§• | ê¶Œì¥ ìƒí™© |
|---------|------|-----------|
| **Canny** | ë‚ ì¹´ë¡œìš´ ì—ì§€ | ì„ ëª…í•œ ìœ¤ê³½ì„  í•„ìš” ì‹œ |
| **HED** | ë¶€ë“œëŸ¬ìš´ ì—ì§€ | ìì—°ìŠ¤ëŸ¬ìš´ ê²°ê³¼ ì›í•  ë•Œ |
| **MLSD** | ì§ì„ ë§Œ ê²€ì¶œ | ê±´ì¶•, ì¸í…Œë¦¬ì–´ |
| **PiDiNet** | Soft Edge | HEDì™€ ìœ ì‚¬, ì•½ê°„ ë‹¤ë¥¸ ê²°ê³¼ |

## í”í•œ ì˜¤í•´ì™€ íŒ

> âš ï¸ **í”í•œ ì˜¤í•´**: "ControlNet ê°•ë„ëŠ” í•­ìƒ 1.0ì´ ì¢‹ë‹¤" â€” ìƒí™©ì— ë”°ë¼ ë‹¤ë¦…ë‹ˆë‹¤. ìŠ¤ì¼€ì¹˜ë¥¼ ì°¸ê³ ë§Œ í•˜ë ¤ë©´ 0.5~0.7, ì •í™•íˆ ë”°ë¥´ë ¤ë©´ 1.0, í•˜ì§€ë§Œ ë„ˆë¬´ ë†’ìœ¼ë©´(1.5+) ì•„í‹°íŒ©íŠ¸ê°€ ìƒê¸¸ ìˆ˜ ìˆì–´ìš”.

> ğŸ”¥ **ì‹¤ë¬´ íŒ**: **ControlNet + LoRA ì¡°í•©**ì´ ë§¤ìš° íš¨ê³¼ì ì…ë‹ˆë‹¤. ControlNetìœ¼ë¡œ êµ¬ì¡°ë¥¼ ì œì–´í•˜ê³ , LoRAë¡œ ìŠ¤íƒ€ì¼ì„ ì ìš©í•˜ë©´ ì›í•˜ëŠ” ê²°ê³¼ë¥¼ ì •ë°€í•˜ê²Œ ë§Œë“¤ ìˆ˜ ìˆì–´ìš”.

> ğŸ’¡ **ì•Œê³  ê³„ì…¨ë‚˜ìš”?** ControlNet ë…¼ë¬¸ì€ arXivì— ê³µê°œëœ ì§€ í•œ ë‹¬ ë§Œì— GitHub ìŠ¤íƒ€ 1ë§Œ ê°œë¥¼ ëŒíŒŒí–ˆìŠµë‹ˆë‹¤. ì˜¤í”ˆì†ŒìŠ¤ AI ë„êµ¬ ì¤‘ì—ì„œë„ ê°€ì¥ ë¹ ë¥´ê²Œ ì±„íƒëœ ì‚¬ë¡€ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.

## í•µì‹¬ ì •ë¦¬

| ê°œë… | ì„¤ëª… |
|------|------|
| **ControlNet ì›ë¦¬** | ì¡°ê±´ ì´ë¯¸ì§€ì˜ êµ¬ì¡°ë¥¼ ë”°ë¼ ìƒˆ ì´ë¯¸ì§€ ìƒì„± |
| **Zero Convolution** | 0 ì´ˆê¸°í™”ë¡œ ì›ë³¸ ëª¨ë¸ ë³´ì¡´í•˜ë©° ì ì§„ì  í•™ìŠµ |
| **ì£¼ìš” ìœ í˜•** | Canny(ì—ì§€), OpenPose(í¬ì¦ˆ), Depth(ê¹Šì´), Seg(ë¶„í• ) |
| **Conditioning Scale** | 0.0~1.5, ControlNet ì˜í–¥ë ¥ ì¡°ì ˆ |
| **ë‹¤ì¤‘ ControlNet** | ì—¬ëŸ¬ ì¡°ê±´ì„ ë™ì‹œì— ì ìš© ê°€ëŠ¥ |
| **ì „ì²˜ë¦¬ê¸°** | ì…ë ¥ ì´ë¯¸ì§€ì—ì„œ ì¡°ê±´ ë§µ ì¶”ì¶œ |

## ë‹¤ìŒ ì„¹ì…˜ ë¯¸ë¦¬ë³´ê¸°

ë‹¤ìŒ [IP-Adapter](./04-ip-adapter.md)ì—ì„œëŠ” **ì´ë¯¸ì§€ë¥¼ í”„ë¡¬í”„íŠ¸ë¡œ ì‚¬ìš©**í•˜ëŠ” ê¸°ìˆ ì„ ë°°ì›ë‹ˆë‹¤. ControlNetì´ "êµ¬ì¡°"ë¥¼ ë”°ë¥¸ë‹¤ë©´, IP-AdapterëŠ” ì°¸ì¡° ì´ë¯¸ì§€ì˜ "ìŠ¤íƒ€ì¼"ì´ë‚˜ "ë¶„ìœ„ê¸°"ë¥¼ ì „ì´í•©ë‹ˆë‹¤. "ì´ ì‚¬ì§„ ëŠë‚Œìœ¼ë¡œ ìƒˆ ì´ë¯¸ì§€ ë§Œë“¤ì–´ì¤˜"ê°€ ê°€ëŠ¥í•´ì§‘ë‹ˆë‹¤.

## ì°¸ê³  ìë£Œ

- [Adding Conditional Control to Text-to-Image Diffusion Models (arXiv)](https://arxiv.org/abs/2302.05543) - ControlNet ì›ë…¼ë¬¸
- [ControlNet GitHub](https://github.com/lllyasviel/ControlNet) - ê³µì‹ ì €ì¥ì†Œ
- [ControlNet in Diffusers](https://huggingface.co/blog/controlnet) - HuggingFace ê³µì‹ ê°€ì´ë“œ
- [ControlNet: A Complete Guide - Stable Diffusion Art](https://stable-diffusion-art.com/controlnet/) - ì¢…í•© ê°€ì´ë“œ
- [The Ultimate Guide to ControlNet - Civitai](https://education.civitai.com/civitai-guide-to-controlnet/) - ì‹¤ì „ í™œìš© ê°€ì´ë“œ
- [ControlNet - LearnOpenCV](https://learnopencv.com/controlnet/) - ê¸°ìˆ ì  ìƒì„¸ ì„¤ëª…
