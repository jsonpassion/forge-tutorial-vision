# Text-to-3D

> DreamFusion, Zero-1-to-3

## ê°œìš”

ì´ ì„¹ì…˜ì—ì„œëŠ” **í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë§Œìœ¼ë¡œ 3D ì½˜í…ì¸ ë¥¼ ìƒì„±**í•˜ëŠ” í˜ì‹ ì ì¸ ê¸°ìˆ ì„ ë‹¤ë£¹ë‹ˆë‹¤. "A cute corgi wearing a party hat"ì´ë¼ê³  ì…ë ¥í•˜ë©´ ì‹¤ì œ 3D ëª¨ë¸ì´ ë§Œë“¤ì–´ì§€ëŠ” ë§ˆë²• ê°™ì€ ê¸°ìˆ ì´ì£ . **DreamFusion**ì˜ í•µì‹¬ì¸ **Score Distillation Sampling(SDS)**ë¶€í„° **Zero-1-to-3**ì˜ ì´ë¯¸ì§€ ê¸°ë°˜ ì ‘ê·¼ê¹Œì§€, Text-to-3Dì˜ ì›ë¦¬ì™€ ìµœì‹  ë™í–¥ì„ ì‚´í´ë´…ë‹ˆë‹¤.

**ì„ ìˆ˜ ì§€ì‹**:
- [NeRF ê¸°ì´ˆ](./01-nerf-basics.md)ì˜ ì‹ ê²½ë§ 3D í‘œí˜„
- [Diffusion ì´ë¡ ](../12-diffusion-models/01-diffusion-theory.md)ì˜ ìŠ¤ì½”ì–´ í•¨ìˆ˜ ê°œë…
- [CFG](../12-diffusion-models/05-cfg.md)ì˜ Classifier-Free Guidance

**í•™ìŠµ ëª©í‘œ**:
- Score Distillation Samplingì˜ ì›ë¦¬ ì´í•´í•˜ê¸°
- DreamFusionì˜ í•™ìŠµ ê³¼ì • íŒŒì•…í•˜ê¸°
- Image-to-3D ê¸°ë²•ë“¤ì˜ ì°¨ì´ì  ì•Œì•„ë³´ê¸°

## ì™œ ì•Œì•„ì•¼ í• ê¹Œ?

ê¸°ì¡´ 3D ì½˜í…ì¸  ì œì‘ì˜ í•œê³„:

| ê¸°ì¡´ ë°©ì‹ | Text-to-3D |
|----------|-----------|
| 3D ëª¨ë¸ë§ ê¸°ìˆ  í•„ìš” | í…ìŠ¤íŠ¸ ì…ë ¥ë§Œìœ¼ë¡œ ìƒì„± |
| ì œì‘ì— ìˆ˜ì¼~ìˆ˜ì£¼ | ìˆ˜ ë¶„~ìˆ˜ ì‹œê°„ |
| ì „ë¬¸ ì†Œí”„íŠ¸ì›¨ì–´ í•„ìš” | í”„ë¡¬í”„íŠ¸ ì‘ì„± ëŠ¥ë ¥ë§Œ |
| ì œí•œëœ ìƒìƒë ¥ | ë¬´í•œí•œ ì°½ì˜ì  í‘œí˜„ |

Text-to-3DëŠ” ê²Œì„ ì—ì…‹ ì œì‘, VR/AR ì½˜í…ì¸ , ì œí’ˆ í”„ë¡œí† íƒ€ì´í•‘, ê±´ì¶• ì‹œê°í™” ë“± **3D ì½˜í…ì¸  ë¯¼ì£¼í™”**ë¥¼ ì´ëŒê³  ìˆìŠµë‹ˆë‹¤.

## í•µì‹¬ ê°œë…

### ê°œë… 1: Score Distillation Sampling (SDS)

> ğŸ’¡ **ë¹„ìœ **: ì¡°ê°ê°€ê°€ ëŒ€ë¦¬ì„ì„ ì¡°ê°í•œë‹¤ê³  ìƒìƒí•´ë³´ì„¸ìš”. í•˜ì§€ë§Œ ì´ ì¡°ê°ê°€ëŠ” ëˆˆì´ ê°€ë ¤ì ¸ ìˆê³ , ê³ì— ìˆëŠ” **ë¹„í‰ê°€(Diffusion ëª¨ë¸)**ê°€ "ìœ„ìª½ì„ ë” ê¹ì•„" "ì—¬ê¸°ëŠ” ì¢€ ë” ì„¸ë°€í•˜ê²Œ"ë¼ê³  í”¼ë“œë°±ì„ ì¤ë‹ˆë‹¤. SDSëŠ” ì´ ë¹„í‰ê°€ì˜ í”¼ë“œë°±ì„ ìˆ˜í•™ì ìœ¼ë¡œ í‘œí˜„í•œ ê²ƒì…ë‹ˆë‹¤.

**DreamFusion(2022)**ì˜ í•µì‹¬ í˜ì‹ ì¸ SDSëŠ” 2D Diffusion ëª¨ë¸ì˜ ì§€ì‹ì„ 3D ìƒì„±ì— í™œìš©í•©ë‹ˆë‹¤.

**ë¬¸ì œ ìƒí™©:**
- 3D ë°ì´í„°ì…‹ì€ 2Dì— ë¹„í•´ ë§¤ìš° ì ìŒ
- í•˜ì§€ë§Œ ê°•ë ¥í•œ 2D Diffusion ëª¨ë¸(Stable Diffusion ë“±)ì€ ì´ë¯¸ ì¡´ì¬
- ì–´ë–»ê²Œ 2D ì§€ì‹ì„ 3D ìƒì„±ì— í™œìš©í• ê¹Œ?

**í•µì‹¬ ì•„ì´ë””ì–´:**

3D ëª¨ë¸ $\theta$ì—ì„œ ë Œë”ë§í•œ ì´ë¯¸ì§€ $x$ê°€ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ $y$ì— ë§ëŠ” "ìì—°ìŠ¤ëŸ¬ìš´" ì´ë¯¸ì§€ê°€ ë˜ë„ë¡ ìµœì í™”í•©ë‹ˆë‹¤.

**SDS ì†ì‹¤ í•¨ìˆ˜:**

$$\nabla_\theta \mathcal{L}_{SDS} = \mathbb{E}_{t, \epsilon}\left[ w(t) \left( \hat{\epsilon}_\phi(x_t; y, t) - \epsilon \right) \frac{\partial x}{\partial \theta} \right]$$

ê° ê¸°í˜¸ì˜ ì˜ë¯¸:
- $x = g(\theta)$: 3D ëª¨ë¸ $\theta$ì—ì„œ ë Œë”ë§í•œ ì´ë¯¸ì§€
- $x_t$: ë…¸ì´ì¦ˆ ë ˆë²¨ $t$ì—ì„œì˜ ë…¸ì´ì¦ˆ ì¶”ê°€ëœ ì´ë¯¸ì§€
- $\hat{\epsilon}_\phi$: ì‚¬ì „ í•™ìŠµëœ Diffusion ëª¨ë¸ì˜ ë…¸ì´ì¦ˆ ì˜ˆì¸¡
- $\epsilon$: ì‹¤ì œ ì¶”ê°€ëœ ë…¸ì´ì¦ˆ
- $w(t)$: ì‹œê°„ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜

**ì§ê´€ì  ì´í•´:**

1. 3D ëª¨ë¸ì—ì„œ ì´ë¯¸ì§€ ë Œë”ë§
2. ì´ë¯¸ì§€ì— ëœë¤ ë…¸ì´ì¦ˆ ì¶”ê°€
3. Diffusion ëª¨ë¸ì—ê²Œ "ì´ ì´ë¯¸ì§€ê°€ í”„ë¡¬í”„íŠ¸ì— ë§ë‚˜ìš”?" ë¬¼ì–´ë´„
4. ëª¨ë¸ì˜ í”¼ë“œë°±(ë…¸ì´ì¦ˆ ì˜ˆì¸¡ ì°¨ì´)ì„ 3D ëª¨ë¸ë¡œ ì—­ì „íŒŒ
5. ë°˜ë³µí•˜ì—¬ 3D ëª¨ë¸ ê°œì„ 

### ê°œë… 2: DreamFusion íŒŒì´í”„ë¼ì¸

> ğŸ’¡ **ë¹„ìœ **: DreamFusionì€ **360ë„ íšŒì „í•˜ëŠ” ì¡°ê° ì‹¬ì‚¬**ì™€ ê°™ìŠµë‹ˆë‹¤. ë¬´ì‘ìœ„ ê°ë„ì—ì„œ ì‚¬ì§„ì„ ì°ê³ , ê° ì‚¬ì§„ì´ í”„ë¡¬í”„íŠ¸ì— ë§ëŠ”ì§€ í‰ê°€ë°›ì•„ ì¡°ê°ì„ ìˆ˜ì •í•©ë‹ˆë‹¤. ëª¨ë“  ê°ë„ì—ì„œ ì¢‹ì€ í‰ê°€ë¥¼ ë°›ìœ¼ë©´ ì™„ì„±ì…ë‹ˆë‹¤.

**DreamFusion êµ¬ì¡°:**

1. **3D í‘œí˜„**: NeRF (MLPë¡œ ì•”ì‹œì  í‘œí˜„)
2. **ë Œë”ëŸ¬**: ë³¼ë¥¨ ë Œë”ë§
3. **2D Prior**: Imagen (Google) ë˜ëŠ” Stable Diffusion
4. **ìµœì í™”**: SDS ì†ì‹¤ë¡œ NeRF íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸

**í•™ìŠµ ê³¼ì •:**

```
ë°˜ë³µ:
    1. ëœë¤ ì¹´ë©”ë¼ ì‹œì  ìƒ˜í”Œë§
    2. í•´ë‹¹ ì‹œì ì—ì„œ NeRF ë Œë”ë§ â†’ ì´ë¯¸ì§€ x
    3. ëœë¤ ë…¸ì´ì¦ˆ ë ˆë²¨ t ì„ íƒ
    4. xì— ë…¸ì´ì¦ˆ ì¶”ê°€ â†’ x_t
    5. Diffusion ëª¨ë¸ë¡œ ë…¸ì´ì¦ˆ ì˜ˆì¸¡
    6. SDS ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°
    7. NeRF íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
```

**ì¶”ê°€ ê¸°ë²•ë“¤:**

- **Shading**: ì¡°ëª… íš¨ê³¼ë¡œ ê¸°í•˜í•™ í•™ìŠµ ê°œì„ 
- **View-dependent prompting**: "front view of...", "side view of..." ë“±
- **Coarse-to-fine**: ì €í•´ìƒë„ì—ì„œ ê³ í•´ìƒë„ë¡œ ì ì§„ì  í•™ìŠµ

### ê°œë… 3: Zero-1-to-3 - ì´ë¯¸ì§€ì—ì„œ 3Dë¡œ

> ğŸ’¡ **ë¹„ìœ **: ì‚¬ì§„ í•œ ì¥ë§Œ ë³´ê³  ë’·ëª¨ìŠµì„ ìƒìƒí•´ë³´ì„¸ìš”. ì‚¬ëŒì€ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ë’·ëª¨ìŠµì„ ì¶”ì¸¡í•©ë‹ˆë‹¤. Zero-1-to-3ëŠ” ìˆ˜ë°±ë§Œ ì¥ì˜ 3D ë°ì´í„°ë¡œ í•™ìŠµí•´ì„œ **ë‹¨ì¼ ì´ë¯¸ì§€ì˜ ë‹¤ë¥¸ ê°ë„ë¥¼ ìƒìƒ**í•©ë‹ˆë‹¤.

**Zero-1-to-3(2023)**ëŠ” ë‹¨ì¼ ì´ë¯¸ì§€ì—ì„œ ë‹¤ë¥¸ ì‹œì ì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

**í•µì‹¬ ì•„ì´ë””ì–´:**

Stable Diffusionì„ fine-tuneí•˜ì—¬:
- **ì…ë ¥**: ì°¸ì¡° ì´ë¯¸ì§€ + ì›í•˜ëŠ” ì¹´ë©”ë¼ ë³€í™˜
- **ì¶œë ¥**: ë³€í™˜ëœ ì‹œì ì—ì„œì˜ ì´ë¯¸ì§€

**ì¹´ë©”ë¼ ì¡°ê±´í™”:**

ìƒëŒ€ì  ì¹´ë©”ë¼ ë³€í™˜ $(\Delta\theta, \Delta\phi, \Delta r)$ì„ ì¡°ê±´ìœ¼ë¡œ ì œê³µ:
- $\Delta\theta$: ë°©ìœ„ê° ë³€í™”
- $\Delta\phi$: ê³ ë„ê° ë³€í™”
- $\Delta r$: ê±°ë¦¬ ë³€í™” (ì¤Œ)

**3D ì¬êµ¬ì„±:**

Zero-1-to-3ë¡œ ì—¬ëŸ¬ ê°ë„ ì´ë¯¸ì§€ ìƒì„± â†’ NeRF/3DGSë¡œ 3D ë³µì›

### ê°œë… 4: SDSì˜ ë³€í˜•ë“¤

ì›ë³¸ SDSì—ëŠ” ëª‡ ê°€ì§€ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤:

**ë¬¸ì œì :**
1. **Over-saturation**: ìƒ‰ì´ ê³¼í¬í™”ë¨
2. **Over-smoothing**: ë””í…Œì¼ì´ ë­‰ê°œì§
3. **Janus problem**: ì—¬ëŸ¬ ì–¼êµ´ì´ ìƒê¸°ëŠ” í˜„ìƒ

**ê°œì„ ëœ ë³€í˜•ë“¤:**

**VSD (Variational Score Distillation, ProlificDreamer):**

NeRFë¥¼ ë¶„í¬ë¡œ ëª¨ë¸ë§í•˜ì—¬ ë” ë‹¤ì–‘í•˜ê³  ë””í…Œì¼í•œ ê²°ê³¼:

$$\nabla_\theta \mathcal{L}_{VSD} = \mathbb{E}\left[ w(t) \left( \hat{\epsilon}_\phi(x_t; y, t) - \hat{\epsilon}_\psi(x_t; y, t) \right) \frac{\partial x}{\partial \theta} \right]$$

ì—¬ê¸°ì„œ $\hat{\epsilon}_\psi$ëŠ” NeRFì— ë§ì¶° fine-tuneëœ LoRA Diffusion ëª¨ë¸ì…ë‹ˆë‹¤.

**ISM (Interval Score Matching):**

ë‘ ë…¸ì´ì¦ˆ ë ˆë²¨ ì‚¬ì´ì˜ ì¼ê´€ì„± í™œìš©:

$$\mathcal{L}_{ISM} = \|D(x_{t_1}) - D(x_{t_2})\|$$

**CSD (Classifier Score Distillation):**

CFGì˜ classifier ë¶€ë¶„ë§Œ ì‚¬ìš©í•˜ì—¬ ë” ì•ˆì •ì ì¸ í•™ìŠµ.

### ê°œë… 5: ìµœì‹  Text-to-3D ëª¨ë¸ë“¤

**2024-2025ë…„ ì£¼ìš” ë°œì „:**

| ëª¨ë¸ | íŠ¹ì§• | ìƒì„± ì‹œê°„ |
|------|------|----------|
| DreamFusion | ì›ì¡° SDS | ~1.5ì‹œê°„ |
| Magic3D | 2ë‹¨ê³„ (coarseâ†’fine) | ~40ë¶„ |
| Fantasia3D | ë¶„ë¦¬ëœ geometry/appearance | ~30ë¶„ |
| ProlificDreamer | VSDë¡œ ê³ í’ˆì§ˆ | ~10ì‹œê°„ |
| DreamGaussian | 3DGS ê¸°ë°˜ | ~2ë¶„! |
| LGM (2024) | Feed-forward ìƒì„± | ~5ì´ˆ! |
| Instant3D | Triplane + feed-forward | ìˆ˜ ì´ˆ |

**Feed-forward ë°©ì‹ì˜ ë“±ì¥:**

ìµœê·¼ì—ëŠ” ìµœì í™” ì—†ì´ ë‹¨ì¼ forward passë¡œ 3D ìƒì„±:
- **ì…ë ¥**: ì´ë¯¸ì§€ ë˜ëŠ” í…ìŠ¤íŠ¸
- **ì¶œë ¥**: 3D í‘œí˜„ (triplane, 3DGS ë“±)
- **ì¥ì **: ì´ˆê³ ì† (ìˆ˜ ì´ˆ), ì¼ê´€ëœ í’ˆì§ˆ

### ê°œë… 6: Threestudio - í†µí•© í”„ë ˆì„ì›Œí¬

**Threestudio**ëŠ” ë‹¤ì–‘í•œ Text-to-3D ë°©ë²•ì„ í†µí•©í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤:

**ì§€ì›í•˜ëŠ” ë°©ë²•ë“¤:**
- DreamFusion (SDS)
- Magic3D
- ProlificDreamer (VSD)
- Zero-1-to-3
- DreamGaussian

**ì§€ì›í•˜ëŠ” 3D í‘œí˜„:**
- NeRF
- DMTet (ë©”ì‰¬)
- 3D Gaussian Splatting

## ì‹¤ìŠµ: Text-to-3D ì½”ë“œ êµ¬í˜„

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from diffusers import StableDiffusionPipeline
import numpy as np

class ScoreDistillationSampling:
    """
    Score Distillation Sampling (SDS) êµ¬í˜„

    ì‚¬ì „ í•™ìŠµëœ Diffusion ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ 3D ëª¨ë¸ ìµœì í™”
    """
    def __init__(
        self,
        model_id: str = "stabilityai/stable-diffusion-2-1-base",
        device: str = "cuda",
        guidance_scale: float = 100.0,
        grad_scale: float = 1.0
    ):
        self.device = device
        self.guidance_scale = guidance_scale
        self.grad_scale = grad_scale

        # Stable Diffusion ë¡œë“œ
        self.pipe = StableDiffusionPipeline.from_pretrained(
            model_id,
            torch_dtype=torch.float16
        ).to(device)

        # í•„ìš”í•œ ì»´í¬ë„ŒíŠ¸ ì¶”ì¶œ
        self.unet = self.pipe.unet
        self.vae = self.pipe.vae
        self.text_encoder = self.pipe.text_encoder
        self.tokenizer = self.pipe.tokenizer
        self.scheduler = self.pipe.scheduler

        # Freeze ëª¨ë¸
        for param in self.unet.parameters():
            param.requires_grad = False
        for param in self.vae.parameters():
            param.requires_grad = False

        # ë…¸ì´ì¦ˆ ìŠ¤ì¼€ì¤„
        self.num_train_timesteps = self.scheduler.config.num_train_timesteps
        self.min_step = int(self.num_train_timesteps * 0.02)  # t_min
        self.max_step = int(self.num_train_timesteps * 0.98)  # t_max

    def encode_text(self, prompt: str):
        """í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        # Tokenize
        tokens = self.tokenizer(
            prompt,
            padding="max_length",
            max_length=self.tokenizer.model_max_length,
            truncation=True,
            return_tensors="pt"
        )

        # Encode
        with torch.no_grad():
            text_embeddings = self.text_encoder(tokens.input_ids.to(self.device))[0]

        # Unconditional embedding (CFGìš©)
        uncond_tokens = self.tokenizer(
            "",
            padding="max_length",
            max_length=self.tokenizer.model_max_length,
            return_tensors="pt"
        )
        with torch.no_grad():
            uncond_embeddings = self.text_encoder(uncond_tokens.input_ids.to(self.device))[0]

        # [uncond, cond] ê²°í•©
        text_embeddings = torch.cat([uncond_embeddings, text_embeddings])
        return text_embeddings

    def compute_sds_loss(
        self,
        rendered_images: torch.Tensor,  # (B, 3, H, W) [0, 1] ë²”ìœ„
        text_embeddings: torch.Tensor
    ):
        """
        SDS ì†ì‹¤ ê³„ì‚°

        Args:
            rendered_images: 3D ëª¨ë¸ì—ì„œ ë Œë”ë§ëœ ì´ë¯¸ì§€
            text_embeddings: ì¸ì½”ë”©ëœ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸

        Returns:
            SDS ê·¸ë˜ë””ì–¸íŠ¸
        """
        batch_size = rendered_images.shape[0]

        # ì´ë¯¸ì§€ë¥¼ latent spaceë¡œ ì¸ì½”ë”©
        # [0, 1] â†’ [-1, 1]
        images = 2 * rendered_images - 1
        images = images.half()

        with torch.no_grad():
            latents = self.vae.encode(images).latent_dist.sample()
            latents = latents * self.vae.config.scaling_factor

        # ëœë¤ íƒ€ì„ìŠ¤í… ìƒ˜í”Œë§
        t = torch.randint(
            self.min_step, self.max_step,
            (batch_size,),
            device=self.device
        )

        # ë…¸ì´ì¦ˆ ì¶”ê°€
        noise = torch.randn_like(latents)
        noisy_latents = self.scheduler.add_noise(latents, noise, t)

        # CFGë¥¼ ìœ„í•´ latent ë³µì œ
        latent_model_input = torch.cat([noisy_latents] * 2)
        t_input = torch.cat([t] * 2)

        # U-Netìœ¼ë¡œ ë…¸ì´ì¦ˆ ì˜ˆì¸¡
        with torch.no_grad():
            noise_pred = self.unet(
                latent_model_input,
                t_input,
                encoder_hidden_states=text_embeddings
            ).sample

        # CFG ì ìš©
        noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)
        noise_pred = noise_pred_uncond + self.guidance_scale * (
            noise_pred_text - noise_pred_uncond
        )

        # SDS ê·¸ë˜ë””ì–¸íŠ¸: (ì˜ˆì¸¡ ë…¸ì´ì¦ˆ - ì‹¤ì œ ë…¸ì´ì¦ˆ)
        # ì´ê²ƒì„ latentì— ëŒ€í•œ ê·¸ë˜ë””ì–¸íŠ¸ë¡œ ì‚¬ìš©
        w = (1 - self.scheduler.alphas_cumprod[t]).view(-1, 1, 1, 1)
        grad = w * (noise_pred - noise)

        # ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ì´ë¯¸ì§€ì— ì—­ì „íŒŒí•˜ê¸° ìœ„í•´ íƒ€ê¹ƒ ì„¤ì •
        target = (latents - grad).detach()

        # MSE ì†ì‹¤ (ê·¸ë˜ë””ì–¸íŠ¸ íë¦„ìš©)
        loss = 0.5 * F.mse_loss(latents, target, reduction='sum') / batch_size
        loss = loss * self.grad_scale

        return loss


# ê°„ë‹¨í•œ NeRF + SDS í•™ìŠµ ì˜ˆì‹œ
class SimpleNeRF(nn.Module):
    """ê°„ëµí™”ëœ NeRF ëª¨ë¸ (DreamFusion ìŠ¤íƒ€ì¼)"""
    def __init__(self, hidden_dim=64):
        super().__init__()
        # Hash encoding ëŒ€ì‹  ê°„ë‹¨í•œ MLP
        self.mlp = nn.Sequential(
            nn.Linear(63, hidden_dim),  # í¬ì§€ì…”ë„ ì¸ì½”ë”©ëœ ì…ë ¥
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
        )
        self.density_head = nn.Linear(hidden_dim, 1)
        self.color_head = nn.Sequential(
            nn.Linear(hidden_dim + 27, hidden_dim),  # + ë°©í–¥ ì¸ì½”ë”©
            nn.ReLU(),
            nn.Linear(hidden_dim, 3),
            nn.Sigmoid()
        )

    def forward(self, pos_encoded, dir_encoded):
        h = self.mlp(pos_encoded)
        density = F.softplus(self.density_head(h))
        color = self.color_head(torch.cat([h, dir_encoded], dim=-1))
        return color, density


# í•™ìŠµ ë£¨í”„ ì˜ˆì‹œ (ì˜ì‚¬ ì½”ë“œ)
"""
# ì´ˆê¸°í™”
sds = ScoreDistillationSampling()
nerf = SimpleNeRF().cuda()
optimizer = torch.optim.Adam(nerf.parameters(), lr=1e-3)

prompt = "a DSLR photo of a cute corgi puppy"
text_embeddings = sds.encode_text(prompt)

# í•™ìŠµ ë£¨í”„
for step in range(10000):
    # ëœë¤ ì¹´ë©”ë¼ ì‹œì 
    camera = sample_random_camera()

    # NeRF ë Œë”ë§
    rendered = render_nerf(nerf, camera)  # (1, 3, 64, 64)

    # SDS ì†ì‹¤ ê³„ì‚°
    loss = sds.compute_sds_loss(rendered, text_embeddings)

    # ì—­ì „íŒŒ
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    if step % 100 == 0:
        print(f"Step {step}, Loss: {loss.item():.4f}")
"""
```

```bash
# Threestudioë¥¼ ì‚¬ìš©í•œ Text-to-3D

# 1. ì„¤ì¹˜
git clone https://github.com/threestudio-project/threestudio.git
cd threestudio
pip install -r requirements.txt

# 2. DreamFusion ìŠ¤íƒ€ì¼ í•™ìŠµ
python launch.py --config configs/dreamfusion-sd.yaml \
    --train \
    system.prompt_processor.prompt="a zoomed out DSLR photo of a baby bunny sitting on top of a stack of pancakes"

# 3. Magic3D ìŠ¤íƒ€ì¼ (2ë‹¨ê³„)
# Coarse stage (NeRF)
python launch.py --config configs/magic3d-coarse-sd.yaml \
    --train \
    system.prompt_processor.prompt="a DSLR photo of an ice cream sundae"

# Fine stage (DMTet mesh)
python launch.py --config configs/magic3d-refine-sd.yaml \
    --train \
    system.prompt_processor.prompt="a DSLR photo of an ice cream sundae" \
    system.geometry_convert_from=path/to/coarse/ckpt

# 4. Zero-1-to-3 (ì´ë¯¸ì§€ â†’ 3D)
python launch.py --config configs/zero123.yaml \
    --train \
    data.image_path=./your_image.png

# 5. DreamGaussian (ë¹ ë¥¸ 3DGS ê¸°ë°˜)
# ë³„ë„ ì €ì¥ì†Œ ì‚¬ìš©
git clone https://github.com/dreamgaussian/dreamgaussian.git
cd dreamgaussian
python main.py --config configs/text.yaml prompt="a hamburger"
```

```python
# Zero-1-to-3 ìŠ¤íƒ€ì¼ Novel View Synthesis
import torch
from diffusers import DiffusionPipeline
from PIL import Image
import numpy as np

def generate_novel_view(
    image_path: str,
    delta_azimuth: float = 30.0,  # ë°©ìœ„ê° ë³€í™” (ë„)
    delta_elevation: float = 0.0,  # ê³ ë„ê° ë³€í™”
    delta_radius: float = 0.0      # ê±°ë¦¬ ë³€í™”
):
    """
    Zero-1-to-3ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ ì‹œì  ì´ë¯¸ì§€ ìƒì„±

    Args:
        image_path: ì…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œ
        delta_azimuth: ë°©ìœ„ê° ë³€í™” (-180 ~ 180)
        delta_elevation: ê³ ë„ê° ë³€í™” (-90 ~ 90)
        delta_radius: ê±°ë¦¬ ë³€í™” (ìŒìˆ˜: ê°€ê¹Œì´, ì–‘ìˆ˜: ë©€ë¦¬)
    """
    # ëª¨ë¸ ë¡œë“œ (ì‹¤ì œë¡œëŠ” Zero123 ëª¨ë¸)
    # ì—¬ê¸°ì„œëŠ” ê°œë… ì„¤ëª…ìš© ì˜ì‚¬ ì½”ë“œ
    """
    pipe = DiffusionPipeline.from_pretrained(
        "bennyguo/zero123-xl-diffusers",
        torch_dtype=torch.float16
    ).to("cuda")

    # ì…ë ¥ ì´ë¯¸ì§€ ë¡œë“œ
    input_image = Image.open(image_path).convert("RGB")
    input_image = input_image.resize((256, 256))

    # ì¹´ë©”ë¼ ë³€í™˜ ì¡°ê±´
    # ì‹¤ì œ Zero123ëŠ” ë¼ë””ì•ˆ ë‹¨ìœ„ ì‚¬ìš©
    azimuth_rad = np.deg2rad(delta_azimuth)
    elevation_rad = np.deg2rad(delta_elevation)

    # ìƒì„±
    output = pipe(
        input_image,
        azimuth=azimuth_rad,
        elevation=elevation_rad,
        radius=delta_radius,
        num_inference_steps=50,
        guidance_scale=3.0
    ).images[0]

    return output
    """
    pass


# Multi-view ìƒì„± í›„ 3D ë³µì› íŒŒì´í”„ë¼ì¸
def text_to_3d_via_multiview(prompt: str, num_views: int = 8):
    """
    Text â†’ Multi-view images â†’ 3D ë³µì› íŒŒì´í”„ë¼ì¸

    1. Text-to-Imageë¡œ ì •ë©´ ì´ë¯¸ì§€ ìƒì„±
    2. Zero-1-to-3ë¡œ ì—¬ëŸ¬ ê°ë„ ì´ë¯¸ì§€ ìƒì„±
    3. 3DGS ë˜ëŠ” NeRFë¡œ 3D ë³µì›
    """
    pass  # êµ¬í˜„ ìƒëµ


# LGM (Large Gaussian Model) ìŠ¤íƒ€ì¼ Feed-forward 3D ìƒì„±
class FeedForward3DGenerator(nn.Module):
    """
    ì´ë¯¸ì§€ì—ì„œ ì§ì ‘ 3DGS íŒŒë¼ë¯¸í„°ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸

    ìµœì í™” ì—†ì´ ë‹¨ì¼ forward passë¡œ 3D ìƒì„±
    """
    def __init__(self, num_gaussians: int = 10000):
        super().__init__()
        self.num_gaussians = num_gaussians

        # ì´ë¯¸ì§€ ì¸ì½”ë” (ì˜ˆ: DINOv2)
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 64, 7, stride=2, padding=3),
            nn.ReLU(),
            nn.Conv2d(64, 128, 3, stride=2, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 256, 3, stride=2, padding=1),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d((8, 8))
        )

        # Transformerë¡œ ê°€ìš°ì‹œì•ˆ íŒŒë¼ë¯¸í„° ì˜ˆì¸¡
        self.gaussian_decoder = nn.Sequential(
            nn.Linear(256 * 64, 1024),
            nn.ReLU(),
            nn.Linear(1024, num_gaussians * 14)  # 3(pos) + 3(scale) + 4(rot) + 1(opacity) + 3(color)
        )

    def forward(self, images: torch.Tensor):
        """
        Args:
            images: (B, V, 3, H, W) ë©€í‹°ë·° ì´ë¯¸ì§€

        Returns:
            ê°€ìš°ì‹œì•ˆ íŒŒë¼ë¯¸í„°ë“¤
        """
        B, V = images.shape[:2]

        # ê° ë·° ì¸ì½”ë”©
        features = []
        for v in range(V):
            feat = self.encoder(images[:, v])
            features.append(feat.flatten(1))

        # ë·° íŠ¹ì§• ê²°í•©
        combined = torch.stack(features, dim=1).mean(dim=1)

        # ê°€ìš°ì‹œì•ˆ íŒŒë¼ë¯¸í„° ì˜ˆì¸¡
        params = self.gaussian_decoder(combined)
        params = params.view(B, self.num_gaussians, 14)

        return {
            'positions': params[..., :3],
            'scales': torch.exp(params[..., 3:6]),
            'rotations': F.normalize(params[..., 6:10], dim=-1),
            'opacities': torch.sigmoid(params[..., 10:11]),
            'colors': torch.sigmoid(params[..., 11:14])
        }


print("Text-to-3D ì˜ˆì‹œ ì½”ë“œ ë¡œë“œ ì™„ë£Œ")
```

## ë” ê¹Šì´ ì•Œì•„ë³´ê¸°

### DreamFusionì˜ íƒ„ìƒ ìŠ¤í† ë¦¬

DreamFusionì€ 2022ë…„ Google Researchì—ì„œ ë°œí‘œë˜ì—ˆìŠµë‹ˆë‹¤. í•µì‹¬ ì•„ì´ë””ì–´ì¸ **Score Distillation Sampling**ì€ ì‚¬ì‹¤ ê¸°ì¡´ì˜ **classifier guidance**ì™€ **knowledge distillation**ì„ ì°½ì˜ì ìœ¼ë¡œ ê²°í•©í•œ ê²ƒì…ë‹ˆë‹¤.

> ğŸ’¡ **ì•Œê³  ê³„ì…¨ë‚˜ìš”?**: DreamFusion ë…¼ë¬¸ì€ ì²˜ìŒì— arXivì— ê³µê°œë˜ì—ˆì„ ë•Œ ì½”ë“œ ê³µê°œ ì—†ì´ ê²°ê³¼ë¬¼ë§Œ ë³´ì—¬ì¤¬ëŠ”ë°, ë¶ˆê³¼ ë©°ì¹  ë§Œì— ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ì¬í˜„ ì½”ë“œë“¤ì´ ìŸì•„ì¡ŒìŠµë‹ˆë‹¤. stable-dreamfusion, threestudio ë“±ì´ ê·¸ ê²°ê³¼ë¬¼ì´ì£ !

### Janus Problem (ì•¼ëˆ„ìŠ¤ ë¬¸ì œ)

Text-to-3Dì˜ ëŒ€í‘œì ì¸ ì‹¤íŒ¨ ëª¨ë“œì…ë‹ˆë‹¤:

**ì¦ìƒ:**
- "a dog"ë¥¼ ìƒì„±í•˜ë©´ ì•/ë’¤ ëª¨ë‘ ì–¼êµ´ì´ ìˆìŒ
- ì—¬ëŸ¬ ë°©í–¥ì—ì„œ ë´ë„ ì •ë©´ì²˜ëŸ¼ ë³´ì´ëŠ” ê¸°í˜•ì ì¸ ê²°ê³¼

**ì›ì¸:**
- 2D Diffusion ëª¨ë¸ì€ ëŒ€ë¶€ë¶„ ì •ë©´ ì´ë¯¸ì§€ë¡œ í•™ìŠµë¨
- SDSê°€ ëª¨ë“  ë°©í–¥ì—ì„œ "ì¢‹ì•„ ë³´ì´ëŠ”" ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ë ¤ë‹¤ ë³´ë‹ˆ ë°œìƒ

**í•´ê²°ì±…:**
1. **View-dependent prompting**: "back view of a dog", "side view of a dog" ì‚¬ìš©
2. **3D-aware prior**: 3D ë°ì´í„°ë¡œ fine-tuneëœ ëª¨ë¸ ì‚¬ìš©
3. **Geometry regularization**: í•©ë¦¬ì ì¸ ê¸°í•˜í•™ ì œì•½ ì¶”ê°€

### ìµœê·¼ ì—°êµ¬ íŠ¸ë Œë“œ (2024-2025)

**ì†ë„ í˜ì‹ :**
- **LGM, Instant3D**: ì´ˆ ë‹¨ìœ„ ìƒì„±
- **Feed-forward ë°©ì‹**: ìµœì í™” ì—†ì´ ì§ì ‘ ì˜ˆì¸¡

**í’ˆì§ˆ ê°œì„ :**
- **Multi-view Diffusion**: MVDream, Wonder3D
- **3D-native generation**: 3D ë°ì´í„°ë¡œ ì§ì ‘ í•™ìŠµ

**ì‘ìš© í™•ì¥:**
- **Text-to-4D**: ë™ì  3D ì½˜í…ì¸  ìƒì„±
- **Text-to-Scene**: ì „ì²´ ì¥ë©´ ìƒì„±
- **Controllable 3D**: ControlNet + 3D

## í”í•œ ì˜¤í•´ì™€ íŒ

> âš ï¸ **í”í•œ ì˜¤í•´**: "Text-to-3DëŠ” Text-to-Imageì²˜ëŸ¼ ë¹ ë¥´ë‹¤" â€” ê¸°ë³¸ DreamFusionì€ 1-2ì‹œê°„, ProlificDreamerëŠ” 10ì‹œê°„ ì´ìƒ ê±¸ë¦½ë‹ˆë‹¤. ë¹ ë¥¸ ë°©ë²•ë“¤(DreamGaussian, LGM)ì€ í’ˆì§ˆ íŠ¸ë ˆì´ë“œì˜¤í”„ê°€ ìˆìŠµë‹ˆë‹¤.

> ğŸ’¡ **ì•Œê³  ê³„ì…¨ë‚˜ìš”?**: SDSì˜ ë†’ì€ guidance scale(100+)ì€ Text-to-Imageì—ì„œ ì‚¬ìš©í•˜ëŠ” ê°’(7.5)ë³´ë‹¤ í›¨ì”¬ ë†’ìŠµë‹ˆë‹¤. ì´ëŠ” 3D ì¼ê´€ì„±ì„ ìœ„í•´ ë” ê°•í•œ ì¡°ê±´ ë¶€ì—¬ê°€ í•„ìš”í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

> ğŸ”¥ **ì‹¤ë¬´ íŒ**: í”„ë¡¬í”„íŠ¸ì— "a DSLR photo of...", "highly detailed", "8K" ê°™ì€ í’ˆì§ˆ í‚¤ì›Œë“œë¥¼ ì¶”ê°€í•˜ë©´ ê²°ê³¼ê°€ í¬ê²Œ ê°œì„ ë©ë‹ˆë‹¤. ë˜í•œ "floating in the air", "isolated on white background" ê°™ì´ ë°°ê²½ì„ ë‹¨ìˆœí™”í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë„ íš¨ê³¼ì ì…ë‹ˆë‹¤.

## í•µì‹¬ ì •ë¦¬

| ê°œë… | ì„¤ëª… |
|------|------|
| Score Distillation Sampling | 2D Diffusion ëª¨ë¸ì˜ ìŠ¤ì½”ì–´ë¡œ 3D ìµœì í™” ìœ ë„ |
| DreamFusion | SDS + NeRFë¡œ í…ìŠ¤íŠ¸ì—ì„œ 3D ìƒì„± |
| Zero-1-to-3 | ë‹¨ì¼ ì´ë¯¸ì§€ì—ì„œ ë‹¤ë¥¸ ì‹œì  ì´ë¯¸ì§€ ìƒì„± |
| Janus Problem | ëª¨ë“  ë°©í–¥ì—ì„œ ì •ë©´ì²˜ëŸ¼ ë³´ì´ëŠ” ì‹¤íŒ¨ ëª¨ë“œ |
| Feed-forward 3D | ìµœì í™” ì—†ì´ ì§ì ‘ 3D íŒŒë¼ë¯¸í„° ì˜ˆì¸¡, ì´ˆê³ ì† |

## ë‹¤ìŒìœ¼ë¡œ

Chapter 17 Neural Renderingì„ ë§ˆì³¤ìŠµë‹ˆë‹¤! NeRFì—ì„œ ì‹œì‘í•´ 3D Gaussian Splatting, ê·¸ë¦¬ê³  Text-to-3Dê¹Œì§€ ìµœì‹  Neural Rendering ê¸°ìˆ ì˜ í•µì‹¬ì„ ë°°ì› ìŠµë‹ˆë‹¤.

ë‹¤ìŒ [Chapter 18: ë©€í‹°ëª¨ë‹¬ AI ìµœì „ì„ ](../18-multimodal-frontier/01-unified-models.md)ì—ì„œëŠ” ì´ë¯¸ì§€-í…ìŠ¤íŠ¸-ì˜¤ë””ì˜¤ë¥¼ í†µí•©í•˜ëŠ” **Unified Multimodal Models**, **World Models**, **Embodied AI** ë“± AIì˜ ìµœì „ì„ ì„ íƒí—˜í•©ë‹ˆë‹¤.

## ì°¸ê³  ìë£Œ

- [DreamFusion í”„ë¡œì íŠ¸](https://dreamfusion3d.github.io/) - Google Research ê³µì‹ í˜ì´ì§€
- [DreamFusion ë…¼ë¬¸](https://arxiv.org/abs/2209.14988) - ì›ë³¸ ë…¼ë¬¸
- [Threestudio GitHub](https://github.com/threestudio-project/threestudio) - í†µí•© Text-to-3D í”„ë ˆì„ì›Œí¬
- [stable-dreamfusion](https://github.com/ashawkey/stable-dreamfusion) - Stable Diffusion ê¸°ë°˜ êµ¬í˜„
- [DreamGaussian](https://dreamgaussian.github.io/) - ë¹ ë¥¸ 3DGS ê¸°ë°˜ Text-to-3D
- [Zero-1-to-3](https://zero123.cs.columbia.edu/) - ì´ë¯¸ì§€ ê¸°ë°˜ novel view synthesis
- [ProlificDreamer](https://ml.cs.tsinghua.edu.cn/prolificdreamer/) - VSDë¡œ ê³ í’ˆì§ˆ ìƒì„±
