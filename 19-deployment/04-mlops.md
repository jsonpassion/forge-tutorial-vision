# CV MLOps

> í•™ìŠµ íŒŒì´í”„ë¼ì¸ê³¼ ëª¨ë‹ˆí„°ë§

## ê°œìš”

ëª¨ë¸ì„ í•œ ë²ˆ ë°°í¬í•˜ë©´ ëì¼ê¹Œìš”? ì•„ë‹™ë‹ˆë‹¤! ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” **ë°ì´í„°ê°€ ë³€í•˜ê³ , ì„±ëŠ¥ì´ ì €í•˜ë˜ê³ , ìƒˆ ë²„ì „ì„ ë°°í¬**í•´ì•¼ í•©ë‹ˆë‹¤. ì´ ì„¹ì…˜ì—ì„œëŠ” ì»´í“¨í„° ë¹„ì „ ëª¨ë¸ì˜ **ì „ì²´ ìƒì• ì£¼ê¸°**ë¥¼ ê´€ë¦¬í•˜ëŠ” MLOps(Machine Learning Operations)ë¥¼ ë°°ì›ë‹ˆë‹¤. ë°ì´í„° íŒŒì´í”„ë¼ì¸, ì‹¤í—˜ ì¶”ì , ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬, ëª¨ë‹ˆí„°ë§ê¹Œì§€ í”„ë¡œë•ì…˜ ML ì‹œìŠ¤í…œ ìš´ì˜ ë°©ë²•ì„ ìµí™ë‹ˆë‹¤.

**ì„ ìˆ˜ ì§€ì‹**:
- [ì—£ì§€ ë°°í¬](./03-edge-deployment.md)
- ê¸°ë³¸ì ì¸ CI/CD ê°œë…

**í•™ìŠµ ëª©í‘œ**:
- MLOpsì˜ ê°œë…ê³¼ CV íŠ¹í™” ìš”êµ¬ì‚¬í•­ ì´í•´í•˜ê¸°
- ì‹¤í—˜ ì¶”ì ê³¼ ëª¨ë¸ ë²„ì „ ê´€ë¦¬ êµ¬í˜„í•˜ê¸°
- í”„ë¡œë•ì…˜ ëª¨ë‹ˆí„°ë§ê³¼ ë“œë¦¬í”„íŠ¸ ê°ì§€ ì„¤ì •í•˜ê¸°

## ì™œ ì•Œì•„ì•¼ í• ê¹Œ?

> ğŸ’¡ **ë¹„ìœ **: ìë™ì°¨ë¥¼ ë§Œë“œëŠ” ê²ƒê³¼ **ìš´ì˜í•˜ëŠ” ê²ƒ**ì€ ë‹¤ë¦…ë‹ˆë‹¤. ê³µì¥ì—ì„œ ì°¨ë¥¼ ë§Œë“¤ë©´ ëì´ ì•„ë‹ˆë¼, ì •ë¹„ì†Œ, ì£¼ìœ ì†Œ, ë³´í—˜, ë¦¬ì½œ ì‹œìŠ¤í…œì´ í•„ìš”í•˜ì£ . ML ëª¨ë¸ë„ í•™ìŠµ(ê³µì¥)ë§Œìœ¼ë¡œëŠ” ë¶€ì¡±í•©ë‹ˆë‹¤. **ë°°í¬, ëª¨ë‹ˆí„°ë§, ì¬í•™ìŠµì˜ ìˆœí™˜**ì´ í•„ìš”í•©ë‹ˆë‹¤.

**ML í”„ë¡œì íŠ¸ ì‹¤íŒ¨ì˜ í˜„ì‹¤:**

| ë‹¨ê³„ | ì‹¤íŒ¨ìœ¨ | ì£¼ìš” ì›ì¸ |
|------|--------|----------|
| ì—°êµ¬ â†’ í”„ë¡œí† íƒ€ì… | 30% | ê¸°ìˆ ì  í•œê³„ |
| í”„ë¡œí† íƒ€ì… â†’ ë°°í¬ | 50% | ì¸í”„ë¼/í†µí•© ë¬¸ì œ |
| ë°°í¬ â†’ ì§€ì† ìš´ì˜ | 40% | ì„±ëŠ¥ ì €í•˜, ë“œë¦¬í”„íŠ¸ |

**ê²°ë¡ **: ì—°êµ¬ì—ì„œ ì‹œì‘í•œ ML í”„ë¡œì íŠ¸ ì¤‘ **ì‹¤ì œ ê°€ì¹˜ë¥¼ ì°½ì¶œí•˜ëŠ” ë¹„ìœ¨ì€ 20% ë¯¸ë§Œ**ì…ë‹ˆë‹¤. MLOpsëŠ” ì´ ê²©ì°¨ë¥¼ ì¤„ì´ëŠ” í•µì‹¬ ì—­ëŸ‰ì…ë‹ˆë‹¤.

## í•µì‹¬ ê°œë…

### ê°œë… 1: MLOpsë€?

> ğŸ’¡ **ë¹„ìœ **: MLOpsëŠ” **DevOpsì˜ ML ë²„ì „**ì…ë‹ˆë‹¤. DevOpsê°€ ì½”ë“œì˜ ê°œë°œâ†’í…ŒìŠ¤íŠ¸â†’ë°°í¬ë¥¼ ìë™í™”í–ˆë‹¤ë©´, MLOpsëŠ” **ë°ì´í„°â†’í•™ìŠµâ†’ë°°í¬â†’ëª¨ë‹ˆí„°ë§**ì˜ ì „ì²´ ì‚¬ì´í´ì„ ìë™í™”í•©ë‹ˆë‹¤.

**MLOps ì„±ìˆ™ë„ ë ˆë²¨:**

| ë ˆë²¨ | ì„¤ëª… | íŠ¹ì§• |
|------|------|------|
| **Level 0** | ìˆ˜ë™ ML | Jupyter ë…¸íŠ¸ë¶, ìˆ˜ë™ ë°°í¬ |
| **Level 1** | ML íŒŒì´í”„ë¼ì¸ | ìë™í™”ëœ í•™ìŠµ, ìˆ˜ë™ ë°°í¬ |
| **Level 2** | CI/CD for ML | ìë™ í•™ìŠµ + ìë™ ë°°í¬ |
| **Level 3** | ì™„ì „ ìë™í™” | ìë™ ì¬í•™ìŠµ + ë¡¤ë°± + ëª¨ë‹ˆí„°ë§ |

**CV MLOpsì˜ íŠ¹ìˆ˜í•œ ìš”êµ¬ì‚¬í•­:**

| ì¼ë°˜ MLOps | CV íŠ¹í™” |
|------------|---------|
| í‘œ í˜•íƒœ ë°ì´í„° | ëŒ€ìš©ëŸ‰ ì´ë¯¸ì§€/ë¹„ë””ì˜¤ |
| GB ë‹¨ìœ„ ë°ì´í„° | TB-PB ë‹¨ìœ„ ë°ì´í„° |
| ë‹¨ìˆœ í†µê³„ ë“œë¦¬í”„íŠ¸ | ì‹œê°ì  ë“œë¦¬í”„íŠ¸ ê°ì§€ |
| CPU í•™ìŠµ ê°€ëŠ¥ | GPU í´ëŸ¬ìŠ¤í„° í•„ìˆ˜ |
| ë¹ ë¥¸ ì¶”ë¡  | ë³µì¡í•œ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ |

### ê°œë… 2: ë°ì´í„° íŒŒì´í”„ë¼ì¸

CV í”„ë¡œì íŠ¸ì—ì„œ **ë°ì´í„° ê´€ë¦¬**ëŠ” ê°€ì¥ ì¤‘ìš”í•˜ë©´ì„œë„ ì–´ë ¤ìš´ ë¶€ë¶„ì…ë‹ˆë‹¤.

```python
# ë°ì´í„° ë²„ì „ ê´€ë¦¬: DVC (Data Version Control)
# pip install dvc dvc-s3

"""
DVC ê¸°ë³¸ ì›Œí¬í”Œë¡œìš°:

1. ì´ˆê¸°í™”
$ dvc init
$ dvc remote add -d storage s3://my-bucket/dvc-cache

2. ë°ì´í„° ì¶”ì 
$ dvc add data/images/
$ git add data/images.dvc .gitignore
$ git commit -m "Add training images v1"

3. ë°ì´í„° í‘¸ì‹œ/í’€
$ dvc push
$ dvc pull

4. ë²„ì „ ì „í™˜
$ git checkout v1.0
$ dvc checkout
"""

# Pythonì—ì„œ DVC ì‚¬ìš©
import dvc.api

# íŠ¹ì • ë²„ì „ì˜ ë°ì´í„° ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
data_url = dvc.api.get_url(
    path='data/images',
    repo='https://github.com/user/cv-project',
    rev='v1.0'  # Git íƒœê·¸ ë˜ëŠ” ì»¤ë°‹
)

# ë°ì´í„° ì§ì ‘ ì½ê¸°
with dvc.api.open(
    'data/annotations.json',
    repo='https://github.com/user/cv-project',
    rev='v2.0'
) as f:
    annotations = json.load(f)
```

```python
# ëŒ€ê·œëª¨ ì´ë¯¸ì§€ ë°ì´í„° íŒŒì´í”„ë¼ì¸
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import albumentations as A
from albumentations.pytorch import ToTensorV2

class CVDataPipeline:
    """í”„ë¡œë•ì…˜ ìˆ˜ì¤€ CV ë°ì´í„° íŒŒì´í”„ë¼ì¸"""

    def __init__(self, data_root, split='train'):
        self.data_root = data_root
        self.split = split

        # í•™ìŠµ/ê²€ì¦ augmentation ë¶„ë¦¬
        if split == 'train':
            self.transform = A.Compose([
                A.RandomResizedCrop(224, 224),
                A.HorizontalFlip(p=0.5),
                A.ColorJitter(brightness=0.2, contrast=0.2),
                A.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225]),
                ToTensorV2()
            ])
        else:
            self.transform = A.Compose([
                A.Resize(256, 256),
                A.CenterCrop(224, 224),
                A.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225]),
                ToTensorV2()
            ])

    def get_dataloader(self, batch_size=32, num_workers=8):
        """ë°ì´í„°ë¡œë” ìƒì„±"""
        dataset = ImageDataset(
            root=f"{self.data_root}/{self.split}",
            transform=self.transform
        )

        loader = DataLoader(
            dataset,
            batch_size=batch_size,
            shuffle=(self.split == 'train'),
            num_workers=num_workers,
            pin_memory=True,  # GPU ì „ì†¡ ìµœì í™”
            prefetch_factor=2,  # ë¯¸ë¦¬ ë¡œë“œ
            persistent_workers=True  # ì›Œì»¤ ì¬ì‚¬ìš©
        )
        return loader
```

### ê°œë… 3: ì‹¤í—˜ ì¶”ì 

> ğŸ’¡ **ë¹„ìœ **: ì‹¤í—˜ ì¶”ì ì€ **ì—°êµ¬ ë…¸íŠ¸**ì™€ ê°™ìŠµë‹ˆë‹¤. ê³¼í•™ìê°€ ì‹¤í—˜í•  ë•Œë§ˆë‹¤ ì¡°ê±´ê³¼ ê²°ê³¼ë¥¼ ê¸°ë¡í•˜ë“¯, ML ì—”ì§€ë‹ˆì–´ë„ í•˜ì´í¼íŒŒë¼ë¯¸í„°, ë©”íŠ¸ë¦­, ì•„í‹°íŒ©íŠ¸ë¥¼ ê¸°ë¡í•´ì•¼ í•©ë‹ˆë‹¤.

**ì£¼ìš” ì‹¤í—˜ ì¶”ì  ë„êµ¬:**

| ë„êµ¬ | íŠ¹ì§• | ê°€ê²© |
|------|------|------|
| **MLflow** | ì˜¤í”ˆì†ŒìŠ¤, ìì²´ í˜¸ìŠ¤íŒ… | ë¬´ë£Œ |
| **Weights & Biases** | ê°•ë ¥í•œ ì‹œê°í™”, í˜‘ì—… | ë¬´ë£Œ~ìœ ë£Œ |
| **Neptune.ai** | ëŒ€ê·œëª¨ íŒ€ ìµœì í™” | ìœ ë£Œ |
| **ClearML** | ì˜¤í”ˆì†ŒìŠ¤, ì˜¬ì¸ì› | ë¬´ë£Œ~ìœ ë£Œ |

```python
# MLflowë¡œ ì‹¤í—˜ ì¶”ì 
import mlflow
import mlflow.pytorch
from torchvision import models

# MLflow ì„œë²„ ì„¤ì •
mlflow.set_tracking_uri("http://localhost:5000")
mlflow.set_experiment("image-classification")

def train_with_tracking(config):
    """MLflowë¡œ í•™ìŠµ ì¶”ì """

    with mlflow.start_run(run_name=config['run_name']):
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œê¹…
        mlflow.log_params({
            'model': config['model_name'],
            'learning_rate': config['lr'],
            'batch_size': config['batch_size'],
            'epochs': config['epochs'],
            'optimizer': config['optimizer'],
        })

        # ëª¨ë¸ ìƒì„±
        model = models.resnet18(pretrained=True)
        model.fc = nn.Linear(512, config['num_classes'])

        # í•™ìŠµ ë£¨í”„
        for epoch in range(config['epochs']):
            train_loss, train_acc = train_epoch(model, train_loader)
            val_loss, val_acc = validate(model, val_loader)

            # ë©”íŠ¸ë¦­ ë¡œê¹…
            mlflow.log_metrics({
                'train_loss': train_loss,
                'train_acc': train_acc,
                'val_loss': val_loss,
                'val_acc': val_acc,
            }, step=epoch)

            print(f"Epoch {epoch}: val_acc={val_acc:.4f}")

        # ëª¨ë¸ ì €ì¥
        mlflow.pytorch.log_model(model, "model")

        # ì¶”ê°€ ì•„í‹°íŒ©íŠ¸ (í˜¼ë™ í–‰ë ¬ ë“±)
        cm_fig = plot_confusion_matrix(model, val_loader)
        mlflow.log_figure(cm_fig, "confusion_matrix.png")

        return model

# ì‹¤í–‰
config = {
    'run_name': 'resnet18-lr001',
    'model_name': 'resnet18',
    'lr': 0.001,
    'batch_size': 32,
    'epochs': 10,
    'optimizer': 'Adam',
    'num_classes': 10
}
model = train_with_tracking(config)
```

```python
# Weights & Biases ì‚¬ìš©
import wandb

def train_with_wandb(config):
    """W&Bë¡œ ì‹¤í—˜ ì¶”ì  (ë” ê°•ë ¥í•œ ì‹œê°í™”)"""

    # ì‹¤í—˜ ì´ˆê¸°í™”
    wandb.init(
        project="cv-classification",
        name=config['run_name'],
        config=config
    )

    model = models.resnet18(pretrained=True)

    # ëª¨ë¸ êµ¬ì¡° ì‹œê°í™”
    wandb.watch(model, log='all', log_freq=100)

    for epoch in range(config['epochs']):
        train_loss, train_acc = train_epoch(model, train_loader)
        val_loss, val_acc = validate(model, val_loader)

        # ë©”íŠ¸ë¦­ ë¡œê¹…
        wandb.log({
            'epoch': epoch,
            'train/loss': train_loss,
            'train/acc': train_acc,
            'val/loss': val_loss,
            'val/acc': val_acc,
        })

        # ìƒ˜í”Œ ì˜ˆì¸¡ ì‹œê°í™”
        if epoch % 5 == 0:
            log_predictions(model, val_loader)

    # ëª¨ë¸ ì €ì¥ (W&B Artifacts)
    artifact = wandb.Artifact('model', type='model')
    torch.save(model.state_dict(), 'model.pth')
    artifact.add_file('model.pth')
    wandb.log_artifact(artifact)

    wandb.finish()

def log_predictions(model, dataloader, num_samples=16):
    """ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”"""
    images, labels = next(iter(dataloader))
    preds = model(images[:num_samples]).argmax(dim=1)

    wandb.log({
        "predictions": [
            wandb.Image(img, caption=f"Pred: {p}, True: {l}")
            for img, p, l in zip(images[:num_samples], preds, labels[:num_samples])
        ]
    })
```

### ê°œë… 4: ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬

> ğŸ’¡ **ë¹„ìœ **: ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ëŠ” **ì™€ì¸ ì €ì¥ê³ **ì™€ ê°™ìŠµë‹ˆë‹¤. ê° ë¹ˆí‹°ì§€(ë²„ì „)ë¥¼ ë¼ë²¨ë§í•˜ê³ , ìˆ™ì„± ìƒíƒœ(ìŠ¤í…Œì´ì§€)ë¥¼ ê´€ë¦¬í•˜ë©°, ìµœìƒì˜ ì™€ì¸(í”„ë¡œë•ì…˜ ëª¨ë¸)ì„ ì„ ë³„í•©ë‹ˆë‹¤.

```python
# MLflow ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬
import mlflow
from mlflow.tracking import MlflowClient

client = MlflowClient()

# 1. ëª¨ë¸ ë“±ë¡
model_uri = "runs:/<run_id>/model"
mv = mlflow.register_model(model_uri, "image-classifier")
print(f"ëª¨ë¸ ë²„ì „: {mv.version}")

# 2. ëª¨ë¸ ìŠ¤í…Œì´ì§€ ê´€ë¦¬
# ìŠ¤í…Œì´ì§€: None â†’ Staging â†’ Production â†’ Archived

# Stagingìœ¼ë¡œ ìŠ¹ê²©
client.transition_model_version_stage(
    name="image-classifier",
    version=1,
    stage="Staging"
)

# Productionìœ¼ë¡œ ìŠ¹ê²© (ìë™ í…ŒìŠ¤íŠ¸ í†µê³¼ í›„)
client.transition_model_version_stage(
    name="image-classifier",
    version=1,
    stage="Production",
    archive_existing_versions=True  # ê¸°ì¡´ ë²„ì „ ì•„ì¹´ì´ë¸Œ
)

# 3. í”„ë¡œë•ì…˜ ëª¨ë¸ ë¡œë“œ
production_model = mlflow.pyfunc.load_model(
    model_uri="models:/image-classifier/Production"
)

# íŠ¹ì • ë²„ì „ ë¡œë“œ
specific_model = mlflow.pyfunc.load_model(
    model_uri="models:/image-classifier/3"
)
```

```python
# ëª¨ë¸ ë°°í¬ ìë™í™” (GitHub Actions ì˜ˆì‹œ)
"""
# .github/workflows/model-deploy.yml

name: Model Deployment

on:
  workflow_dispatch:
    inputs:
      model_version:
        description: 'Model version to deploy'
        required: true

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Load model from registry
        run: |
          python scripts/load_model.py --version ${{ inputs.model_version }}

      - name: Run integration tests
        run: |
          pytest tests/integration/ -v

  deploy:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to production
        run: |
          python scripts/deploy.py --version ${{ inputs.model_version }}

      - name: Update model stage
        run: |
          python scripts/promote_model.py --version ${{ inputs.model_version }} --stage Production
"""
```

### ê°œë… 5: í”„ë¡œë•ì…˜ ëª¨ë‹ˆí„°ë§

> âš ï¸ **í”í•œ ì˜¤í•´**: "ëª¨ë¸ ë°°í¬í•˜ë©´ ë" â€” ì‹¤ì œë¡œëŠ” **ì‹œì‘**ì…ë‹ˆë‹¤. ë°ì´í„° ë¶„í¬ê°€ ë³€í•˜ê³ (ë“œë¦¬í”„íŠ¸), ì„±ëŠ¥ì´ ì €í•˜ë˜ê³ , ì˜ˆìƒì¹˜ ëª»í•œ ì…ë ¥ì´ ë“¤ì–´ì˜µë‹ˆë‹¤.

**ëª¨ë‹ˆí„°ë§í•´ì•¼ í•  ì§€í‘œ:**

| ë²”ì£¼ | ì§€í‘œ | ì„¤ëª… |
|------|------|------|
| **ì‹œìŠ¤í…œ** | ì§€ì—° ì‹œê°„, ì²˜ë¦¬ëŸ‰, ì—ëŸ¬ìœ¨ | ì¸í”„ë¼ ê±´ê°• ìƒíƒœ |
| **ëª¨ë¸** | ì •í™•ë„, ì‹ ë¢°ë„ ë¶„í¬ | ì˜ˆì¸¡ í’ˆì§ˆ |
| **ë°ì´í„°** | ì…ë ¥ ë¶„í¬, ë“œë¦¬í”„íŠ¸ ì ìˆ˜ | ë°ì´í„° ë³€í™” ê°ì§€ |
| **ë¹„ì¦ˆë‹ˆìŠ¤** | ì‚¬ìš©ì í”¼ë“œë°±, ì „í™˜ìœ¨ | ì‹¤ì œ ê°€ì¹˜ |

```python
# í”„ë¡œë•ì…˜ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
from prometheus_client import Counter, Histogram, start_http_server
import numpy as np
from scipy import stats

# Prometheus ë©”íŠ¸ë¦­ ì •ì˜
PREDICTION_COUNT = Counter('predictions_total', 'Total predictions', ['class'])
PREDICTION_LATENCY = Histogram('prediction_latency_seconds', 'Prediction latency')
CONFIDENCE_HISTOGRAM = Histogram('prediction_confidence', 'Prediction confidence',
                                  buckets=[0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99])

class ProductionMonitor:
    """í”„ë¡œë•ì…˜ ëª¨ë¸ ëª¨ë‹ˆí„°ë§"""

    def __init__(self, model, reference_data=None):
        self.model = model
        self.reference_data = reference_data  # í•™ìŠµ ë°ì´í„° í†µê³„
        self.predictions_buffer = []
        self.confidence_buffer = []

    def predict_with_monitoring(self, input_data):
        """ëª¨ë‹ˆí„°ë§ì´ í¬í•¨ëœ ì˜ˆì¸¡"""
        import time

        # ì§€ì—° ì‹œê°„ ì¸¡ì •
        start = time.time()
        output = self.model(input_data)
        latency = time.time() - start

        # ë©”íŠ¸ë¦­ ê¸°ë¡
        PREDICTION_LATENCY.observe(latency)

        # ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„
        probs = torch.softmax(output, dim=1)
        confidence, predicted_class = probs.max(dim=1)

        for conf, cls in zip(confidence, predicted_class):
            CONFIDENCE_HISTOGRAM.observe(conf.item())
            PREDICTION_COUNT.labels(class=str(cls.item())).inc()

        # ë²„í¼ì— ì €ì¥ (ë“œë¦¬í”„íŠ¸ ê°ì§€ìš©)
        self.confidence_buffer.extend(confidence.tolist())
        self.predictions_buffer.extend(predicted_class.tolist())

        return output

    def check_data_drift(self, current_features):
        """ë°ì´í„° ë“œë¦¬í”„íŠ¸ ê°ì§€"""
        if self.reference_data is None:
            return None

        # KS í…ŒìŠ¤íŠ¸ë¡œ ë¶„í¬ ë³€í™” ê°ì§€
        drift_scores = {}
        for i in range(current_features.shape[1]):
            stat, pvalue = stats.ks_2samp(
                self.reference_data[:, i],
                current_features[:, i]
            )
            drift_scores[f'feature_{i}'] = {
                'statistic': stat,
                'pvalue': pvalue,
                'drift_detected': pvalue < 0.05
            }

        return drift_scores

    def check_model_performance(self, window_size=1000):
        """ëª¨ë¸ ì„±ëŠ¥ ì €í•˜ ê°ì§€"""
        if len(self.confidence_buffer) < window_size:
            return None

        recent_conf = self.confidence_buffer[-window_size:]
        historical_conf = self.confidence_buffer[:-window_size]

        if len(historical_conf) < window_size:
            return None

        # ì‹ ë¢°ë„ ë¶„í¬ ë³€í™” ê°ì§€
        stat, pvalue = stats.ks_2samp(historical_conf[-window_size:], recent_conf)

        return {
            'mean_confidence': np.mean(recent_conf),
            'drift_statistic': stat,
            'pvalue': pvalue,
            'alert': pvalue < 0.01  # ìœ ì˜ìˆ˜ì¤€ 1%
        }

# ì‚¬ìš© ì˜ˆì‹œ
# start_http_server(8000)  # Prometheus ë©”íŠ¸ë¦­ ì—”ë“œí¬ì¸íŠ¸
# monitor = ProductionMonitor(model, reference_data)
# output = monitor.predict_with_monitoring(input_data)
```

```python
# ì´ë¯¸ì§€ ë“œë¦¬í”„íŠ¸ ê°ì§€ (CV íŠ¹í™”)
from sklearn.decomposition import PCA
import numpy as np

class ImageDriftDetector:
    """ì´ë¯¸ì§€ ë°ì´í„° ë“œë¦¬í”„íŠ¸ ê°ì§€"""

    def __init__(self, feature_extractor, reference_features):
        """
        Args:
            feature_extractor: ì´ë¯¸ì§€ â†’ íŠ¹ì§• ë²¡í„° ì¶”ì¶œ ëª¨ë¸
            reference_features: í•™ìŠµ ë°ì´í„°ì˜ íŠ¹ì§• ë²¡í„°
        """
        self.extractor = feature_extractor
        self.reference = reference_features

        # PCAë¡œ ì°¨ì› ì¶•ì†Œ (ë¹„êµ ìš©ì´)
        self.pca = PCA(n_components=50)
        self.ref_reduced = self.pca.fit_transform(reference_features)

        # ê¸°ì¤€ í†µê³„
        self.ref_mean = self.ref_reduced.mean(axis=0)
        self.ref_std = self.ref_reduced.std(axis=0)

    def detect_drift(self, new_images, threshold=3.0):
        """ìƒˆ ì´ë¯¸ì§€ì˜ ë“œë¦¬í”„íŠ¸ ê°ì§€"""
        # íŠ¹ì§• ì¶”ì¶œ
        with torch.no_grad():
            new_features = self.extractor(new_images).numpy()

        # ì°¨ì› ì¶•ì†Œ
        new_reduced = self.pca.transform(new_features)

        # Z-score ê³„ì‚° (ê¸°ì¤€ ë¶„í¬ì—ì„œ ì–¼ë§ˆë‚˜ ë²—ì–´ë‚¬ëŠ”ì§€)
        z_scores = np.abs((new_reduced - self.ref_mean) / (self.ref_std + 1e-8))
        max_z = z_scores.max(axis=1)

        # ë“œë¦¬í”„íŠ¸ ê°ì§€ ê²°ê³¼
        drift_detected = max_z > threshold
        drift_ratio = drift_detected.mean()

        return {
            'drift_ratio': drift_ratio,
            'max_z_scores': max_z,
            'alert': drift_ratio > 0.1  # 10% ì´ìƒ ë“œë¦¬í”„íŠ¸
        }
```

> ğŸ”¥ **ì‹¤ë¬´ íŒ**: CV ëª¨ë¸ì˜ ë“œë¦¬í”„íŠ¸ëŠ” **ì‹œê°ì ìœ¼ë¡œ í™•ì¸**í•˜ëŠ” ê²ƒì´ ê°€ì¥ íš¨ê³¼ì ì…ë‹ˆë‹¤. ì˜ˆì¸¡ ì‹ ë¢°ë„ê°€ ë‚®ì€ ìƒ˜í”Œ, ë“œë¦¬í”„íŠ¸ ì ìˆ˜ê°€ ë†’ì€ ìƒ˜í”Œì„ ì£¼ê¸°ì ìœ¼ë¡œ ì‹œê°í™”í•˜ì—¬ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œì— ì¶”ê°€í•˜ì„¸ìš”.

## ë” ê¹Šì´ ì•Œì•„ë³´ê¸°: CV MLOps ë„êµ¬ ìƒíƒœê³„

**2025ë…„ ê¶Œì¥ ìŠ¤íƒ:**

| ì—­í•  | ë„êµ¬ | ëŒ€ì•ˆ |
|------|------|------|
| **ë°ì´í„° ë²„ì „ ê´€ë¦¬** | DVC | LakeFS, Pachyderm |
| **ì‹¤í—˜ ì¶”ì ** | W&B, MLflow | Neptune, ClearML |
| **íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜** | Kubeflow, Airflow | Prefect, Dagster |
| **ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬** | MLflow | Vertex AI, SageMaker |
| **ì„œë¹™** | Triton, TorchServe | BentoML, Seldon |
| **ëª¨ë‹ˆí„°ë§** | Prometheus + Grafana | Evidently, Whylogs |

## í•µì‹¬ ì •ë¦¬

| ê°œë… | ì„¤ëª… |
|------|------|
| **MLOps** | ML ëª¨ë¸ì˜ ê°œë°œ-ë°°í¬-ìš´ì˜ ì „ì²´ ì‚¬ì´í´ ìë™í™” |
| **ë°ì´í„° íŒŒì´í”„ë¼ì¸** | ëŒ€ìš©ëŸ‰ ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ì²˜ë¦¬ ë° ë²„ì „ ê´€ë¦¬ |
| **ì‹¤í—˜ ì¶”ì ** | í•˜ì´í¼íŒŒë¼ë¯¸í„°, ë©”íŠ¸ë¦­, ì•„í‹°íŒ©íŠ¸ ê¸°ë¡ |
| **ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬** | ëª¨ë¸ ë²„ì „ ê´€ë¦¬ ë° ìŠ¤í…Œì´ì§€ ìŠ¹ê²© |
| **ë“œë¦¬í”„íŠ¸ ê°ì§€** | ë°ì´í„°/ëª¨ë¸ ì„±ëŠ¥ ë³€í™” ìë™ ê°ì§€ |
| **í”„ë¡œë•ì…˜ ëª¨ë‹ˆí„°ë§** | ì‹¤ì‹œê°„ ì§€ì—° ì‹œê°„, ì²˜ë¦¬ëŸ‰, ì—ëŸ¬ìœ¨ ì¶”ì  |

## ë‹¤ìŒ ì„¹ì…˜ ë¯¸ë¦¬ë³´ê¸°

MLOps ì¸í”„ë¼ê°€ ê°–ì¶°ì¡Œë‹¤ë©´, ë§ˆì§€ë§‰ìœ¼ë¡œ **ëª¨ë¸ ì„œë¹™**ì„ êµ¬í˜„í•  ì°¨ë¡€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì„¹ì…˜ [ëª¨ë¸ ì„œë¹™](./05-serving.md)ì—ì„œëŠ” Triton Inference Server, TorchServe, FastAPIë¥¼ ì‚¬ìš©í•´ **í”„ë¡œë•ì…˜ ìˆ˜ì¤€ì˜ ì¶”ë¡  API**ë¥¼ êµ¬ì¶•í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤.

## ì°¸ê³  ìë£Œ

- [Google Cloud MLOps Guide](https://docs.cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning) - MLOps ê°œë… ì •ë¦¬
- [MLOps for Computer Vision](https://dac.digital/mlops-for-computer-vision-key-components-challenges-and-best-practices/) - CV íŠ¹í™” MLOps
- [Building MLOps Pipeline for CV](https://neptune.ai/blog/mlops-pipeline-for-computer-vision-image-classification) - Neptune.ai íŠœí† ë¦¬ì–¼
- [Mastering MLOps for CV 2025](https://easyflow.tech/mlops-for-computer-vision/) - 2025ë…„ ìµœì‹  íŠ¸ë Œë“œ
- [MLOps Best Practices](https://www.clarifai.com/blog/mlops-best-practices) - ì‹¤ë¬´ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤
