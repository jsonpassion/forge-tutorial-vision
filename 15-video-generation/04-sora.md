# Soraì™€ ëŒ€ê·œëª¨ ë¹„ë””ì˜¤ ëª¨ë¸

> Diffusion Transformer ê¸°ë°˜ ë¹„ë””ì˜¤

## ê°œìš”

[Stable Video Diffusion](./03-svd.md)ì—ì„œ ì´ë¯¸ì§€ë¥¼ ë¹„ë””ì˜¤ë¡œ ë³€í™˜í•˜ëŠ” ë°©ë²•ì„ ë°°ì› ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ëª‡ ì´ˆ ë¶„ëŸ‰ì˜ ë‹¨ìˆœí•œ ì›€ì§ì„ì´ í•œê³„ì˜€ì£ . 2024ë…„ 2ì›”, OpenAIê°€ ê³µê°œí•œ **Sora**ëŠ” ë¹„ë””ì˜¤ ìƒì„±ì˜ íŒë„ë¥¼ ì™„ì „íˆ ë°”ê¿¨ìŠµë‹ˆë‹¤. **1ë¶„ ê¸¸ì´ì˜ ê³ í•´ìƒë„ ì˜ìƒ**, ë³µì¡í•œ ì¹´ë©”ë¼ ì›€ì§ì„, ì—¬ëŸ¬ ìºë¦­í„°ì˜ ìƒí˜¸ì‘ìš©ê¹Œì§€ ê°€ëŠ¥í•´ì¡ŒìŠµë‹ˆë‹¤. ì´ ì„¹ì…˜ì—ì„œëŠ” Soraë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ **ëŒ€ê·œëª¨ ë¹„ë””ì˜¤ ìƒì„± ëª¨ë¸**ì˜ í•µì‹¬ ê¸°ìˆ ì„ ì‚´í´ë´…ë‹ˆë‹¤.

**ì„ ìˆ˜ ì§€ì‹**: [ë¹„ë””ì˜¤ Diffusion ê¸°ì´ˆ](./01-video-diffusion.md), [FLUXì™€ SD3](../13-stable-diffusion/05-flux.md), [Transformer ì•„í‚¤í…ì²˜](../09-vision-transformer/02-transformer-basics.md)
**í•™ìŠµ ëª©í‘œ**:
- U-Netì—ì„œ DiTë¡œì˜ íŒ¨ëŸ¬ë‹¤ì„ ì „í™˜ì„ ì´í•´í•œë‹¤
- Spacetime Patchesì™€ 3D VAEì˜ ì›ë¦¬ë¥¼ íŒŒì•…í•œë‹¤
- Soraì˜ ì•„í‚¤í…ì²˜ì™€ í›ˆë ¨ ì „ëµì„ ì´í•´í•œë‹¤
- ì£¼ìš” ë¹„ë””ì˜¤ ìƒì„± ëª¨ë¸(Runway, Kling, Veo)ì„ ë¹„êµí•  ìˆ˜ ìˆë‹¤

## ì™œ ì•Œì•„ì•¼ í• ê¹Œ?

ë¹„ë””ì˜¤ ìƒì„± AIëŠ” 2024ë…„ë¶€í„° **ì‚°ì—…ì˜ í•µì‹¬ ê¸°ìˆ **ì´ ë˜ì—ˆìŠµë‹ˆë‹¤. ì˜í™” í”„ë¦¬ë¹„ì¦ˆ, ê´‘ê³  ì œì‘, ê²Œì„ ì‹œë„¤ë§ˆí‹±, êµìœ¡ ì½˜í…ì¸ , SNS ë§ˆì¼€íŒ… ë“± ëª¨ë“  ì˜ìƒ ì‚°ì—…ì´ ë³€í™”í•˜ê³  ìˆì£ . Soraì˜ ë“±ì¥ì€ "**AIê°€ ì˜í™”ë¥¼ ë§Œë“¤ ìˆ˜ ìˆë‹¤**"ëŠ” ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì¤¬ê³ , ì´í›„ Google Veo, Runway Gen-3, Kuaishou Kling ë“±ì´ ê²½ìŸì ìœ¼ë¡œ ë°œí‘œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ê¸°ìˆ ì˜ ì›ë¦¬ë¥¼ ì´í•´í•˜ë©´ ë¯¸ë˜ì˜ í¬ë¦¬ì—ì´í‹°ë¸Œ ë„êµ¬ë¥¼ ë” ì˜ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## í•µì‹¬ ê°œë…

### ê°œë… 1: U-Netì—ì„œ DiTë¡œ â€” íŒ¨ëŸ¬ë‹¤ì„ì˜ ì „í™˜

> ğŸ’¡ **ë¹„ìœ **: U-Net ê¸°ë°˜ ëª¨ë¸ì´ **ìˆ™ë ¨ëœ ì¥ì¸ì˜ ì†ì‘ì—…**ì´ë¼ë©´, DiT ê¸°ë°˜ ëª¨ë¸ì€ **ê±°ëŒ€í•œ ê³µì¥ì˜ ìë™í™” ì‹œìŠ¤í…œ**ì…ë‹ˆë‹¤. ì¥ì¸ì€ ì„¬ì„¸í•˜ì§€ë§Œ ê·œëª¨ í™•ì¥ì´ ì–´ë µê³ , ìë™í™” ê³µì¥ì€ í¬ê¸°ë§Œ í‚¤ìš°ë©´ ìƒì‚°ëŸ‰ì´ ëŠ˜ì–´ë‚˜ì£ .

[FLUXì™€ SD3](../13-stable-diffusion/05-flux.md)ì—ì„œ ë°°ìš´ ê²ƒì²˜ëŸ¼, ì´ë¯¸ì§€ ìƒì„±ì—ì„œë„ U-Net â†’ Transformer ì „í™˜ì´ ì¼ì–´ë‚˜ê³  ìˆìŠµë‹ˆë‹¤. ë¹„ë””ì˜¤ì—ì„œëŠ” ì´ ì „í™˜ì´ **ë”ìš± ê·¹ì **ì…ë‹ˆë‹¤.

**U-Netì˜ í•œê³„:**

| ë¬¸ì œ | ì„¤ëª… |
|------|------|
| **ìŠ¤ì¼€ì¼ë§ ë¹„íš¨ìœ¨** | ëª¨ë¸ í¬ê¸° 2ë°° â‰  ì„±ëŠ¥ 2ë°° |
| **êµ¬ì¡°ì  ì œì•½** | ì¸ì½”ë”-ë””ì½”ë” ëŒ€ì¹­ êµ¬ì¡° í•„ìˆ˜ |
| **ì‹œí€€ìŠ¤ ê¸¸ì´ í•œê³„** | ê¸´ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì–´ë ¤ì›€ |
| **í•™ìŠµ ë¶ˆì•ˆì •** | ëŒ€ê·œëª¨ì—ì„œ ìˆ˜ë ´ ì–´ë ¤ì›€ |

**DiT(Diffusion Transformer)ì˜ ì¥ì :**

| ì¥ì  | ì„¤ëª… |
|------|------|
| **ìŠ¤ì¼€ì¼ë§ ë²•ì¹™** | íŒŒë¼ë¯¸í„° ì¦ê°€ â†’ ì„±ëŠ¥ ì˜ˆì¸¡ ê°€ëŠ¥í•œ í–¥ìƒ |
| **ìœ ì—°í•œ êµ¬ì¡°** | ë‹¤ì–‘í•œ í•´ìƒë„, ê¸¸ì´ ì²˜ë¦¬ ê°€ëŠ¥ |
| **ê¸´ ì»¨í…ìŠ¤íŠ¸** | ì–´í…ì…˜ìœ¼ë¡œ ì „ì²´ ë¹„ë””ì˜¤ ê´€ê³„ í•™ìŠµ |
| **ê²€ì¦ëœ ë ˆì‹œí”¼** | LLMì—ì„œ ê²€ì¦ëœ í›ˆë ¨ ê¸°ë²• í™œìš© |

### ê°œë… 2: Spacetime Patches â€” ë¹„ë””ì˜¤ë¥¼ í† í°ìœ¼ë¡œ

> ğŸ’¡ **ë¹„ìœ **: ì˜í™” í•„ë¦„ì„ ì˜ë¼ì„œ **í¼ì¦ ì¡°ê°**ìœ¼ë¡œ ë§Œë“œëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤. ê° ì¡°ê°ì—ëŠ” íŠ¹ì • ìœ„ì¹˜ì˜ ì§§ì€ ì‹œê°„ ë™ì•ˆ ì •ë³´ê°€ ë‹´ê²¨ ìˆì£ . ì´ ì¡°ê°ë“¤ì„ Transformerê°€ ì´í•´í•˜ê³  ì¬ì¡°í•©í•´ì„œ ì™„ì„±ëœ ì˜í™”ë¥¼ ë§Œë“­ë‹ˆë‹¤.

**ê¸°ì¡´ ì´ë¯¸ì§€ íŒ¨ì¹˜ vs Spacetime íŒ¨ì¹˜:**

[ViT](../09-vision-transformer/03-vit.md)ì—ì„œ ì´ë¯¸ì§€ë¥¼ íŒ¨ì¹˜ë¡œ ë‚˜ëˆ  í† í°í™”í–ˆìŠµë‹ˆë‹¤. SoraëŠ” ì´ë¥¼ **ì‹œê³µê°„ìœ¼ë¡œ í™•ì¥**í•©ë‹ˆë‹¤:

> ì´ë¯¸ì§€ íŒ¨ì¹˜: (H, W) â†’ 16Ã—16 íŒ¨ì¹˜
>
> Spacetime íŒ¨ì¹˜: (T, H, W) â†’ 1Ã—16Ã—16 ë˜ëŠ” 2Ã—8Ã—8 ë“±ì˜ 3D íŒ¨ì¹˜

**íŒ¨ì¹˜í™” ê³¼ì •:**

1. ë¹„ë””ì˜¤ë¥¼ **3D VAE**ë¡œ ì••ì¶• (ì‹œê³µê°„ ëª¨ë‘ ì¶•ì†Œ)
2. ì••ì¶•ëœ latentë¥¼ **3D íŒ¨ì¹˜**ë¡œ ë¶„í• 
3. ê° íŒ¨ì¹˜ë¥¼ **1D ì‹œí€€ìŠ¤ë¡œ í¼ì¹¨** (flatten)
4. Transformerê°€ **ì „ì²´ ì‹œí€€ìŠ¤ì— ì–´í…ì…˜** ì ìš©

**ì˜ˆì‹œ: 1ë¶„ 1080p ë¹„ë””ì˜¤**

| ë‹¨ê³„ | ì°¨ì› | í† í° ìˆ˜ (ëŒ€ëµ) |
|------|------|----------------|
| ì›ë³¸ | (1800, 1920, 1080, 3) | - |
| VAE ì••ì¶• | (450, 240, 135, 4) | - |
| íŒ¨ì¹˜í™” (4Ã—16Ã—16) | - | ~28,000 í† í° |

ì´ 28,000ê°œ í† í°ì´ **GPTì²˜ëŸ¼** Transformerì— ì…ë ¥ë©ë‹ˆë‹¤.

### ê°œë… 3: Sora ì•„í‚¤í…ì²˜ ë¶„ì„

OpenAIëŠ” Soraì˜ ì„¸ë¶€ ì‚¬í•­ì„ ê³µê°œí•˜ì§€ ì•Šì•˜ì§€ë§Œ, ê¸°ìˆ  ë³´ê³ ì„œì™€ ë¶„ì„ì„ í†µí•´ í•µì‹¬ êµ¬ì¡°ë¥¼ ì¶”ë¡ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ì¶”ì • ì•„í‚¤í…ì²˜:**

> **Sora êµ¬ì¡° (ì¶”ì •)**
>
> ì…ë ¥: í…ìŠ¤íŠ¸ + (ì„ íƒì ) ì´ë¯¸ì§€/ë¹„ë””ì˜¤
> â†“
> í…ìŠ¤íŠ¸ ì¸ì½”ë” (GPT ë˜ëŠ” T5 ê³„ì—´)
> â†“
> 3D VAE ì¸ì½”ë” (ì‹œê³µê°„ ì••ì¶•)
> â†“
> **DiT ë°±ë³¸** (ìˆ˜ì‹­~ìˆ˜ë°± ë ˆì´ì–´)
> - Bidirectional Self-Attention
> - Cross-Attention (í…ìŠ¤íŠ¸ ì¡°ê±´)
> - AdaLN-Zero (ì¡°ê±´ ì£¼ì…)
> â†“
> 3D VAE ë””ì½”ë”
> â†“
> ì¶œë ¥: ë¹„ë””ì˜¤

**í•µì‹¬ ì„¤ê³„ ê²°ì •:**

| ìš”ì†Œ | ì„ íƒ | ì´ìœ  |
|------|------|------|
| **ë°±ë³¸** | Transformer (DiT) | ìŠ¤ì¼€ì¼ë§ ë²•ì¹™ |
| **í† í°í™”** | Spacetime íŒ¨ì¹˜ | ê°€ë³€ í•´ìƒë„/ê¸¸ì´ |
| **ì–´í…ì…˜** | ì–‘ë°©í–¥ Full Attention | ì „ì²´ ë§¥ë½ ì´í•´ |
| **ì¡°ê±´ ì£¼ì…** | Cross-Attention + AdaLN | ê°•ë ¥í•œ í…ìŠ¤íŠ¸ ì œì–´ |
| **ì••ì¶•** | 3D VAE | ê³„ì‚° íš¨ìœ¨ |

**ê°€ë³€ í•´ìƒë„ì™€ ê¸¸ì´:**

Soraì˜ í˜ì‹  ì¤‘ í•˜ë‚˜ëŠ” **ê³ ì • í•´ìƒë„/ê¸¸ì´ê°€ ì•„ë‹Œ** ìœ ì—°í•œ ìƒì„±ì…ë‹ˆë‹¤:

- 16:9, 9:16, 1:1 ë“± ë‹¤ì–‘í•œ ë¹„ìœ¨
- ëª‡ ì´ˆì—ì„œ 1ë¶„ê¹Œì§€ ê°€ë³€ ê¸¸ì´
- 720p, 1080p ë‹¤ì–‘í•œ í•´ìƒë„

ì´ëŠ” **íŒ¨ì¹˜ ê·¸ë¦¬ë“œì˜ í¬ê¸°**ë¥¼ ì¡°ì ˆí•´ì„œ êµ¬í˜„í•©ë‹ˆë‹¤. í•™ìŠµ ì‹œ ë‹¤ì–‘í•œ í¬ê¸°ì˜ ë¹„ë””ì˜¤ë¥¼ ì‚¬ìš©í•˜ê³ , ì¶”ë¡  ì‹œ ì›í•˜ëŠ” í¬ê¸°ì˜ íŒ¨ì¹˜ ê·¸ë¦¬ë“œë¥¼ ì´ˆê¸°í™”í•˜ë©´ ë©ë‹ˆë‹¤.

### ê°œë… 4: "World Simulator" â€” ë¬¼ë¦¬ ì„¸ê³„ ì‹œë®¬ë ˆì´ì…˜

> ğŸ’¡ **ë¹„ìœ **: SoraëŠ” ë‹¨ìˆœí•œ "ë¹„ë””ì˜¤ ìƒì„±ê¸°"ê°€ ì•„ë‹ˆë¼ **ë¨¸ë¦¿ì†ìœ¼ë¡œ ë¬¼ë¦¬ ì„¸ê³„ë¥¼ ìƒìƒí•˜ëŠ” ë‘ë‡Œ**ì— ê°€ê¹ìŠµë‹ˆë‹¤. "ê³µì„ ë˜ì§€ë©´ ì–´ë””ë¡œ ë‚ ì•„ê°ˆê¹Œ?"ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆì–´ì•¼ ìì—°ìŠ¤ëŸ¬ìš´ ë¹„ë””ì˜¤ê°€ ë˜ì£ .

OpenAIëŠ” Soraë¥¼ "**Video generation models as world simulators**"ë¼ê³  ì†Œê°œí–ˆìŠµë‹ˆë‹¤. ë‹¨ìˆœíˆ í”½ì…€ì„ ìƒì„±í•˜ëŠ” ê²Œ ì•„ë‹ˆë¼, **3D ê³µê°„ê³¼ ë¬¼ë¦¬ ë²•ì¹™ì„ ì´í•´**í•œë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.

**Soraê°€ í•™ìŠµí•œ ê²ƒë“¤:**

| ì˜ì—­ | ì˜ˆì‹œ |
|------|------|
| **3D ì¼ê´€ì„±** | ì¹´ë©”ë¼ê°€ íšŒì „í•´ë„ ë¬¼ì²´ í˜•íƒœ ìœ ì§€ |
| **ë¬¼ì²´ ì˜ì†ì„±** | ë¬¼ì²´ê°€ ê°€ë ¤ì ¸ë„ ì¡´ì¬ ì¸ì‹ |
| **ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜** | ë¬¼, ë¶ˆ, ì—°ê¸°ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ì›€ì§ì„ |
| **ìƒí˜¸ì‘ìš©** | ìºë¦­í„° ê°„ ëŒ€í™”, ì ‘ì´‰ |
| **ì¥ê¸° ì¼ê´€ì„±** | 60ì´ˆ ë™ì•ˆ ìºë¦­í„°/ë°°ê²½ ìœ ì§€ |

ë¬¼ë¡  ì™„ë²½í•˜ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤. ë³µì¡í•œ ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜(ìœ ë¦¬ ê¹¨ì§, ìœ ì²´ ì—­í•™)ì´ë‚˜ ì¸ê³¼ê´€ê³„(ì›ì¸-ê²°ê³¼)ëŠ” ì—¬ì „íˆ í•œê³„ê°€ ìˆì£ .

### ê°œë… 5: ì£¼ìš” ë¹„ë””ì˜¤ ìƒì„± ëª¨ë¸ ë¹„êµ

2024ë…„ ì´í›„ ì—¬ëŸ¬ ëŒ€ê·œëª¨ ë¹„ë””ì˜¤ ëª¨ë¸ì´ ê³µê°œë˜ì—ˆìŠµë‹ˆë‹¤:

**OpenAI Sora (2024.02~12)**

| í•­ëª© | ì‚¬ì–‘ |
|------|------|
| ìµœëŒ€ ê¸¸ì´ | 1ë¶„ (ê³µê°œ ë‹¹ì‹œ) |
| í•´ìƒë„ | ìµœëŒ€ 1080p |
| ì•„í‚¤í…ì²˜ | DiT ê¸°ë°˜ |
| íŠ¹ì§• | ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜, ì¥ê¸° ì¼ê´€ì„± |
| ì ‘ê·¼ì„± | ChatGPT Plus êµ¬ë…ì |

**Google Veo / Veo 2 (2024.05~12)**

| í•­ëª© | ì‚¬ì–‘ |
|------|------|
| ìµœëŒ€ ê¸¸ì´ | 1ë¶„+ |
| í•´ìƒë„ | ìµœëŒ€ 4K (Veo 2) |
| ì•„í‚¤í…ì²˜ | DiT ê¸°ë°˜ ì¶”ì • |
| íŠ¹ì§• | ì‹œë„¤ë§ˆí‹± íš¨ê³¼, ë¹ ë¥¸ ìƒì„± |
| ì ‘ê·¼ì„± | Google Labs, Vertex AI |

**Runway Gen-3 Alpha (2024.06)**

| í•­ëª© | ì‚¬ì–‘ |
|------|------|
| ìµœëŒ€ ê¸¸ì´ | 10ì´ˆ |
| í•´ìƒë„ | 1080p |
| ì•„í‚¤í…ì²˜ | ê³µê°œë˜ì§€ ì•ŠìŒ |
| íŠ¹ì§• | ë¹ ë¥¸ ìƒì„±, í”„ë¡œ ë„êµ¬ |
| ì ‘ê·¼ì„± | Runway êµ¬ë… |

**Kuaishou Kling (2024.06)**

| í•­ëª© | ì‚¬ì–‘ |
|------|------|
| ìµœëŒ€ ê¸¸ì´ | 2ë¶„ |
| í•´ìƒë„ | 1080p |
| ì•„í‚¤í…ì²˜ | DiT ê¸°ë°˜ |
| íŠ¹ì§• | ê¸´ ì˜ìƒ, ì¤‘êµ­ ì‹œì¥ ìµœì í™” |
| ì ‘ê·¼ì„± | Kling ì•± |

**MiniMax / Hailuo AI (2024)**

| í•­ëª© | ì‚¬ì–‘ |
|------|------|
| ìµœëŒ€ ê¸¸ì´ | 6ì´ˆ |
| í•´ìƒë„ | 720p |
| ì•„í‚¤í…ì²˜ | DiT ê¸°ë°˜ |
| íŠ¹ì§• | ë¬´ë£Œ ì‚¬ìš©, ë¹ ë¥¸ ìƒì„± |
| ì ‘ê·¼ì„± | ì›¹/ì•± ë¬´ë£Œ |

## ì‹¤ìŠµ: ì˜¤í”ˆì†ŒìŠ¤ ë¹„ë””ì˜¤ ìƒì„± ëª¨ë¸

SoraëŠ” ê³µê°œë˜ì§€ ì•Šì•˜ì§€ë§Œ, ë¹„ìŠ·í•œ ì ‘ê·¼ë²•ì„ ì‚¬ìš©í•˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ë“¤ì´ ìˆìŠµë‹ˆë‹¤.

### Open-Soraë¡œ ë¹„ë””ì˜¤ ìƒì„±

```python
# Open-SoraëŠ” Soraì˜ ì•„í‚¤í…ì²˜ë¥¼ ì¬í˜„í•˜ë ¤ëŠ” ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤
# ì„¤ì¹˜: pip install opensora

from opensora.models import OpenSoraT2V
from opensora.utils import export_to_video
import torch

# ëª¨ë¸ ë¡œë“œ (DiT ê¸°ë°˜)
model = OpenSoraT2V.from_pretrained(
    "hpcaitech/Open-Sora-v1.2",
    torch_dtype=torch.float16
)
model = model.to("cuda")

# í…ìŠ¤íŠ¸-íˆ¬-ë¹„ë””ì˜¤ ìƒì„±
prompt = "A golden retriever running on the beach, waves crashing, \
         sunset lighting, cinematic, slow motion"

# 2ì´ˆ ë¹„ë””ì˜¤ ìƒì„± (16í”„ë ˆì„)
video = model.generate(
    prompt=prompt,
    num_frames=16,
    height=480,
    width=854,  # 16:9
    num_inference_steps=50,
    guidance_scale=7.0,
)

export_to_video(video, "beach_dog.mp4", fps=8)
print("âœ… Open-Sora ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ!")
```

### CogVideoXë¡œ í…ìŠ¤íŠ¸-íˆ¬-ë¹„ë””ì˜¤

```python
import torch
from diffusers import CogVideoXPipeline
from diffusers.utils import export_to_video

# CogVideoX: ì¹­í™”ëŒ€í•™ì˜ ë¹„ë””ì˜¤ ìƒì„± ëª¨ë¸
pipe = CogVideoXPipeline.from_pretrained(
    "THUDM/CogVideoX-2b",  # 2B íŒŒë¼ë¯¸í„°
    torch_dtype=torch.float16
)
pipe.enable_model_cpu_offload()
pipe.vae.enable_slicing()

prompt = "A panda playing guitar in a bamboo forest, \
         soft lighting, peaceful atmosphere"

# 6ì´ˆ ë¹„ë””ì˜¤ ìƒì„±
video = pipe(
    prompt=prompt,
    num_videos_per_prompt=1,
    num_inference_steps=50,
    num_frames=49,  # ì•½ 6ì´ˆ
    guidance_scale=6.0,
).frames[0]

export_to_video(video, "panda_guitar.mp4", fps=8)
print("âœ… CogVideoX ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ!")
```

### LTX-Video: ë¹ ë¥¸ ë¹„ë””ì˜¤ ìƒì„±

```python
import torch
from diffusers import LTXPipeline
from diffusers.utils import export_to_video

# LTX-Video: Lightricksì˜ ì‹¤ì‹œê°„ ë¹„ë””ì˜¤ ëª¨ë¸
pipe = LTXPipeline.from_pretrained(
    "Lightricks/LTX-Video",
    torch_dtype=torch.bfloat16
)
pipe.to("cuda")

# ë¹ ë¥¸ ìƒì„± (ìˆ˜ ì´ˆ ë‚´)
prompt = "A timelapse of a flower blooming, macro shot"

video = pipe(
    prompt=prompt,
    negative_prompt="worst quality, blurry",
    num_frames=121,  # 5ì´ˆ @ 24fps
    height=480,
    width=704,
    num_inference_steps=30,
    guidance_scale=3.0,
).frames[0]

export_to_video(video, "flower_bloom.mp4", fps=24)
print("âœ… LTX-Video ìƒì„± ì™„ë£Œ!")
```

### DiT ê¸°ë°˜ ë¹„ë””ì˜¤ ëª¨ë¸ êµ¬ì¡° ì´í•´

```python
import torch
import torch.nn as nn
from einops import rearrange

class VideoSpacetimePatch(nn.Module):
    """ë¹„ë””ì˜¤ë¥¼ ì‹œê³µê°„ íŒ¨ì¹˜ë¡œ ë³€í™˜í•˜ëŠ” ë ˆì´ì–´"""
    def __init__(self, in_channels, embed_dim, patch_size=(2, 16, 16)):
        super().__init__()
        self.patch_size = patch_size  # (t, h, w)
        pt, ph, pw = patch_size

        # 3D ì»¨ë³¼ë£¨ì…˜ìœ¼ë¡œ íŒ¨ì¹˜ ì„ë² ë”©
        self.proj = nn.Conv3d(
            in_channels,
            embed_dim,
            kernel_size=patch_size,
            stride=patch_size
        )

    def forward(self, x):
        """
        x: (B, C, T, H, W) - ë¹„ë””ì˜¤ í…ì„œ
        ì¶œë ¥: (B, N, D) - í† í° ì‹œí€€ìŠ¤
        """
        # íŒ¨ì¹˜ ì„ë² ë”©
        x = self.proj(x)  # (B, D, T', H', W')

        # ì‹œí€€ìŠ¤ë¡œ ë³€í™˜
        x = rearrange(x, 'b d t h w -> b (t h w) d')

        return x


class VideoDiTBlock(nn.Module):
    """ë¹„ë””ì˜¤ DiT ë¸”ë¡ (Sora ìŠ¤íƒ€ì¼ ì¶”ì •)"""
    def __init__(self, dim, num_heads=16, mlp_ratio=4.0):
        super().__init__()

        # Layer Norms
        self.norm1 = nn.LayerNorm(dim)
        self.norm2 = nn.LayerNorm(dim)
        self.norm3 = nn.LayerNorm(dim)

        # Self-Attention (ì „ì²´ ì‹œê³µê°„)
        self.attn = nn.MultiheadAttention(dim, num_heads, batch_first=True)

        # Cross-Attention (í…ìŠ¤íŠ¸ ì¡°ê±´)
        self.cross_attn = nn.MultiheadAttention(dim, num_heads, batch_first=True)

        # MLP
        hidden_dim = int(dim * mlp_ratio)
        self.mlp = nn.Sequential(
            nn.Linear(dim, hidden_dim),
            nn.GELU(),
            nn.Linear(hidden_dim, dim)
        )

        # AdaLN-Zeroë¥¼ ìœ„í•œ scale/shift
        self.adaLN = nn.Linear(dim, 6 * dim)

    def forward(self, x, text_emb, time_emb):
        """
        x: (B, N, D) - ë¹„ë””ì˜¤ í† í°
        text_emb: (B, L, D) - í…ìŠ¤íŠ¸ ì„ë² ë”©
        time_emb: (B, D) - íƒ€ì„ìŠ¤í… ì„ë² ë”©
        """
        # AdaLN íŒŒë¼ë¯¸í„° ê³„ì‚°
        ada_params = self.adaLN(time_emb)  # (B, 6*D)
        shift1, scale1, shift2, scale2, shift3, scale3 = ada_params.chunk(6, dim=-1)

        # Self-Attention + AdaLN
        h = self.norm1(x) * (1 + scale1.unsqueeze(1)) + shift1.unsqueeze(1)
        h = self.attn(h, h, h)[0]
        x = x + h

        # Cross-Attention (í…ìŠ¤íŠ¸)
        h = self.norm2(x) * (1 + scale2.unsqueeze(1)) + shift2.unsqueeze(1)
        h = self.cross_attn(h, text_emb, text_emb)[0]
        x = x + h

        # MLP
        h = self.norm3(x) * (1 + scale3.unsqueeze(1)) + shift3.unsqueeze(1)
        h = self.mlp(h)
        x = x + h

        return x


# ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    # 480p, 16í”„ë ˆì„ ë¹„ë””ì˜¤
    video = torch.randn(2, 4, 16, 60, 80)  # (B, C, T, H, W) - latent

    # íŒ¨ì¹˜ ì„ë² ë”©
    patch_embed = VideoSpacetimePatch(
        in_channels=4,
        embed_dim=1024,
        patch_size=(2, 8, 8)
    )

    tokens = patch_embed(video)
    print(f"ë¹„ë””ì˜¤ â†’ í† í°: {video.shape} â†’ {tokens.shape}")
    # [2, 4, 16, 60, 80] â†’ [2, 600, 1024]

    # DiT ë¸”ë¡
    block = VideoDiTBlock(dim=1024)

    text_emb = torch.randn(2, 77, 1024)   # í…ìŠ¤íŠ¸ ì„ë² ë”©
    time_emb = torch.randn(2, 1024)       # íƒ€ì„ìŠ¤í… ì„ë² ë”©

    output = block(tokens, text_emb, time_emb)
    print(f"DiT ì¶œë ¥: {output.shape}")  # [2, 600, 1024]
```

## ë” ê¹Šì´ ì•Œì•„ë³´ê¸°: ë¹„ë””ì˜¤ AIì˜ ë¯¸ë˜

**2024ë…„ â€” ë¹„ë””ì˜¤ ìƒì„± í­ë°œì˜ í•´**

2024ë…„ì€ ë¹„ë””ì˜¤ ìƒì„± AIì˜ í­ë°œì  ì„±ì¥ì˜ í•´ì˜€ìŠµë‹ˆë‹¤. Sora ë°œí‘œ ì´í›„ ë¶ˆê³¼ 10ê°œì›” ë§Œì—:

- **Google Veo/Veo 2**: Soraì— í•„ì í•˜ëŠ” í’ˆì§ˆ
- **Runway Gen-3**: í”„ë¡œ í¬ë¦¬ì—ì´í„°ìš© ë„êµ¬
- **Kling**: 2ë¶„ ì˜ìƒ ê°€ëŠ¥
- **Open-Sora**: ì˜¤í”ˆì†ŒìŠ¤ ì¬í˜„
- **CogVideoX**: í•™ê³„ ê³µê°œ ëª¨ë¸
- **Mochi 1**: Genmoì˜ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸

**í•µì‹¬ íŠ¸ë Œë“œ:**

1. **DiTê°€ í‘œì¤€ì´ ë¨**: ê±°ì˜ ëª¨ë“  SOTA ëª¨ë¸ì´ Transformer ê¸°ë°˜
2. **ì‹œê³µê°„ í†µí•© ì²˜ë¦¬**: ê³µê°„/ì‹œê°„ ë¶„ë¦¬ â†’ í†µí•© ì–´í…ì…˜
3. **ìŠ¤ì¼€ì¼ë§ì´ ë‹µ**: ë” í° ëª¨ë¸ = ë” ì¢‹ì€ í’ˆì§ˆ
4. **ë°ì´í„°ê°€ í•µì‹¬**: ê³ í’ˆì§ˆ ë¹„ë””ì˜¤ ë°ì´í„°ì…‹ í™•ë³´ ê²½ìŸ

**ë‚¨ì€ ê³¼ì œ:**

| ê³¼ì œ | í˜„ì¬ ìƒíƒœ |
|------|-----------|
| **ë¬¼ë¦¬ ì •í™•ì„±** | ë‹¨ìˆœí•œ ë¬¼ë¦¬ëŠ” OK, ë³µì¡í•œ ìƒí˜¸ì‘ìš©ì€ ë¶€ì •í™• |
| **ê¸´ ì˜ìƒ** | 1ë¶„ ì´ìƒì€ ì¼ê´€ì„± ì €í•˜ |
| **ì œì–´ ê°€ëŠ¥ì„±** | ì„¸ë°€í•œ ë™ì‘ ì œì–´ ì–´ë ¤ì›€ |
| **ìƒì„± ì†ë„** | 1ë¶„ ì˜ìƒì— ìˆ˜ì‹­ ë¶„ ì†Œìš” |
| **ìœ¤ë¦¬ì  ë¬¸ì œ** | ë”¥í˜ì´í¬, ì €ì‘ê¶Œ |

## í”í•œ ì˜¤í•´ì™€ íŒ

> âš ï¸ **í”í•œ ì˜¤í•´**: "Soraê°€ ê³µê°œë˜ë©´ ëˆ„êµ¬ë‚˜ í• ë¦¬ìš°ë“œ ì˜í™”ë¥¼ ë§Œë“¤ ìˆ˜ ìˆë‹¤"
>
> í˜„ì‹¤ì€ ë‹¤ë¦…ë‹ˆë‹¤. í˜„ì¬ ë¹„ë””ì˜¤ AIëŠ” **ëª‡ ì´ˆ~1ë¶„ í´ë¦½**ì„ ì˜ ë§Œë“¤ì§€ë§Œ, ì˜í™”ëŠ” **ìˆ˜ì²œ ê°œ í´ë¦½ì˜ ì¼ê´€ëœ ì—°ê²°**ì…ë‹ˆë‹¤. ìºë¦­í„° ì¼ê´€ì„±, ìŠ¤í† ë¦¬ ì—°ì†ì„±, ì˜¤ë””ì˜¤ ì‹±í¬ ë“± í•´ê²°í•´ì•¼ í•  ë¬¸ì œê°€ ë§ìŠµë‹ˆë‹¤.

> ğŸ’¡ **ì•Œê³  ê³„ì…¨ë‚˜ìš”?**: Sora í›ˆë ¨ì—ëŠ” ì¶”ì • **ìˆ˜ì²œì–µ~ì¡° ë‹¨ìœ„ í† í°**ì˜ ë¹„ë””ì˜¤ ë°ì´í„°ê°€ ì‚¬ìš©ë˜ì—ˆì„ ê²ƒì…ë‹ˆë‹¤. GPT-4 í›ˆë ¨ ë°ì´í„°ì™€ ë§ë¨¹ëŠ” ê·œëª¨ì£ . ë¹„ë””ì˜¤ëŠ” ì´ë¯¸ì§€ë³´ë‹¤ ë°ì´í„° ë°€ë„ê°€ ë‚®ê¸° ë•Œë¬¸ì—, ë” ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.

> ğŸ”¥ **ì‹¤ë¬´ íŒ**: í˜„ì¬ ë¹„ë””ì˜¤ AIë¥¼ ì‹¤ë¬´ì— í™œìš©í•˜ë ¤ë©´ **ìƒì„± í›„ í¸ì§‘** ì›Œí¬í”Œë¡œìš°ê°€ í•„ìˆ˜ì…ë‹ˆë‹¤. AIê°€ ìƒì„±í•œ ì—¬ëŸ¬ í´ë¦½ ì¤‘ ì¢‹ì€ ê²ƒì„ ì„ ë³„í•˜ê³ , í¸ì§‘ ì†Œí”„íŠ¸ì›¨ì–´ì—ì„œ ì¡°í•©í•˜ì„¸ìš”.

> ğŸ”¥ **ì‹¤ë¬´ íŒ**: ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸(CogVideoX, Open-Sora, LTX-Video)ì€ ë¡œì»¬ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•˜ì§€ë§Œ, **ìƒìš© ì„œë¹„ìŠ¤(Runway, Pika)**ê°€ í’ˆì§ˆê³¼ ì†ë„ ë©´ì—ì„œ ì•ì„œëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ìš©ë„ì— ë§ê²Œ ì„ íƒí•˜ì„¸ìš”.

## í•µì‹¬ ì •ë¦¬

| ê°œë… | ì„¤ëª… |
|------|------|
| **DiT (Diffusion Transformer)** | U-Net ëŒ€ì‹  Transformer ì‚¬ìš©, ìŠ¤ì¼€ì¼ë§ íš¨ìœ¨ì  |
| **Spacetime Patches** | ë¹„ë””ì˜¤ë¥¼ 3D íŒ¨ì¹˜ë¡œ ë‚˜ëˆ  í† í°í™” |
| **3D VAE** | ì‹œê³µê°„ ë™ì‹œ ì••ì¶•ìœ¼ë¡œ ê³„ì‚°ëŸ‰ ê°ì†Œ |
| **ì–‘ë°©í–¥ ì–´í…ì…˜** | ì „ì²´ ë¹„ë””ì˜¤ì— Full Attention ì ìš© |
| **World Simulator** | ë¬¼ë¦¬ ë²•ì¹™ê³¼ 3D ê³µê°„ ì´í•´ ëª©í‘œ |
| **ìŠ¤ì¼€ì¼ë§ ë²•ì¹™** | ëª¨ë¸/ë°ì´í„° í¬ê¸° â†‘ â†’ í’ˆì§ˆ â†‘ |

## ë‹¤ìŒ ì±•í„° ë¯¸ë¦¬ë³´ê¸°

ì´ë¡œì¨ ë¹„ë””ì˜¤ ìƒì„±ì˜ ì„¸ê³„ë¥¼ ì‚´í´ë´¤ìŠµë‹ˆë‹¤! ë‹¤ìŒ ì±•í„° [3D ì»´í“¨í„° ë¹„ì „](../16-3d-vision/01-depth-estimation.md)ì—ì„œëŠ” **2D ì´ë¯¸ì§€ì—ì„œ 3D ì„¸ê³„ë¥¼ ì´í•´í•˜ëŠ” ê¸°ìˆ **ì„ ë°°ì›ë‹ˆë‹¤. ê¹Šì´ ì¶”ì •, í¬ì¸íŠ¸ í´ë¼ìš°ë“œ, ì¹´ë©”ë¼ ê¸°í•˜í•™ ë“± ë¹„ë””ì˜¤ë¥¼ ë„˜ì–´ **ê³µê°„ì„ ì´í•´í•˜ëŠ” AI**ì˜ ì„¸ê³„ë¡œ ë“¤ì–´ê°‘ë‹ˆë‹¤. Soraê°€ "World Simulator"ë¥¼ ëª©í‘œë¡œ í•œë‹¤ë©´, 3D ë¹„ì „ì€ ê·¸ ê¸°ë°˜ì´ ë˜ëŠ” ê¸°ìˆ ì´ì£ !

## ì°¸ê³  ìë£Œ

- [Video generation models as world simulators - OpenAI](https://openai.com/index/video-generation-models-as-world-simulators/) - Sora ê¸°ìˆ  ë³´ê³ ì„œ
- [Sora System Card - OpenAI](https://openai.com/index/sora-system-card/) - ì•ˆì „ ë° í•œê³„ ë¬¸ì„œ
- [Explaining Sora's Spacetime Patches - TDS](https://towardsdatascience.com/explaining-openai-soras-spacetime-patches-the-key-ingredient-e14e0703ec5b/) - ì‹œê³µê°„ íŒ¨ì¹˜ í•´ì„¤
- [Open-Sora GitHub](https://github.com/hpcaitech/Open-Sora) - ì˜¤í”ˆì†ŒìŠ¤ ì¬í˜„ í”„ë¡œì íŠ¸
- [Video Generation Models Explosion 2024](https://yenchenlin.me/blog/2025/01/08/video-generation-models-explosion-2024/) - 2024 ë¹„ë””ì˜¤ ëª¨ë¸ ì´ì •ë¦¬
- [Sora Technical Review - Medium](https://j-qi.medium.com/openai-soras-technical-review-a8f85b44cb7f) - ê¸°ìˆ  ë¶„ì„
