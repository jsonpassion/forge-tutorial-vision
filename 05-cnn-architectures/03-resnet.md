# ResNetê³¼ Skip Connection

> ì”ì°¨ í•™ìŠµìœ¼ë¡œ ê¹Šì€ ë„¤íŠ¸ì›Œí¬ í›ˆë ¨

## ê°œìš”

[VGG](./02-vgg-googlenet.md)ì—ì„œ "ê¹Šì´ê°€ ê¹Šì„ìˆ˜ë¡ ì¢‹ë‹¤"ê³  í–ˆì§€ë§Œ, 20ì¸µì„ ë„˜ì–´ê°€ë©´ ì˜¤íˆë ¤ ì„±ëŠ¥ì´ **ë–¨ì–´ì§€ëŠ”** í˜„ìƒì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ë‚œì œë¥¼ ë‹¨ í•˜ë‚˜ì˜ ì•„ì´ë””ì–´ â€” **Skip Connection(ì”ì°¨ ì—°ê²°)** â€” ë¡œ í•´ê²°í•œ ê²ƒì´ **ResNet**ì…ë‹ˆë‹¤. 2015ë…„ ë“±ì¥ ì´í›„ ì‚¬ì‹¤ìƒ ëª¨ë“  ë”¥ëŸ¬ë‹ ì•„í‚¤í…ì²˜ì˜ ê¸°ë³¸ ìš”ì†Œê°€ ëœ, ì—­ëŒ€ ê°€ì¥ ì˜í–¥ë ¥ ìˆëŠ” CNN ë…¼ë¬¸ì„ ë‹¤ë£¹ë‹ˆë‹¤.

**ì„ ìˆ˜ ì§€ì‹**: [VGGì™€ GoogLeNet](./02-vgg-googlenet.md), [ì—­ì „íŒŒ ì•Œê³ ë¦¬ì¦˜](../03-deep-learning-basics/03-backpropagation.md)
**í•™ìŠµ ëª©í‘œ**:
- ì„±ëŠ¥ ì €í•˜(Degradation) ë¬¸ì œê°€ ë¬´ì—‡ì¸ì§€ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤
- ì”ì°¨ í•™ìŠµ(Residual Learning)ì˜ ì›ë¦¬ì™€ íš¨ê³¼ë¥¼ ì´í•´í•œë‹¤
- Basic Blockê³¼ Bottleneck Blockì˜ ì°¨ì´ë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤

## ì™œ ì•Œì•„ì•¼ í• ê¹Œ?

ResNetì€ ë‹¨ìˆœíˆ "ì¢‹ì€ ëª¨ë¸ í•˜ë‚˜"ê°€ ì•„ë‹™ë‹ˆë‹¤. Skip Connectionì´ë¼ëŠ” ê°œë…ì€ ì´í›„ DenseNet, Transformer, U-Net, Diffusion ëª¨ë¸ ë“± ê±°ì˜ **ëª¨ë“  í˜„ëŒ€ ì•„í‚¤í…ì²˜**ì— ìŠ¤ë©°ë“¤ì–´ ìˆìŠµë‹ˆë‹¤. ResNetì„ ì´í•´í•˜ë©´ í˜„ëŒ€ ë”¥ëŸ¬ë‹ì˜ í•µì‹¬ ì„¤ê³„ ì›ë¦¬ë¥¼ ì´í•´í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

## í•µì‹¬ ê°œë…

### 1. ì„±ëŠ¥ ì €í•˜(Degradation) ë¬¸ì œ â€” ê¹Šìœ¼ë©´ ì¢‹ì§€ ì•Šë‚˜ìš”?

ì§ê´€ì ìœ¼ë¡œ ìƒê°í•˜ë©´, 20ì¸µ ë„¤íŠ¸ì›Œí¬ê°€ ì˜ ë™ì‘í•œë‹¤ë©´ 56ì¸µ ë„¤íŠ¸ì›Œí¬ëŠ” ë” ì˜ ë™ì‘í•´ì•¼ í•©ë‹ˆë‹¤. ìµœì†Œí•œ ì¶”ê°€ ë ˆì´ì–´ê°€ í•­ë“± í•¨ìˆ˜(ì•„ë¬´ê²ƒë„ ì•ˆ í•¨)ë§Œ í•™ìŠµí•´ë„ 20ì¸µê³¼ ê°™ì€ ì„±ëŠ¥ì€ ë‚˜ì™€ì•¼ í•˜ë‹ˆê¹Œìš”.

ê·¸ëŸ°ë° ì‹¤ì œë¡œëŠ” **56ì¸µì´ 20ì¸µë³´ë‹¤ ì„±ëŠ¥ì´ ë‚˜ë¹´ìŠµë‹ˆë‹¤**. ê·¸ê²ƒë„ ê³¼ì í•©ì´ ì•„ë‹ˆë¼, **í•™ìŠµ ë°ì´í„°ì—ì„œë„** ì„±ëŠ¥ì´ ë‚®ì•˜ìŠµë‹ˆë‹¤.

> ğŸ’¡ **ë¹„ìœ **: 10ëª…ì´ ë¦´ë ˆì´ë¡œ ê·¸ë¦¼ì„ ë”°ë¼ ê·¸ë¦¬ëŠ” ê²Œì„ì—ì„œ, ì‚¬ëŒì´ ë§ì„ìˆ˜ë¡ ì›ë³¸ê³¼ ë‹¬ë¼ì§€ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤. ê° ì‚¬ëŒ(ë ˆì´ì–´)ì´ "ì›ë³¸ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬"í•˜ëŠ” ê²ƒì¡°ì°¨ ì–´ë µê¸° ë•Œë¬¸ì´ì£ .

ì´ê²ƒì´ **ì„±ëŠ¥ ì €í•˜ ë¬¸ì œ**ì…ë‹ˆë‹¤. ê¸°ìš¸ê¸° ì†Œì‹¤ê³¼ë„ ê´€ë ¨ ìˆì§€ë§Œ, í•µì‹¬ì€ ê¹Šì€ ë„¤íŠ¸ì›Œí¬ê°€ **í•­ë“± í•¨ìˆ˜ì¡°ì°¨ í•™ìŠµí•˜ê¸° ì–´ë µë‹¤**ëŠ” ê²ƒì…ë‹ˆë‹¤.

### 2. ì”ì°¨ í•™ìŠµ(Residual Learning) â€” í•µì‹¬ ì•„ì´ë””ì–´

ì¹´ì´ë° í—ˆ(Kaiming He)ì˜ í†µì°°ì€ ì´ë ‡ìŠµë‹ˆë‹¤:

> "ì›ë˜ í•¨ìˆ˜ $H(x)$ë¥¼ ì§ì ‘ í•™ìŠµí•˜ëŠ” ëŒ€ì‹ , **ì”ì°¨(residual)** $F(x) = H(x) - x$ë¥¼ í•™ìŠµí•˜ì"

ìˆ˜ì‹ìœ¼ë¡œ í‘œí˜„í•˜ë©´:

$$y = F(x) + x$$

- $x$: ì…ë ¥ (Skip Connectionìœ¼ë¡œ ê·¸ëŒ€ë¡œ ì „ë‹¬)
- $F(x)$: ë ˆì´ì–´ê°€ í•™ìŠµí•˜ëŠ” ì”ì°¨ í•¨ìˆ˜
- $y$: ì¶œë ¥

> ğŸ’¡ **ë¹„ìœ **: ì‚¬ì§„ì„ ë³´ì •í•  ë•Œ, ì²˜ìŒë¶€í„° ì™„ì„±ë³¸ì„ ê·¸ë¦¬ëŠ” ê²ƒ(ì›ë˜ ë°©ì‹)ë³´ë‹¤ **ì›ë³¸ì— ìˆ˜ì • ì‚¬í•­ë§Œ ì¶”ê°€**í•˜ëŠ” ê²ƒ(ì”ì°¨ í•™ìŠµ)ì´ í›¨ì”¬ ì‰½ì£ ? "ì›ë³¸ + ì•½ê°„ì˜ ë³´ì • = ê²°ê³¼"ê°€ í•µì‹¬ì…ë‹ˆë‹¤.

**ì™œ íš¨ê³¼ì ì¼ê¹Œìš”?**
- ì¶”ê°€ ë ˆì´ì–´ê°€ í•™ìŠµí•  ê²Œ ì—†ìœ¼ë©´, $F(x) = 0$ë§Œ í•™ìŠµí•˜ë©´ ë©ë‹ˆë‹¤ â†’ **í•­ë“± í•¨ìˆ˜ê°€ ìë™ìœ¼ë¡œ ë³´ì¥**
- ê¸°ìš¸ê¸°ê°€ Skip Connectionì„ í†µí•´ ì§ì ‘ ì „ë‹¬ â†’ **ê¸°ìš¸ê¸° ì†Œì‹¤ ì™„í™”**
- ë„¤íŠ¸ì›Œí¬ê°€ "ë³€í™”ëŸ‰"ì— ì§‘ì¤‘ â†’ í•™ìŠµì´ ë” ì‰¬ì›€

### 3. Residual Blockì˜ ë‘ ê°€ì§€ í˜•íƒœ

**Basic Block (ResNet-18/34)**

| ìˆœì„œ | ë ˆì´ì–´ | ì„¤ëª… |
|------|--------|------|
| 1 | Conv 3Ã—3 | íŠ¹ì„± ì¶”ì¶œ |
| 2 | BatchNorm + ReLU | ì •ê·œí™” + í™œì„±í™” |
| 3 | Conv 3Ã—3 | íŠ¹ì„± ì¶”ì¶œ |
| 4 | BatchNorm | ì •ê·œí™” |
| + | **Skip Connection** | ì…ë ¥ì„ ë”í•¨ |
| 5 | ReLU | í™œì„±í™” |

**Bottleneck Block (ResNet-50/101/152)**

ë” ê¹Šì€ ëª¨ë¸ì—ì„œëŠ” ì—°ì‚°ëŸ‰ì„ ì¤„ì´ê¸° ìœ„í•´ **ë³‘ëª© êµ¬ì¡°**ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤:

| ìˆœì„œ | ë ˆì´ì–´ | ì±„ë„ ë³€í™” | ì—­í•  |
|------|--------|----------|------|
| 1 | Conv 1Ã—1 | 256 â†’ 64 | ì±„ë„ ì¶•ì†Œ (ë³‘ëª©) |
| 2 | BatchNorm + ReLU | | |
| 3 | Conv 3Ã—3 | 64 â†’ 64 | ê³µê°„ íŠ¹ì„± ì¶”ì¶œ |
| 4 | BatchNorm + ReLU | | |
| 5 | Conv 1Ã—1 | 64 â†’ 256 | ì±„ë„ ë³µì› |
| 6 | BatchNorm | | |
| + | **Skip Connection** | | ì…ë ¥ì„ ë”í•¨ |
| 7 | ReLU | | |

1Ã—1ë¡œ ì±„ë„ì„ ì¤„ì¸ ë’¤(64) 3Ã—3 í•©ì„±ê³±ì„ ìˆ˜í–‰í•˜ê³ , ë‹¤ì‹œ 1Ã—1ë¡œ ë³µì›(256)í•˜ëŠ” êµ¬ì¡°ì…ë‹ˆë‹¤. [1Ã—1 í•©ì„±ê³±](./02-vgg-googlenet.md)ì˜ ì±„ë„ ì¶•ì†Œ íš¨ê³¼ë¥¼ í™œìš©í•œ ê²ƒì´ì£ .

### 4. ResNet ì•„í‚¤í…ì²˜ íŒ¨ë°€ë¦¬

| ëª¨ë¸ | ë¸”ë¡ íƒ€ì… | ë ˆì´ì–´ ìˆ˜ | íŒŒë¼ë¯¸í„° | Top-5 ì—ëŸ¬ |
|------|----------|----------|---------|-----------|
| ResNet-18 | Basic | 18 | 11.7M | 10.9% |
| ResNet-34 | Basic | 34 | 21.8M | 8.6% |
| **ResNet-50** | Bottleneck | 50 | **25.6M** | **6.7%** |
| ResNet-101 | Bottleneck | 101 | 44.5M | 6.0% |
| ResNet-152 | Bottleneck | 152 | 60.2M | 5.7% |

**ResNet-50**ì´ ì‹¤ë¬´ì—ì„œ ê°€ì¥ ë§ì´ ì‚¬ìš©ë©ë‹ˆë‹¤. íŒŒë¼ë¯¸í„° ëŒ€ë¹„ ì„±ëŠ¥ì˜ ê· í˜•ì´ ê°€ì¥ ì¢‹ê¸° ë•Œë¬¸ì´ì£ .

### 5. Projection Shortcut â€” í¬ê¸°ê°€ ë‹¤ë¥¼ ë•Œ

Skip Connectionì—ì„œ ì…ë ¥ $x$ì™€ ì¶œë ¥ $F(x)$ì˜ í¬ê¸°ê°€ ë‹¤ë¥´ë©´ ì–´ë–»ê²Œ í• ê¹Œìš”? ì˜ˆë¥¼ ë“¤ì–´ ì±„ë„ì´ 64 â†’ 128ë¡œ ë°”ë€ŒëŠ” ê²½ìš°:

**í•´ê²°: 1Ã—1 í•©ì„±ê³±ìœ¼ë¡œ ì°¨ì› ë§ì¶”ê¸° (Projection Shortcut)**

$$y = F(x) + W_s \cdot x$$

$W_s$ëŠ” 1Ã—1 í•©ì„±ê³±ìœ¼ë¡œ, ì…ë ¥ì˜ ì±„ë„ ìˆ˜ë¥¼ ì¶œë ¥ê³¼ ë§ì¶°ì¤ë‹ˆë‹¤. ë™ì‹œì— ìŠ¤íŠ¸ë¼ì´ë“œ 2ë¥¼ ì ìš©í•´ ê³µê°„ í¬ê¸°ë„ ë§ì¶¥ë‹ˆë‹¤.

## ì‹¤ìŠµ: PyTorchë¡œ ResNet ë¸”ë¡ êµ¬í˜„í•˜ê¸°

### Basic Block

```python
import torch
import torch.nn as nn

class BasicBlock(nn.Module):
    """ResNet-18/34ì˜ ê¸°ë³¸ ë¸”ë¡"""
    def __init__(self, in_channels, out_channels, stride=1):
        super().__init__()
        # ë©”ì¸ ê²½ë¡œ
        self.conv1 = nn.Conv2d(in_channels, out_channels, 3,
                               stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, 3,
                               padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)

        # Skip Connection (ì°¨ì›ì´ ë‹¤ë¥´ë©´ projection)
        self.shortcut = nn.Sequential()
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, 1,
                          stride=stride, bias=False),
                nn.BatchNorm2d(out_channels),
            )

    def forward(self, x):
        identity = self.shortcut(x)       # Skip Connection
        out = self.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += identity                    # ì”ì°¨ ì—°ê²°!
        return self.relu(out)

# í…ŒìŠ¤íŠ¸
block = BasicBlock(64, 128, stride=2)  # ë‹¤ìš´ìƒ˜í”Œë§
x = torch.randn(1, 64, 32, 32)
print(f"ì…ë ¥: {x.shape} â†’ ì¶œë ¥: {block(x).shape}")
# [1, 64, 32, 32] â†’ [1, 128, 16, 16]
```

### Bottleneck Block

```python
import torch
import torch.nn as nn

class BottleneckBlock(nn.Module):
    """ResNet-50/101/152ì˜ ë³‘ëª© ë¸”ë¡"""
    expansion = 4  # ì¶œë ¥ ì±„ë„ = ì¤‘ê°„ ì±„ë„ Ã— 4

    def __init__(self, in_channels, mid_channels, stride=1):
        super().__init__()
        out_channels = mid_channels * self.expansion

        # 1Ã—1 â†’ 3Ã—3 â†’ 1Ã—1 ë³‘ëª© êµ¬ì¡°
        self.conv1 = nn.Conv2d(in_channels, mid_channels, 1, bias=False)
        self.bn1 = nn.BatchNorm2d(mid_channels)
        self.conv2 = nn.Conv2d(mid_channels, mid_channels, 3,
                               stride=stride, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(mid_channels)
        self.conv3 = nn.Conv2d(mid_channels, out_channels, 1, bias=False)
        self.bn3 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)

        # Projection Shortcut
        self.shortcut = nn.Sequential()
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, 1,
                          stride=stride, bias=False),
                nn.BatchNorm2d(out_channels),
            )

    def forward(self, x):
        identity = self.shortcut(x)
        out = self.relu(self.bn1(self.conv1(x)))  # 1Ã—1: ì±„ë„ ì¶•ì†Œ
        out = self.relu(self.bn2(self.conv2(out)))  # 3Ã—3: ê³µê°„ íŠ¹ì„±
        out = self.bn3(self.conv3(out))             # 1Ã—1: ì±„ë„ ë³µì›
        out += identity
        return self.relu(out)

# í…ŒìŠ¤íŠ¸: 256 â†’ 64(ë³‘ëª©) â†’ 256
block = BottleneckBlock(256, 64)
x = torch.randn(1, 256, 14, 14)
print(f"ì…ë ¥: {x.shape} â†’ ì¶œë ¥: {block(x).shape}")
# [1, 256, 14, 14] â†’ [1, 256, 14, 14]
```

### torchvisionì˜ ì‚¬ì „ í•™ìŠµ ResNet-50

```python
import torch
import torchvision.models as models

# ImageNet ì‚¬ì „ í•™ìŠµ ResNet-50
resnet50 = models.resnet50(weights='IMAGENET1K_V2')

# êµ¬ì¡° í™•ì¸
print(f"íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in resnet50.parameters()):,}")
# ~25,557,032

# 10 í´ë˜ìŠ¤ íŒŒì¸íŠœë‹
resnet50.fc = torch.nn.Linear(2048, 10)

# ì¶”ë¡  í…ŒìŠ¤íŠ¸
resnet50.eval()
x = torch.randn(1, 3, 224, 224)
with torch.no_grad():
    output = resnet50(x)
print(f"ì¶œë ¥: {output.shape}")  # [1, 10]
```

## ë” ê¹Šì´ ì•Œì•„ë³´ê¸°

### ResNetì˜ íƒ„ìƒ â€” "ì´ê±´ ë§ì´ ì•ˆ ë¼"ì—ì„œ ì‹œì‘ëœ í˜ëª…

2015ë…„, ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ ë¦¬ì„œì¹˜ ì•„ì‹œì•„(MSRA)ì˜ **ì¹´ì´ë° í—ˆ(Kaiming He)**ëŠ” ê¹Šì€ ë„¤íŠ¸ì›Œí¬ì˜ ì„±ëŠ¥ ì €í•˜ ì‹¤í—˜ ê²°ê³¼ë¥¼ ë³´ê³  ì˜ì•„í•´í–ˆìŠµë‹ˆë‹¤. 56ì¸µ ë„¤íŠ¸ì›Œí¬ê°€ 20ì¸µë³´ë‹¤ **í•™ìŠµ ë°ì´í„°ì—ì„œì¡°ì°¨** ì„±ëŠ¥ì´ ë‚®ë‹¤ë‹ˆ, ì´ë¡ ì ìœ¼ë¡œ ë¶ˆê°€ëŠ¥í•œ ì¼ì´ì—ˆì£ .

í•µì‹¬ í†µì°°ì€ ë†€ëë„ë¡ ë‹¨ìˆœí–ˆìŠµë‹ˆë‹¤: "ë ˆì´ì–´ì—ê²Œ ì „ì²´ í•¨ìˆ˜ë¥¼ ì²˜ìŒë¶€í„° í•™ìŠµí•˜ë¼ê³  í•˜ì§€ ë§ê³ , **ì…ë ¥ ëŒ€ë¹„ ë³€í™”ëŸ‰(ì”ì°¨)**ë§Œ í•™ìŠµí•˜ë¼ê³  í•˜ë©´ ì–´ë–¨ê¹Œ?" ì´ ì•„ì´ë””ì–´ë¥¼ êµ¬í˜„í•˜ëŠ” ë°©ë²•ì€ ê·¸ì € **ì…ë ¥ì„ ì¶œë ¥ì— ë”í•˜ëŠ” ì—°ê²°ì„  í•˜ë‚˜**ë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒë¿ì´ì—ˆìŠµë‹ˆë‹¤.

ê²°ê³¼ëŠ” ì••ë„ì ì´ì—ˆìŠµë‹ˆë‹¤. 152ì¸µ ResNetì´ 2015ë…„ ImageNetì—ì„œ **3.57% ì—ëŸ¬ìœ¨**(ì¸ê°„ ìˆ˜ì¤€ì¸ 5.1%ë¥¼ ìƒíšŒ!)ì„ ë‹¬ì„±í•˜ë©° 1ìœ„ë¥¼ ì°¨ì§€í–ˆìŠµë‹ˆë‹¤. ì¹´ì´ë° í—ˆëŠ” ì´í›„ Faster R-CNN, Mask R-CNN ë“±ë„ ê°œë°œí•˜ë©° ì»´í“¨í„° ë¹„ì „ ë¶„ì•¼ì—ì„œ ê°€ì¥ ì˜í–¥ë ¥ ìˆëŠ” ì—°êµ¬ì ì¤‘ í•œ ëª…ì´ ë˜ì—ˆìŠµë‹ˆë‹¤.

> ğŸ’¡ **ì•Œê³  ê³„ì…¨ë‚˜ìš”?**: ResNet ë…¼ë¬¸ì€ 2025ë…„ ê¸°ì¤€ **20ë§Œ íšŒ ì´ìƒ ì¸ìš©**ë˜ì–´, ë”¥ëŸ¬ë‹ ë¶„ì•¼ ì—­ëŒ€ ìµœë‹¤ ì¸ìš© ë…¼ë¬¸ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. Skip Connectionì˜ ì•„ì´ë””ì–´ëŠ” ì´í›„ Transformerì˜ ì”ì°¨ ì—°ê²°, U-Netì˜ ìŠ¤í‚µ ì—°ê²°, DenseNetì˜ ë°€ì§‘ ì—°ê²° ë“± ë¬´ìˆ˜í•œ ë³€í˜•ì„ ë‚³ì•˜ìŠµë‹ˆë‹¤.

### Pre-Activation ResNet

ì›ë˜ ResNet ë¸”ë¡ì€ Conv â†’ BN â†’ ReLU ìˆœì„œì— Skip Connectionì„ ë”í•˜ëŠ” êµ¬ì¡°ì˜€ì§€ë§Œ, ì¹´ì´ë° í—ˆëŠ” 2016ë…„ í›„ì† ë…¼ë¬¸ì—ì„œ BN â†’ ReLU â†’ Conv ìˆœì„œ(Pre-Activation)ê°€ **ë§¤ìš° ê¹Šì€ ë„¤íŠ¸ì›Œí¬ì—ì„œ ë” ì¢‹ë‹¤**ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ê·¸ë˜ë””ì–¸íŠ¸ê°€ í™œì„±í™” í•¨ìˆ˜ì— ë°©í•´ë°›ì§€ ì•Šê³  Skip Connectionì„ í†µí•´ ìˆœìˆ˜í•˜ê²Œ íë¥¼ ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

## í”í•œ ì˜¤í•´ì™€ íŒ

> âš ï¸ **í”í•œ ì˜¤í•´**: "ResNetì˜ Skip Connectionì€ ê¸°ìš¸ê¸° ì†Œì‹¤ì„ í•´ê²°í•œë‹¤" â€” ë§ëŠ” ë§ì´ì§€ë§Œ ë¶ˆì™„ì „í•©ë‹ˆë‹¤. ì›ë˜ ë…¼ë¬¸ì˜ í•µì‹¬ì€ ê¸°ìš¸ê¸° ì†Œì‹¤ì´ ì•„ë‹ˆë¼ **ì„±ëŠ¥ ì €í•˜(degradation)** ë¬¸ì œì…ë‹ˆë‹¤. ê¸°ìš¸ê¸°ê°€ ì˜ íë¥´ëŠ” ê²ƒì€ ì„±ëŠ¥ ì €í•˜ í•´ê²°ì˜ **ê²°ê³¼**ì´ì§€ ì§ì ‘ì  ëª©í‘œëŠ” ì•„ë‹ˆì—ˆìŠµë‹ˆë‹¤.

> ğŸ”¥ **ì‹¤ë¬´ íŒ**: ì‹¤ë¬´ì—ì„œ ê°€ì¥ ë§ì´ ì“°ì´ëŠ” ëª¨ë¸ì€ **ResNet-50**ì…ë‹ˆë‹¤. ResNet-101/152ëŠ” íŒŒë¼ë¯¸í„° ëŒ€ë¹„ ì„±ëŠ¥ í–¥ìƒì´ í¬ì§€ ì•Šì•„, ë¹„ìš© íš¨ìœ¨ì´ ë–¨ì–´ì§‘ë‹ˆë‹¤. "ì¼ë‹¨ ResNet-50ìœ¼ë¡œ ì‹œì‘"ì´ ê±°ì˜ ëª¨ë“  ë¹„ì „ íƒœìŠ¤í¬ì˜ ì•ˆì „í•œ ì‹œì‘ì ì…ë‹ˆë‹¤.

> ğŸ”¥ **ì‹¤ë¬´ íŒ**: `torchvision.models.resnet50(weights='IMAGENET1K_V2')`ì˜ `V2` ê°€ì¤‘ì¹˜ëŠ” ìµœì‹  í•™ìŠµ ê¸°ë²•(ë” ê¸´ í•™ìŠµ, ê°•í•œ ì¦ê°•)ìœ¼ë¡œ ì¬í•™ìŠµëœ ê²ƒìœ¼ë¡œ, ê¸°ì¡´ `V1`ë³´ë‹¤ ì•½ 1~2% ì •í™•ë„ê°€ ë†’ìŠµë‹ˆë‹¤. íŠ¹ë³„í•œ ì´ìœ ê°€ ì—†ë‹¤ë©´ V2ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

## í•µì‹¬ ì •ë¦¬

| ê°œë… | ì„¤ëª… |
|------|------|
| ì„±ëŠ¥ ì €í•˜ ë¬¸ì œ | ê¹Šì€ ë„¤íŠ¸ì›Œí¬ê°€ ì–•ì€ ê²ƒë³´ë‹¤ ì„±ëŠ¥ì´ ë‚˜ìœ ì—­ì„¤ì  í˜„ìƒ |
| Skip Connection | ì…ë ¥ì„ ì¶œë ¥ì— ì§ì ‘ ë”í•˜ëŠ” ì§€ë¦„ê¸¸ ì—°ê²° |
| ì”ì°¨ í•™ìŠµ | $y = F(x) + x$, ë³€í™”ëŸ‰ë§Œ í•™ìŠµí•˜ëŠ” íŒ¨ëŸ¬ë‹¤ì„ |
| Basic Block | 3Ã—3 Conv 2ê°œ + Skip. ResNet-18/34 ì‚¬ìš© |
| Bottleneck Block | 1Ã—1 â†’ 3Ã—3 â†’ 1Ã—1 + Skip. ResNet-50+ ì‚¬ìš© |
| Projection Shortcut | ì°¨ì›ì´ ë‹¤ë¥¼ ë•Œ 1Ã—1 Convë¡œ ë§ì¶”ëŠ” ê¸°ë²• |
| ResNet-50 | ì‹¤ë¬´ í‘œì¤€. 25.6M íŒŒë¼ë¯¸í„°, ë›°ì–´ë‚œ ì„±ëŠ¥ ëŒ€ë¹„ íš¨ìœ¨ |

## ë‹¤ìŒ ì„¹ì…˜ ë¯¸ë¦¬ë³´ê¸°

ResNetì´ "ì…ë ¥ì„ ì¶œë ¥ì— ë”í•œë‹¤"ë©´, "ëª¨ë“  ì´ì „ ë ˆì´ì–´ë¥¼ ì—°ê²°í•œë‹¤"ë©´ ì–´ë–¨ê¹Œìš”? [DenseNetê³¼ SENet](./04-densenet-senet.md)ì—ì„œëŠ” ë” ê·¹ë‹¨ì ì¸ ì—°ê²° ì „ëµê³¼, ì±„ë„ì— "ì£¼ì˜(attention)"ë¥¼ ê¸°ìš¸ì´ëŠ” ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„ì„ ë§Œë‚©ë‹ˆë‹¤.

## ì°¸ê³  ìë£Œ

- [Deep Residual Learning for Image Recognition (He et al., 2015)](https://arxiv.org/abs/1512.03385) - ResNet ì›ì¡° ë…¼ë¬¸. ì—­ëŒ€ ìµœë‹¤ ì¸ìš© ë”¥ëŸ¬ë‹ ë…¼ë¬¸ ì¤‘ í•˜ë‚˜
- [Identity Mappings in Deep Residual Networks (He et al., 2016)](https://arxiv.org/pdf/1603.05027) - Pre-Activation ResNet ë…¼ë¬¸
- [Dive into Deep Learning - ResNet](https://d2l.ai/chapter_convolutional-modern/resnet.html) - ResNetì˜ ë™ê¸°ë¶€í„° êµ¬í˜„ê¹Œì§€ ì²´ê³„ì  ì„¤ëª…
- [ResNet: Revolutionizing Deep Learning - viso.ai](https://viso.ai/deep-learning/resnet-residual-neural-network/) - ResNetì˜ ë³€í˜•ê³¼ ì‘ìš©ì„ í­ë„“ê²Œ ì •ë¦¬
